{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project_31.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "TWIN SVM\n",
        "Features: Energy, Dots, Lines, Contours, Edges, Corners"
      ],
      "metadata": {
        "id": "3tJ4IfDvBKlU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from TVSVM import TwinSVMClassifier"
      ],
      "metadata": {
        "id": "Xz_Uet-qTXuq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_PrM2bhlBHMM"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gsnI1u_vBaCL",
        "outputId": "12fc51bf-1959-4de6-f6a4-924b37f3d63e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/\"MyDrive/Machine Learning/Excel\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T14ZLghuBa8W",
        "outputId": "3b455019-cbb2-4bfb-a25b-ad4e13156fcb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Machine Learning/Excel\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import glob\n",
        "import cv2\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import metrics\n",
        "from sklearn import svm\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import itertools\n",
        "import random\n",
        "import time"
      ],
      "metadata": {
        "id": "Q3O0u-w1CWrf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = list()\n",
        "X_test = list()\n",
        "y_train = list()\n",
        "y_test = list()\n",
        "\n",
        "# for k fold cross validation\n",
        "x_new = list()\n",
        "y_new = list()"
      ],
      "metadata": {
        "id": "qku_lqBfBbyv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 0 = crazing \n",
        "# 1 = inclusion\n",
        "# 2 = patches\n",
        "# 3 = pitted_surface\n",
        "# 4 = rolled in scale\n",
        "# 5 = scratches"
      ],
      "metadata": {
        "id": "4vln4LnMBoQh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset1 = pd.read_csv('neudefect1.csv')\n",
        "print(dataset1)\n",
        "\n",
        "x = dataset1.iloc[:,:-1].values\n",
        "print(len(x[0]))\n",
        "\n",
        "y = list()\n",
        "\n",
        "\n",
        "print(x[0])\n",
        "print(x[499])\n",
        "\n",
        "for i in x:\n",
        "    x_new.append(i)\n",
        "\n",
        "\n",
        "random.shuffle(x)\n",
        "print(x[0])\n",
        "print(x[499])\n",
        "\n",
        "\n",
        "for i in range(0,600):\n",
        "    y.append(0)\n",
        "    y_new.append(0)\n",
        "\n",
        "\n",
        "X_train_new, X_test_new, y_train_new, y_test_new = train_test_split( x, y, test_size=0.2, random_state=4)\n",
        "print(X_test_new)\n",
        "\n",
        "for i in X_train_new :\n",
        "    X_train.append(i)\n",
        "\n",
        "for i in X_test_new :\n",
        "    X_test.append(i)\n",
        "\n",
        "for i in y_train_new :\n",
        "    y_train.append(i)\n",
        "\n",
        "for i in y_test_new :\n",
        "    y_test.append(i)\n",
        "\n",
        "print(len(X_train))\n",
        "print(len(X_test))\n",
        "print(len(y_train))\n",
        "print(len(y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "avRCrAfRmXiR",
        "outputId": "8e879149-d3b9-44a2-81e9-44d66ba2fb2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         energy  dots  lines  contours  edges  corner   \n",
            "0     96.995963   184    186         6   8574      13   \n",
            "1     96.995963   184    186         3   8637       7   \n",
            "2    107.102900   216    106         3   9968      15   \n",
            "3    107.102900   216    106         3   9961      19   \n",
            "4    123.340781   350     19         9  11597       9   \n",
            "..          ...   ...    ...       ...    ...     ... ..\n",
            "595  140.306469   280     38        12  11715       2   \n",
            "596  127.175844   215     66         3  10576       9   \n",
            "597  127.175844   215     66         2  10571       6   \n",
            "598   55.432938   177    519         3   3705       9   \n",
            "599   55.432938   177    519         3   3708       3   \n",
            "\n",
            "[600 rows x 7 columns]\n",
            "6\n",
            "[9.69959625e+01 1.84000000e+02 1.86000000e+02 6.00000000e+00\n",
            " 8.57400000e+03 1.30000000e+01]\n",
            "[3.59366625e+01 1.30000000e+02 5.69000000e+02 1.00000000e+00\n",
            " 1.15800000e+03 6.10000000e+01]\n",
            "[9.69959625e+01 1.84000000e+02 1.86000000e+02 6.00000000e+00\n",
            " 8.57400000e+03 1.30000000e+01]\n",
            "[1.62199525e+02 3.01000000e+02 8.00000000e+00 4.00000000e+00\n",
            " 1.29480000e+04 2.00000000e+00]\n",
            "[[6.04315500e+01 2.73000000e+02 7.70000000e+02 1.00000000e+00\n",
            "  4.28100000e+03 6.70000000e+01]\n",
            " [9.56059688e+01 3.75000000e+02 7.50000000e+01 8.00000000e+00\n",
            "  8.92600000e+03 1.40000000e+01]\n",
            " [1.42101775e+02 2.48000000e+02 7.60000000e+01 8.00000000e+00\n",
            "  1.24750000e+04 2.30000000e+01]\n",
            " [8.50564313e+01 2.73000000e+02 1.79000000e+02 2.00000000e+00\n",
            "  7.38100000e+03 2.00000000e+00]\n",
            " [1.19113238e+02 3.32000000e+02 1.80000000e+01 1.70000000e+01\n",
            "  1.07340000e+04 2.00000000e+00]\n",
            " [1.56597988e+02 3.17000000e+02 6.00000000e+00 1.00000000e+01\n",
            "  1.27720000e+04 7.00000000e+00]\n",
            " [6.66100438e+01 2.45000000e+02 6.06000000e+02 4.00000000e+00\n",
            "  4.79300000e+03 4.00000000e+00]\n",
            " [1.16725913e+02 2.59000000e+02 3.40000000e+01 7.00000000e+00\n",
            "  1.05260000e+04 2.00000000e+00]\n",
            " [4.96400875e+01 1.04000000e+02 4.68000000e+02 1.00000000e+00\n",
            "  2.66400000e+03 5.00000000e+00]\n",
            " [5.41573563e+01 1.14000000e+02 4.82000000e+02 5.00000000e+00\n",
            "  3.51200000e+03 5.00000000e+00]\n",
            " [1.62274888e+02 2.96000000e+02 8.00000000e+00 7.00000000e+00\n",
            "  1.31310000e+04 8.00000000e+00]\n",
            " [8.00765625e+01 2.72000000e+02 2.00000000e+02 1.00000000e+00\n",
            "  6.83600000e+03 3.00000000e+00]\n",
            " [1.25098813e+02 3.04000000e+02 1.80000000e+01 9.00000000e+00\n",
            "  1.13310000e+04 2.00000000e+00]\n",
            " [1.23340781e+02 3.50000000e+02 1.90000000e+01 9.00000000e+00\n",
            "  1.15970000e+04 9.00000000e+00]\n",
            " [1.24809775e+02 3.02000000e+02 1.60000000e+01 2.00000000e+01\n",
            "  1.15010000e+04 1.30000000e+01]\n",
            " [4.98735563e+01 1.15000000e+02 4.92000000e+02 1.00000000e+00\n",
            "  3.04700000e+03 4.00000000e+00]\n",
            " [8.00765625e+01 2.72000000e+02 2.00000000e+02 1.00000000e+00\n",
            "  6.83600000e+03 3.00000000e+00]\n",
            " [1.30465100e+02 2.92000000e+02 3.00000000e+00 2.30000000e+01\n",
            "  1.18880000e+04 3.60000000e+01]\n",
            " [4.86630625e+01 9.20000000e+01 5.06000000e+02 2.00000000e+00\n",
            "  3.16600000e+03 9.00000000e+00]\n",
            " [1.56075363e+02 2.97000000e+02 1.40000000e+01 1.70000000e+01\n",
            "  1.27000000e+04 1.80000000e+01]\n",
            " [1.16725913e+02 2.59000000e+02 3.40000000e+01 7.00000000e+00\n",
            "  1.05260000e+04 2.00000000e+00]\n",
            " [1.06606475e+02 3.01000000e+02 9.90000000e+01 1.00000000e+01\n",
            "  1.03880000e+04 1.30000000e+01]\n",
            " [4.86630625e+01 9.20000000e+01 5.06000000e+02 2.00000000e+00\n",
            "  3.16500000e+03 1.20000000e+01]\n",
            " [1.09499425e+02 3.42000000e+02 7.00000000e+00 1.80000000e+01\n",
            "  1.02550000e+04 1.40000000e+01]\n",
            " [1.11285850e+02 3.58000000e+02 8.50000000e+01 1.10000000e+01\n",
            "  1.11090000e+04 1.00000000e+01]\n",
            " [1.64464863e+02 3.03000000e+02 9.00000000e+00 2.80000000e+01\n",
            "  1.33950000e+04 2.00000000e+00]\n",
            " [9.34162188e+01 3.00000000e+02 8.20000000e+01 3.00000000e+00\n",
            "  8.41200000e+03 3.00000000e+00]\n",
            " [1.65249988e+02 2.23000000e+02 9.00000000e+00 1.20000000e+01\n",
            "  1.31310000e+04 2.00000000e+00]\n",
            " [1.06606475e+02 3.01000000e+02 9.90000000e+01 1.30000000e+01\n",
            "  1.03780000e+04 2.00000000e+00]\n",
            " [5.25190688e+01 1.37000000e+02 6.39000000e+02 1.00000000e+00\n",
            "  3.23400000e+03 9.00000000e+00]\n",
            " [8.50564313e+01 2.73000000e+02 1.79000000e+02 2.00000000e+00\n",
            "  7.38200000e+03 2.00000000e+00]\n",
            " [1.63225088e+02 2.31000000e+02 2.50000000e+01 3.70000000e+01\n",
            "  1.33940000e+04 2.00000000e+00]\n",
            " [1.56220188e+02 3.12000000e+02 1.60000000e+01 4.00000000e+00\n",
            "  1.28460000e+04 1.80000000e+01]\n",
            " [1.32932038e+02 3.16000000e+02 2.80000000e+01 5.00000000e+00\n",
            "  1.16220000e+04 3.00000000e+00]\n",
            " [1.42101775e+02 2.48000000e+02 7.60000000e+01 8.00000000e+00\n",
            "  1.24750000e+04 2.30000000e+01]\n",
            " [1.50637144e+02 2.87000000e+02 2.70000000e+01 1.80000000e+01\n",
            "  1.30330000e+04 2.30000000e+01]\n",
            " [1.13147450e+02 3.04000000e+02 9.20000000e+01 7.00000000e+00\n",
            "  1.10680000e+04 1.20000000e+01]\n",
            " [8.50564313e+01 2.73000000e+02 1.79000000e+02 2.00000000e+00\n",
            "  7.38200000e+03 2.00000000e+00]\n",
            " [1.03034825e+02 3.29000000e+02 5.30000000e+01 4.30000000e+01\n",
            "  9.48100000e+03 2.00000000e+00]\n",
            " [6.85795813e+01 1.61000000e+02 5.64000000e+02 1.00000000e+00\n",
            "  6.00400000e+03 2.00000000e+01]\n",
            " [1.23340781e+02 3.50000000e+02 1.90000000e+01 9.00000000e+00\n",
            "  1.15970000e+04 9.00000000e+00]\n",
            " [1.60721331e+02 3.19000000e+02 9.00000000e+00 1.20000000e+01\n",
            "  1.30890000e+04 1.10000000e+01]\n",
            " [9.69959625e+01 1.84000000e+02 1.86000000e+02 3.00000000e+00\n",
            "  8.63700000e+03 7.00000000e+00]\n",
            " [9.45816938e+01 2.96000000e+02 4.21000000e+02 2.00000000e+00\n",
            "  9.20100000e+03 5.00000000e+00]\n",
            " [1.61389094e+02 3.21000000e+02 1.40000000e+01 1.10000000e+01\n",
            "  1.29640000e+04 9.00000000e+00]\n",
            " [8.85318875e+01 2.96000000e+02 3.69000000e+02 1.00000000e+00\n",
            "  7.70800000e+03 6.00000000e+00]\n",
            " [1.16864663e+02 3.19000000e+02 4.70000000e+01 1.10000000e+01\n",
            "  1.12000000e+04 3.20000000e+01]\n",
            " [1.01178656e+02 3.58000000e+02 9.40000000e+01 2.60000000e+01\n",
            "  9.60900000e+03 7.00000000e+00]\n",
            " [1.58397981e+02 3.33000000e+02 1.80000000e+01 1.90000000e+01\n",
            "  1.33270000e+04 2.80000000e+01]\n",
            " [1.32476731e+02 2.52000000e+02 2.70000000e+01 1.40000000e+01\n",
            "  1.19960000e+04 1.30000000e+01]\n",
            " [1.65114969e+02 2.84000000e+02 5.00000000e+00 2.40000000e+01\n",
            "  1.33140000e+04 6.00000000e+00]\n",
            " [3.93339000e+01 2.83000000e+02 8.77000000e+02 1.00000000e+00\n",
            "  1.16700000e+03 3.50000000e+01]\n",
            " [1.48075688e+02 3.15000000e+02 1.80000000e+01 2.10000000e+01\n",
            "  1.26950000e+04 2.00000000e+00]\n",
            " [6.04315500e+01 2.73000000e+02 7.70000000e+02 4.00000000e+00\n",
            "  4.24300000e+03 9.40000000e+01]\n",
            " [9.80891750e+01 2.93000000e+02 3.10000000e+01 3.00000000e+01\n",
            "  9.35900000e+03 1.10000000e+01]\n",
            " [1.16390419e+02 2.54000000e+02 1.15000000e+02 6.00000000e+00\n",
            "  1.09000000e+04 6.00000000e+00]\n",
            " [9.69959625e+01 1.84000000e+02 1.86000000e+02 6.00000000e+00\n",
            "  8.57400000e+03 1.30000000e+01]\n",
            " [1.48717713e+02 2.31000000e+02 1.30000000e+01 6.00000000e+00\n",
            "  1.21070000e+04 1.30000000e+01]\n",
            " [1.16864663e+02 3.19000000e+02 4.70000000e+01 1.10000000e+01\n",
            "  1.12000000e+04 3.20000000e+01]\n",
            " [1.14294381e+02 2.96000000e+02 1.80000000e+01 4.00000000e+00\n",
            "  1.01970000e+04 6.00000000e+00]\n",
            " [1.07102900e+02 2.16000000e+02 1.06000000e+02 3.00000000e+00\n",
            "  9.96800000e+03 1.50000000e+01]\n",
            " [1.55853163e+02 3.04000000e+02 2.90000000e+01 2.40000000e+01\n",
            "  1.32770000e+04 4.20000000e+01]\n",
            " [1.58035456e+02 3.24000000e+02 8.00000000e+00 9.00000000e+00\n",
            "  1.28120000e+04 1.10000000e+01]\n",
            " [7.84003563e+01 2.97000000e+02 6.41000000e+02 3.00000000e+00\n",
            "  6.69300000e+03 1.30000000e+01]\n",
            " [1.43668000e+02 3.48000000e+02 1.10000000e+01 1.40000000e+01\n",
            "  1.23550000e+04 3.00000000e+00]\n",
            " [1.27597219e+02 2.99000000e+02 2.60000000e+01 1.50000000e+01\n",
            "  1.12790000e+04 2.00000000e+00]\n",
            " [6.66100438e+01 2.45000000e+02 6.06000000e+02 4.00000000e+00\n",
            "  4.79300000e+03 4.00000000e+00]\n",
            " [5.84451750e+01 1.63000000e+02 4.57000000e+02 1.00000000e+00\n",
            "  3.66400000e+03 2.20000000e+01]\n",
            " [1.55590181e+02 2.50000000e+02 1.50000000e+01 1.50000000e+01\n",
            "  1.29490000e+04 1.00000000e+01]\n",
            " [1.14495081e+02 3.21000000e+02 2.80000000e+01 1.30000000e+01\n",
            "  1.10070000e+04 2.00000000e+00]\n",
            " [1.58397981e+02 3.33000000e+02 1.80000000e+01 1.90000000e+01\n",
            "  1.33270000e+04 2.80000000e+01]\n",
            " [1.14495081e+02 3.21000000e+02 2.80000000e+01 1.10000000e+01\n",
            "  1.10370000e+04 5.00000000e+00]\n",
            " [1.19113238e+02 3.32000000e+02 1.80000000e+01 1.60000000e+01\n",
            "  1.07310000e+04 2.00000000e+00]\n",
            " [9.69959625e+01 1.84000000e+02 1.86000000e+02 6.00000000e+00\n",
            "  8.57400000e+03 1.30000000e+01]\n",
            " [6.80904250e+01 2.81000000e+02 7.28000000e+02 5.00000000e+00\n",
            "  4.55600000e+03 2.90000000e+01]\n",
            " [1.09499425e+02 3.42000000e+02 7.00000000e+00 1.80000000e+01\n",
            "  1.02550000e+04 1.40000000e+01]\n",
            " [1.51004606e+02 2.68000000e+02 3.80000000e+01 7.00000000e+00\n",
            "  1.24430000e+04 2.00000000e+00]\n",
            " [1.55590181e+02 2.50000000e+02 1.50000000e+01 1.50000000e+01\n",
            "  1.29490000e+04 1.00000000e+01]\n",
            " [1.24809775e+02 3.02000000e+02 1.60000000e+01 2.00000000e+01\n",
            "  1.15010000e+04 1.30000000e+01]\n",
            " [1.08968925e+02 2.14000000e+02 9.30000000e+01 6.00000000e+00\n",
            "  9.96400000e+03 1.20000000e+01]\n",
            " [8.00765625e+01 2.72000000e+02 2.00000000e+02 1.00000000e+00\n",
            "  6.83000000e+03 2.20000000e+01]\n",
            " [1.60580588e+02 2.18000000e+02 1.00000000e+01 9.00000000e+00\n",
            "  1.27350000e+04 1.00000000e+01]\n",
            " [1.16048456e+02 2.67000000e+02 5.70000000e+01 4.00000000e+00\n",
            "  1.09830000e+04 2.00000000e+00]\n",
            " [1.58073300e+02 2.71000000e+02 2.20000000e+01 2.70000000e+01\n",
            "  1.29240000e+04 2.00000000e+00]\n",
            " [1.32150025e+02 2.73000000e+02 3.30000000e+01 2.60000000e+01\n",
            "  1.17970000e+04 3.00000000e+00]\n",
            " [1.25098813e+02 3.04000000e+02 1.80000000e+01 8.00000000e+00\n",
            "  1.13510000e+04 2.00000000e+00]\n",
            " [7.77065563e+01 3.07000000e+02 6.50000000e+02 2.00000000e+00\n",
            "  6.90600000e+03 3.00000000e+00]\n",
            " [5.25190688e+01 1.37000000e+02 6.39000000e+02 1.00000000e+00\n",
            "  3.23400000e+03 9.00000000e+00]\n",
            " [1.16725913e+02 2.59000000e+02 3.40000000e+01 7.00000000e+00\n",
            "  1.05260000e+04 2.00000000e+00]\n",
            " [4.70643688e+01 2.32000000e+02 8.53000000e+02 1.00000000e+00\n",
            "  2.00500000e+03 3.20000000e+01]\n",
            " [1.47875594e+02 2.63000000e+02 1.20000000e+01 9.00000000e+00\n",
            "  1.25010000e+04 4.00000000e+00]\n",
            " [1.38174300e+02 2.66000000e+02 1.02000000e+02 1.00000000e+01\n",
            "  1.24860000e+04 6.00000000e+00]\n",
            " [7.99522438e+01 1.39000000e+02 3.83000000e+02 2.00000000e+00\n",
            "  6.35100000e+03 5.00000000e+00]\n",
            " [9.40306563e+01 2.89000000e+02 3.66000000e+02 2.00000000e+00\n",
            "  8.62100000e+03 2.00000000e+00]\n",
            " [1.50406694e+02 2.79000000e+02 1.40000000e+01 2.00000000e+01\n",
            "  1.29650000e+04 2.00000000e+01]\n",
            " [1.23541613e+02 3.32000000e+02 2.40000000e+01 9.00000000e+00\n",
            "  1.15230000e+04 4.00000000e+00]\n",
            " [1.51194731e+02 2.82000000e+02 1.40000000e+01 3.10000000e+01\n",
            "  1.28680000e+04 7.00000000e+00]\n",
            " [1.52988350e+02 3.22000000e+02 1.70000000e+01 2.20000000e+01\n",
            "  1.23330000e+04 8.00000000e+00]\n",
            " [1.35712306e+02 2.93000000e+02 1.70000000e+01 5.00000000e+00\n",
            "  1.20280000e+04 2.10000000e+01]\n",
            " [1.16725913e+02 2.59000000e+02 3.40000000e+01 8.00000000e+00\n",
            "  1.05140000e+04 2.00000000e+00]\n",
            " [1.27476244e+02 3.50000000e+02 3.50000000e+01 8.00000000e+00\n",
            "  1.12200000e+04 1.40000000e+01]\n",
            " [1.47347588e+02 2.36000000e+02 3.40000000e+01 2.60000000e+01\n",
            "  1.21790000e+04 3.00000000e+00]\n",
            " [9.76434688e+01 3.03000000e+02 1.91000000e+02 1.00000000e+00\n",
            "  8.44600000e+03 4.00000000e+00]\n",
            " [1.00362606e+02 3.93000000e+02 4.70000000e+01 8.00000000e+00\n",
            "  9.47200000e+03 1.20000000e+01]\n",
            " [1.09180481e+02 3.06000000e+02 4.80000000e+01 7.00000000e+00\n",
            "  1.03100000e+04 1.60000000e+01]\n",
            " [1.00362606e+02 3.93000000e+02 4.70000000e+01 8.00000000e+00\n",
            "  9.47200000e+03 1.20000000e+01]\n",
            " [5.84451750e+01 1.63000000e+02 4.57000000e+02 1.00000000e+00\n",
            "  3.66400000e+03 2.20000000e+01]\n",
            " [1.25098813e+02 3.04000000e+02 1.80000000e+01 8.00000000e+00\n",
            "  1.13510000e+04 2.00000000e+00]\n",
            " [5.41573563e+01 1.14000000e+02 4.82000000e+02 7.00000000e+00\n",
            "  3.51100000e+03 3.00000000e+00]\n",
            " [9.85357938e+01 1.52000000e+02 2.25000000e+02 2.00000000e+00\n",
            "  8.42500000e+03 1.60000000e+01]\n",
            " [1.63842081e+02 2.83000000e+02 2.00000000e+01 1.60000000e+01\n",
            "  1.33190000e+04 2.00000000e+01]\n",
            " [5.41573563e+01 1.14000000e+02 4.82000000e+02 5.00000000e+00\n",
            "  3.51200000e+03 5.00000000e+00]\n",
            " [1.30349081e+02 3.29000000e+02 3.20000000e+01 5.00000000e+00\n",
            "  1.13120000e+04 9.00000000e+00]\n",
            " [1.09471650e+02 1.74000000e+02 7.10000000e+01 5.00000000e+00\n",
            "  9.21500000e+03 9.00000000e+00]\n",
            " [6.85795813e+01 1.61000000e+02 5.64000000e+02 1.00000000e+00\n",
            "  6.00400000e+03 2.00000000e+01]\n",
            " [1.65114969e+02 2.84000000e+02 5.00000000e+00 2.40000000e+01\n",
            "  1.33140000e+04 6.00000000e+00]\n",
            " [7.77065563e+01 3.07000000e+02 6.50000000e+02 1.00000000e+00\n",
            "  6.90000000e+03 2.00000000e+00]\n",
            " [1.18457531e+02 2.69000000e+02 9.60000000e+01 1.30000000e+01\n",
            "  1.16940000e+04 4.00000000e+00]\n",
            " [5.21191813e+01 2.96000000e+02 9.10000000e+02 1.00000000e+00\n",
            "  2.97300000e+03 1.80000000e+01]\n",
            " [9.09995125e+01 2.55000000e+02 1.07000000e+02 1.00000000e+00\n",
            "  8.06400000e+03 1.70000000e+01]]\n",
            "480\n",
            "120\n",
            "480\n",
            "120\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset1 = pd.read_csv('neudefect2.csv')\n",
        "print(dataset1)\n",
        "\n",
        "x = dataset1.iloc[:,:-1].values\n",
        "print(len(x[0]))\n",
        "\n",
        "y = list()\n",
        "\n",
        "\n",
        "print(x[0])\n",
        "print(x[499])\n",
        "\n",
        "\n",
        "random.shuffle(x)\n",
        "print(x[0])\n",
        "print(x[499])\n",
        "\n",
        "for i in x:\n",
        "    x_new.append(i)\n",
        "\n",
        "\n",
        "for i in range(0,600):\n",
        "    y.append(1)\n",
        "    y_new.append(1)\n",
        "\n",
        "\n",
        "X_train_new, X_test_new, y_train_new, y_test_new = train_test_split( x, y, test_size=0.2, random_state=4)\n",
        "print(X_test_new)\n",
        "\n",
        "for i in X_train_new :\n",
        "    X_train.append(i)\n",
        "\n",
        "for i in X_test_new :\n",
        "    X_test.append(i)\n",
        "\n",
        "for i in y_train_new :\n",
        "    y_train.append(i)\n",
        "\n",
        "for i in y_test_new :\n",
        "    y_test.append(i)\n",
        "\n",
        "print(len(X_train))\n",
        "print(len(X_test))\n",
        "print(len(y_train))\n",
        "print(len(y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mbYSc3wNmSvV",
        "outputId": "5bdeaa28-4222-4511-affd-93aaab1bcb75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       energy  dots  lines  contours  edges  corner   \n",
            "0    4.118869    66      9         1     21      98   \n",
            "1    4.118869    66      9         1     21      84   \n",
            "2    4.024788    53      8         1     21      87   \n",
            "3    4.024788    53      8         1     21      85   \n",
            "4    3.838606    41    295         1      0     110   \n",
            "..        ...   ...    ...       ...    ...     ... ..\n",
            "595  3.103481    78     16         1      0     194   \n",
            "596  2.751100    88    319         1      0     187   \n",
            "597  2.751100    88    319         1      0     155   \n",
            "598  2.689631   107    415         1      0     139   \n",
            "599  2.689631   107    415         2      0     149   \n",
            "\n",
            "[600 rows x 7 columns]\n",
            "6\n",
            "[ 4.11886875 66.          9.          1.         21.         98.        ]\n",
            "[ 4.3154375 94.        39.         1.         0.        66.       ]\n",
            "[ 4.11886875 66.          9.          1.         21.         98.        ]\n",
            "[  2.5119375  80.        342.          1.          0.        113.       ]\n",
            "[[  2.423525    92.         386.           1.           0.\n",
            "   65.        ]\n",
            " [  6.00263125  39.           0.           1.         128.\n",
            "   16.        ]\n",
            " [  3.6318625   68.           2.           1.           0.\n",
            "   94.        ]\n",
            " [  4.06584375 206.           0.           4.           0.\n",
            "  101.        ]\n",
            " [  2.5283875   60.         338.           5.           0.\n",
            "  117.        ]\n",
            " [  1.534175    91.         507.           1.           0.\n",
            "  197.        ]\n",
            " [  4.71388125 159.           0.           6.           0.\n",
            "  138.        ]\n",
            " [  3.38574375  64.         292.           1.           0.\n",
            "   84.        ]\n",
            " [  4.59048125  80.          12.           3.           0.\n",
            "  163.        ]\n",
            " [  2.782475    75.          36.           1.           0.\n",
            "  218.        ]\n",
            " [  4.11886875  66.           9.           1.          21.\n",
            "   84.        ]\n",
            " [  3.63565625  32.         354.           3.           0.\n",
            "  148.        ]\n",
            " [  4.68725625 133.           2.           1.           0.\n",
            "  188.        ]\n",
            " [  2.3873      87.         390.           2.           0.\n",
            "  169.        ]\n",
            " [  6.20978125  84.           7.           1.           0.\n",
            "   97.        ]\n",
            " [  1.69934375  99.         428.           1.           0.\n",
            "  114.        ]\n",
            " [  3.8039875  129.           0.           1.           0.\n",
            "  116.        ]\n",
            " [  5.90603125  37.          53.           1.           0.\n",
            "    5.        ]\n",
            " [  4.2491375   64.          41.           1.           0.\n",
            "   41.        ]\n",
            " [  2.7296      52.          56.           1.           0.\n",
            "  300.        ]\n",
            " [  2.5119375   80.         342.           1.           0.\n",
            "   97.        ]\n",
            " [  2.00596875  81.         332.           1.           0.\n",
            "  124.        ]\n",
            " [  4.9879     117.           0.           1.           0.\n",
            "   87.        ]\n",
            " [  4.070525   112.          63.           1.           0.\n",
            "  152.        ]\n",
            " [  3.33391875  59.          31.           1.           0.\n",
            "   17.        ]\n",
            " [  4.6727125  172.           0.           2.           0.\n",
            "  103.        ]\n",
            " [  2.32354375 119.         303.           1.           0.\n",
            "  134.        ]\n",
            " [  3.2594625   96.         261.           1.           0.\n",
            "  144.        ]\n",
            " [  5.7533375   22.           0.           1.           0.\n",
            "   15.        ]\n",
            " [  3.457725   121.           0.           1.           0.\n",
            "  189.        ]\n",
            " [  6.00263125  39.           0.           1.         128.\n",
            "   47.        ]\n",
            " [  1.1828625   44.           1.           1.           0.\n",
            "   50.        ]\n",
            " [  3.12415625  35.         230.           1.           0.\n",
            "   55.        ]\n",
            " [  3.83860625  41.         295.           1.           0.\n",
            "  110.        ]\n",
            " [  1.25380625  56.          76.           1.           0.\n",
            "  180.        ]\n",
            " [  3.9572125   69.          99.           1.           0.\n",
            "   24.        ]\n",
            " [  3.9572125   69.          99.           1.           0.\n",
            "   24.        ]\n",
            " [  3.64945    171.           6.           1.           0.\n",
            "  124.        ]\n",
            " [  4.932875    86.           0.           2.           0.\n",
            "  186.        ]\n",
            " [  3.68334375 101.          19.           2.           0.\n",
            "  168.        ]\n",
            " [  4.0661875   95.          90.           1.           0.\n",
            "   87.        ]\n",
            " [  3.83860625  41.         295.           1.           0.\n",
            "  110.        ]\n",
            " [  3.94920625 153.           0.           3.           0.\n",
            "  188.        ]\n",
            " [  3.3665625   57.         160.           5.           0.\n",
            "    7.        ]\n",
            " [  4.87065    196.           0.           1.           0.\n",
            "  142.        ]\n",
            " [  3.9572125   69.          99.           1.           0.\n",
            "   24.        ]\n",
            " [  4.65568125  52.          53.           1.           0.\n",
            "    8.        ]\n",
            " [  4.65568125  52.          53.           1.           0.\n",
            "    8.        ]\n",
            " [  1.85239375  70.         439.           2.           0.\n",
            "  136.        ]\n",
            " [  1.6776625  114.         343.           2.           0.\n",
            "  145.        ]\n",
            " [  6.7841125   49.           0.           1.         160.\n",
            "   43.        ]\n",
            " [  1.81743125  72.         361.           2.           0.\n",
            "  238.        ]\n",
            " [  4.2491375   64.          41.           1.           0.\n",
            "   22.        ]\n",
            " [  4.2491375   64.          41.           1.           0.\n",
            "   41.        ]\n",
            " [  2.3873      87.         390.           2.           0.\n",
            "  169.        ]\n",
            " [  3.457725   121.           0.           1.           0.\n",
            "  129.        ]\n",
            " [  4.11886875  66.           9.           1.          21.\n",
            "   98.        ]\n",
            " [  4.2063      88.           0.           1.           0.\n",
            "  136.        ]\n",
            " [  6.1887375   82.          20.           1.           0.\n",
            "  108.        ]\n",
            " [  6.00263125  39.           0.           1.         128.\n",
            "   47.        ]\n",
            " [  2.1044375  100.         327.           2.           0.\n",
            "  175.        ]\n",
            " [  4.15184375 105.          56.           1.           0.\n",
            "  103.        ]\n",
            " [  2.5283875   60.         338.           5.           0.\n",
            "  117.        ]\n",
            " [  3.4839875   99.           7.           2.           0.\n",
            "  111.        ]\n",
            " [  1.87693125  87.         376.           1.           0.\n",
            "  134.        ]\n",
            " [  3.01651875 109.           0.           3.           0.\n",
            "  148.        ]\n",
            " [  3.68334375 101.          19.           2.           0.\n",
            "  168.        ]\n",
            " [  4.65568125  52.          53.           1.           0.\n",
            "    8.        ]\n",
            " [  4.75236875  97.          10.           1.           0.\n",
            "   86.        ]\n",
            " [  3.59400625  26.          12.           1.           0.\n",
            "   65.        ]\n",
            " [  3.64945    171.           6.           1.           0.\n",
            "  124.        ]\n",
            " [  2.66284375  92.          78.           1.           0.\n",
            "  199.        ]\n",
            " [  2.32354375 119.         303.           1.           0.\n",
            "  124.        ]\n",
            " [  4.0247875   53.           8.           1.          21.\n",
            "   87.        ]\n",
            " [  4.68725625 133.           2.           1.           0.\n",
            "  200.        ]\n",
            " [  1.7603375   90.         313.           1.           0.\n",
            "  124.        ]\n",
            " [  4.43145625  14.           0.           1.           0.\n",
            "   20.        ]\n",
            " [  1.7133125   66.         314.           1.           0.\n",
            "  186.        ]\n",
            " [  5.88845    109.           0.           1.           0.\n",
            "   88.        ]\n",
            " [  1.521625   109.         367.           1.           0.\n",
            "  138.        ]\n",
            " [  9.2509625   66.           0.           2.         282.\n",
            "   11.        ]\n",
            " [  2.74875625  47.         322.           2.           0.\n",
            "  163.        ]\n",
            " [  3.6921875  143.           0.           3.           0.\n",
            "  176.        ]\n",
            " [  4.11886875  66.           9.           1.          21.\n",
            "   84.        ]\n",
            " [  1.69934375  99.         428.           1.           0.\n",
            "  119.        ]\n",
            " [  7.9683625   56.           0.           1.         348.\n",
            "    4.        ]\n",
            " [  3.6921875  143.           0.           2.           0.\n",
            "  170.        ]\n",
            " [  6.1887375   82.          20.           1.           0.\n",
            "  105.        ]\n",
            " [  5.2190125  102.           6.           1.           0.\n",
            "  122.        ]\n",
            " [  2.48285     69.         274.           1.           0.\n",
            "  182.        ]\n",
            " [  4.070525   112.          63.           1.           0.\n",
            "  149.        ]\n",
            " [  2.13575625  66.         395.           2.           0.\n",
            "  195.        ]\n",
            " [  2.9641875   78.         186.           1.           0.\n",
            "  140.        ]\n",
            " [  2.3873      87.         390.           1.           0.\n",
            "  218.        ]\n",
            " [  3.79701875 156.           6.           1.           0.\n",
            "   87.        ]\n",
            " [  3.68334375 101.          19.           2.           0.\n",
            "  187.        ]\n",
            " [  4.9804875   31.          54.           1.           0.\n",
            "    5.        ]\n",
            " [  3.48475625 153.           9.           2.           0.\n",
            "  141.        ]\n",
            " [  1.8013625  102.         294.           1.           0.\n",
            "  123.        ]\n",
            " [  1.85239375  70.         439.           2.           0.\n",
            "  136.        ]\n",
            " [  5.3443375  101.           0.           3.           0.\n",
            "   92.        ]\n",
            " [  2.205325    70.         375.           2.           0.\n",
            "  155.        ]\n",
            " [  3.485525    70.         341.           1.           0.\n",
            "   80.        ]\n",
            " [  4.0307875   66.          12.           3.           0.\n",
            "  175.        ]\n",
            " [  4.0247875   53.           8.           1.          21.\n",
            "   87.        ]\n",
            " [  6.00263125  39.           0.           1.         128.\n",
            "   16.        ]\n",
            " [  4.070525   112.          63.           1.           0.\n",
            "  152.        ]\n",
            " [  5.2190125  102.           6.           1.           0.\n",
            "  116.        ]\n",
            " [  1.879625    79.         423.           1.           0.\n",
            "  170.        ]\n",
            " [  7.0844375   53.           3.           1.           0.\n",
            "  126.        ]\n",
            " [  4.87065    196.           0.           1.           0.\n",
            "  142.        ]\n",
            " [  4.0661875   95.          90.           1.           0.\n",
            "   87.        ]\n",
            " [  2.74875625  47.         322.           1.           0.\n",
            "  165.        ]\n",
            " [  5.41690625  60.          20.           1.           0.\n",
            "   28.        ]\n",
            " [  4.0247875   53.           8.           1.          21.\n",
            "   87.        ]\n",
            " [  3.86279375  99.          54.           1.           0.\n",
            "   50.        ]\n",
            " [  3.2100125   72.         171.           1.           0.\n",
            "  137.        ]\n",
            " [  2.66284375  92.          78.           1.           0.\n",
            "  199.        ]\n",
            " [  1.657       71.         313.           3.           0.\n",
            "  171.        ]\n",
            " [  4.27731875 197.           0.           1.           0.\n",
            "  112.        ]]\n",
            "960\n",
            "240\n",
            "960\n",
            "240\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset1 = pd.read_csv('neudefect3.csv')\n",
        "print(dataset1)\n",
        "\n",
        "x = dataset1.iloc[:,:-1].values\n",
        "print(len(x[0]))\n",
        "\n",
        "y = list()\n",
        "\n",
        "\n",
        "print(x[0])\n",
        "print(x[499])\n",
        "\n",
        "\n",
        "random.shuffle(x)\n",
        "print(x[0])\n",
        "print(x[499])\n",
        "\n",
        "\n",
        "for i in x:\n",
        "    x_new.append(i)\n",
        "\n",
        "for i in range(0,600):\n",
        "    y.append(2)\n",
        "    y_new.append(2)\n",
        "\n",
        "\n",
        "X_train_new, X_test_new, y_train_new, y_test_new = train_test_split( x, y, test_size=0.2, random_state=4)\n",
        "print(X_test_new)\n",
        "\n",
        "for i in X_train_new :\n",
        "    X_train.append(i)\n",
        "\n",
        "for i in X_test_new :\n",
        "    X_test.append(i)\n",
        "\n",
        "for i in y_train_new :\n",
        "    y_train.append(i)\n",
        "\n",
        "for i in y_test_new :\n",
        "    y_test.append(i)\n",
        "\n",
        "print(len(X_train))\n",
        "print(len(X_test))\n",
        "print(len(y_train))\n",
        "print(len(y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8StoAmXkjztv",
        "outputId": "c2b12424-21ab-4854-9c10-5eab913799ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         energy  dots  lines  contours  edges  corner   \n",
            "0    144.344288   134    130        38  11030      15   \n",
            "1    144.344288   134    130        35  11016      13   \n",
            "2    117.202019   184     99        11   9368      14   \n",
            "3    117.202019   184     99         5   9333      15   \n",
            "4     75.079475   101    215        18   5371      20   \n",
            "..          ...   ...    ...       ...    ...     ... ..\n",
            "595   15.830294   192     37         3      8     115   \n",
            "596   62.683950    27    118        27   4415       7   \n",
            "597   62.683950    27    118        27   4433      13   \n",
            "598   57.148769    47    223        50   4173      38   \n",
            "599   57.148769    47    223        53   4150      42   \n",
            "\n",
            "[600 rows x 7 columns]\n",
            "6\n",
            "[  144.3442875   134.          130.           38.        11030.\n",
            "    15.       ]\n",
            "[  99.93188125   51.          139.           57.         6801.\n",
            "   39.        ]\n",
            "[  144.3442875   134.          130.           38.        11030.\n",
            "    15.       ]\n",
            "[ 104.86659375  122.          165.           26.         8470.\n",
            "   21.        ]\n",
            "[[1.31207181e+02 9.80000000e+01 2.87000000e+02 5.70000000e+01\n",
            "  9.43200000e+03 3.80000000e+01]\n",
            " [4.27316188e+01 1.32000000e+02 5.31000000e+02 5.00000000e+00\n",
            "  2.24300000e+03 8.00000000e+00]\n",
            " [4.69435813e+01 6.70000000e+01 2.83000000e+02 1.50000000e+01\n",
            "  2.38400000e+03 6.00000000e+00]\n",
            " [1.00063781e+02 1.31000000e+02 1.73000000e+02 2.50000000e+01\n",
            "  7.76900000e+03 3.00000000e+00]\n",
            " [1.42717575e+02 1.57000000e+02 5.80000000e+01 1.00000000e+01\n",
            "  1.15490000e+04 9.00000000e+00]\n",
            " [1.28800469e+02 3.10000000e+01 1.13000000e+02 4.30000000e+01\n",
            "  1.04610000e+04 1.50000000e+01]\n",
            " [1.27418706e+02 7.30000000e+01 1.90000000e+02 8.20000000e+01\n",
            "  9.28100000e+03 5.60000000e+01]\n",
            " [8.04977188e+01 5.40000000e+01 1.06000000e+02 2.90000000e+01\n",
            "  6.55200000e+03 1.80000000e+01]\n",
            " [1.20487569e+02 6.40000000e+01 3.82000000e+02 1.02000000e+02\n",
            "  7.54700000e+03 5.40000000e+01]\n",
            " [7.92257688e+01 5.90000000e+01 2.39000000e+02 1.90000000e+01\n",
            "  6.22300000e+03 1.80000000e+01]\n",
            " [3.61493750e+01 9.10000000e+01 4.95000000e+02 4.00000000e+00\n",
            "  1.25300000e+03 1.10000000e+01]\n",
            " [1.17202019e+02 1.84000000e+02 9.90000000e+01 1.10000000e+01\n",
            "  9.36800000e+03 1.40000000e+01]\n",
            " [1.07008150e+02 5.80000000e+01 4.01000000e+02 9.70000000e+01\n",
            "  7.43000000e+03 3.50000000e+01]\n",
            " [1.15925769e+02 3.70000000e+01 2.04000000e+02 6.90000000e+01\n",
            "  8.67500000e+03 4.50000000e+01]\n",
            " [1.18745325e+02 8.50000000e+01 8.00000000e+01 3.10000000e+01\n",
            "  9.73800000e+03 1.70000000e+01]\n",
            " [8.04977188e+01 5.40000000e+01 1.06000000e+02 2.70000000e+01\n",
            "  6.55200000e+03 2.10000000e+01]\n",
            " [7.50794750e+01 1.01000000e+02 2.15000000e+02 1.80000000e+01\n",
            "  5.37100000e+03 2.00000000e+01]\n",
            " [1.15545219e+02 1.48000000e+02 8.40000000e+01 2.30000000e+01\n",
            "  9.24700000e+03 1.30000000e+01]\n",
            " [9.58483688e+01 2.80000000e+01 1.82000000e+02 5.60000000e+01\n",
            "  7.71400000e+03 3.20000000e+01]\n",
            " [7.75438188e+01 7.10000000e+01 3.75000000e+02 1.90000000e+01\n",
            "  5.10100000e+03 1.40000000e+01]\n",
            " [6.55518688e+01 8.80000000e+01 3.73000000e+02 2.80000000e+01\n",
            "  4.61800000e+03 1.80000000e+01]\n",
            " [2.41880000e+01 1.55000000e+02 4.53000000e+02 1.00000000e+00\n",
            "  1.28000000e+02 5.00000000e+00]\n",
            " [2.90244813e+01 8.60000000e+01 1.90000000e+02 1.20000000e+01\n",
            "  6.90000000e+02 7.00000000e+00]\n",
            " [5.09438375e+01 7.80000000e+01 4.96000000e+02 2.50000000e+01\n",
            "  2.72000000e+03 1.80000000e+01]\n",
            " [7.02115875e+01 9.40000000e+01 5.44000000e+02 1.80000000e+01\n",
            "  5.18500000e+03 5.00000000e+00]\n",
            " [9.83213500e+01 9.80000000e+01 3.00000000e+02 1.80000000e+01\n",
            "  7.71000000e+03 1.40000000e+01]\n",
            " [2.54514938e+01 9.30000000e+01 4.97000000e+02 1.00000000e+00\n",
            "  1.34000000e+02 8.00000000e+00]\n",
            " [8.45125813e+01 4.10000000e+01 2.15000000e+02 6.30000000e+01\n",
            "  6.55500000e+03 3.30000000e+01]\n",
            " [1.25612294e+02 8.80000000e+01 1.85000000e+02 8.90000000e+01\n",
            "  9.44400000e+03 2.90000000e+01]\n",
            " [8.04977188e+01 5.40000000e+01 1.06000000e+02 2.90000000e+01\n",
            "  6.55200000e+03 1.80000000e+01]\n",
            " [8.40179250e+01 1.26000000e+02 1.73000000e+02 1.90000000e+01\n",
            "  6.86700000e+03 1.50000000e+01]\n",
            " [1.02325081e+02 1.58000000e+02 8.10000000e+01 1.70000000e+01\n",
            "  8.09100000e+03 1.90000000e+01]\n",
            " [3.31692563e+01 1.19000000e+02 2.53000000e+02 1.00000000e+01\n",
            "  1.49700000e+03 9.00000000e+00]\n",
            " [3.08182750e+01 9.90000000e+01 3.68000000e+02 2.00000000e+00\n",
            "  7.45000000e+02 6.00000000e+00]\n",
            " [1.31991288e+02 1.23000000e+02 1.55000000e+02 9.20000000e+01\n",
            "  1.01890000e+04 1.70000000e+01]\n",
            " [4.69435813e+01 6.70000000e+01 2.83000000e+02 1.50000000e+01\n",
            "  2.38400000e+03 6.00000000e+00]\n",
            " [1.15925769e+02 3.70000000e+01 2.04000000e+02 6.80000000e+01\n",
            "  8.66500000e+03 4.10000000e+01]\n",
            " [1.21707625e+02 9.90000000e+01 2.73000000e+02 5.90000000e+01\n",
            "  8.37700000e+03 3.60000000e+01]\n",
            " [1.17202019e+02 1.84000000e+02 9.90000000e+01 1.10000000e+01\n",
            "  9.36800000e+03 1.40000000e+01]\n",
            " [1.24815656e+02 7.50000000e+01 2.51000000e+02 6.20000000e+01\n",
            "  8.76700000e+03 2.90000000e+01]\n",
            " [8.04977188e+01 5.40000000e+01 1.06000000e+02 2.70000000e+01\n",
            "  6.55200000e+03 2.10000000e+01]\n",
            " [7.25704188e+01 3.80000000e+01 1.34000000e+02 4.40000000e+01\n",
            "  5.62400000e+03 3.60000000e+01]\n",
            " [1.44344288e+02 1.34000000e+02 1.30000000e+02 3.50000000e+01\n",
            "  1.10160000e+04 1.30000000e+01]\n",
            " [1.21935094e+02 9.30000000e+01 3.25000000e+02 6.80000000e+01\n",
            "  9.60000000e+03 2.40000000e+01]\n",
            " [8.66874500e+01 9.50000000e+01 3.30000000e+02 2.90000000e+01\n",
            "  6.40700000e+03 1.40000000e+01]\n",
            " [7.52512000e+01 2.14000000e+02 2.69000000e+02 3.20000000e+01\n",
            "  4.77800000e+03 1.30000000e+01]\n",
            " [7.14687313e+01 8.70000000e+01 3.14000000e+02 1.90000000e+01\n",
            "  5.40100000e+03 1.40000000e+01]\n",
            " [1.35085169e+02 4.50000000e+01 9.20000000e+01 3.90000000e+01\n",
            "  1.04380000e+04 3.00000000e+01]\n",
            " [1.00063781e+02 1.31000000e+02 1.73000000e+02 2.00000000e+01\n",
            "  7.79300000e+03 3.00000000e+00]\n",
            " [1.04747219e+02 6.30000000e+01 2.23000000e+02 4.10000000e+01\n",
            "  6.82400000e+03 2.00000000e+01]\n",
            " [1.21935094e+02 9.30000000e+01 3.25000000e+02 6.50000000e+01\n",
            "  9.59700000e+03 2.20000000e+01]\n",
            " [4.62469313e+01 1.63000000e+02 6.11000000e+02 6.00000000e+00\n",
            "  1.89300000e+03 6.00000000e+00]\n",
            " [8.25261063e+01 5.30000000e+01 2.36000000e+02 4.40000000e+01\n",
            "  6.68100000e+03 3.10000000e+01]\n",
            " [7.85942563e+01 1.14000000e+02 8.30000000e+01 2.70000000e+01\n",
            "  5.57200000e+03 9.00000000e+00]\n",
            " [9.93242313e+01 3.80000000e+01 1.79000000e+02 6.60000000e+01\n",
            "  8.19300000e+03 5.60000000e+01]\n",
            " [1.24991519e+02 5.20000000e+01 3.53000000e+02 7.90000000e+01\n",
            "  9.00000000e+03 3.00000000e+01]\n",
            " [1.17202019e+02 1.84000000e+02 9.90000000e+01 1.10000000e+01\n",
            "  9.36800000e+03 1.40000000e+01]\n",
            " [1.08501975e+02 1.43000000e+02 5.90000000e+01 2.70000000e+01\n",
            "  8.26800000e+03 1.90000000e+01]\n",
            " [1.31185825e+02 1.53000000e+02 2.90000000e+01 1.10000000e+01\n",
            "  1.01100000e+04 1.10000000e+01]\n",
            " [3.81413250e+01 8.20000000e+01 4.39000000e+02 9.00000000e+00\n",
            "  1.71500000e+03 6.00000000e+00]\n",
            " [7.25704188e+01 3.80000000e+01 1.34000000e+02 4.70000000e+01\n",
            "  5.63100000e+03 3.60000000e+01]\n",
            " [7.20127500e+01 2.70000000e+01 2.39000000e+02 3.50000000e+01\n",
            "  5.81700000e+03 3.30000000e+01]\n",
            " [1.31292725e+02 3.00000000e+01 3.90000000e+01 3.00000000e+01\n",
            "  1.08000000e+04 3.80000000e+01]\n",
            " [1.06550950e+02 6.40000000e+01 2.06000000e+02 4.50000000e+01\n",
            "  8.82900000e+03 2.10000000e+01]\n",
            " [4.62469313e+01 1.63000000e+02 6.11000000e+02 6.00000000e+00\n",
            "  1.89300000e+03 6.00000000e+00]\n",
            " [9.02360375e+01 6.60000000e+01 3.23000000e+02 1.20000000e+01\n",
            "  6.28800000e+03 4.00000000e+00]\n",
            " [1.26116194e+02 8.90000000e+01 3.26000000e+02 7.70000000e+01\n",
            "  9.56700000e+03 2.70000000e+01]\n",
            " [9.38321188e+01 7.70000000e+01 1.92000000e+02 2.80000000e+01\n",
            "  7.96600000e+03 2.30000000e+01]\n",
            " [1.25429637e+02 3.20000000e+01 7.80000000e+01 2.30000000e+01\n",
            "  7.99300000e+03 2.80000000e+01]\n",
            " [1.22700725e+02 8.70000000e+01 2.96000000e+02 7.60000000e+01\n",
            "  9.06500000e+03 2.70000000e+01]\n",
            " [1.21707625e+02 9.90000000e+01 2.73000000e+02 5.80000000e+01\n",
            "  8.38600000e+03 3.40000000e+01]\n",
            " [5.44774188e+01 6.60000000e+01 2.77000000e+02 1.70000000e+01\n",
            "  3.46700000e+03 6.00000000e+00]\n",
            " [5.09438375e+01 7.80000000e+01 4.96000000e+02 2.90000000e+01\n",
            "  2.72200000e+03 2.00000000e+01]\n",
            " [1.44344288e+02 1.34000000e+02 1.30000000e+02 3.50000000e+01\n",
            "  1.10160000e+04 1.30000000e+01]\n",
            " [1.31185825e+02 1.53000000e+02 2.90000000e+01 1.10000000e+01\n",
            "  1.01100000e+04 1.10000000e+01]\n",
            " [1.22485925e+02 6.70000000e+01 3.29000000e+02 1.05000000e+02\n",
            "  9.13300000e+03 5.00000000e+01]\n",
            " [9.70783563e+01 1.38000000e+02 2.53000000e+02 4.40000000e+01\n",
            "  6.86700000e+03 2.10000000e+01]\n",
            " [8.80065125e+01 8.90000000e+01 2.45000000e+02 2.60000000e+01\n",
            "  6.00700000e+03 1.90000000e+01]\n",
            " [1.43455419e+02 7.90000000e+01 1.80000000e+02 5.50000000e+01\n",
            "  9.72500000e+03 3.30000000e+01]\n",
            " [9.38321188e+01 7.70000000e+01 1.92000000e+02 2.80000000e+01\n",
            "  7.96600000e+03 2.30000000e+01]\n",
            " [1.14329788e+02 7.40000000e+01 2.76000000e+02 4.10000000e+01\n",
            "  8.76000000e+03 4.00000000e+01]\n",
            " [2.54514938e+01 9.30000000e+01 4.97000000e+02 1.00000000e+00\n",
            "  1.34000000e+02 1.10000000e+01]\n",
            " [3.08182750e+01 9.90000000e+01 3.68000000e+02 2.00000000e+00\n",
            "  7.45000000e+02 7.00000000e+00]\n",
            " [1.33772881e+02 1.03000000e+02 2.04000000e+02 2.80000000e+01\n",
            "  1.01390000e+04 9.00000000e+00]\n",
            " [5.44774188e+01 6.60000000e+01 2.77000000e+02 1.70000000e+01\n",
            "  3.46700000e+03 6.00000000e+00]\n",
            " [1.20487569e+02 6.40000000e+01 3.82000000e+02 1.02000000e+02\n",
            "  7.54700000e+03 5.40000000e+01]\n",
            " [1.15705800e+02 5.40000000e+01 2.52000000e+02 5.80000000e+01\n",
            "  9.24200000e+03 2.50000000e+01]\n",
            " [1.18745325e+02 8.50000000e+01 8.00000000e+01 3.40000000e+01\n",
            "  9.73900000e+03 2.00000000e+01]\n",
            " [1.17202019e+02 1.84000000e+02 9.90000000e+01 1.10000000e+01\n",
            "  9.36800000e+03 1.40000000e+01]\n",
            " [1.36878225e+02 3.90000000e+01 2.81000000e+02 7.70000000e+01\n",
            "  9.50000000e+03 6.00000000e+01]\n",
            " [1.24815656e+02 7.50000000e+01 2.51000000e+02 6.20000000e+01\n",
            "  8.76700000e+03 2.90000000e+01]\n",
            " [1.00063781e+02 1.31000000e+02 1.73000000e+02 2.50000000e+01\n",
            "  7.76900000e+03 3.00000000e+00]\n",
            " [9.55021813e+01 3.80000000e+01 3.01000000e+02 7.20000000e+01\n",
            "  6.28000000e+03 2.60000000e+01]\n",
            " [1.07008150e+02 5.80000000e+01 4.01000000e+02 9.70000000e+01\n",
            "  7.43000000e+03 3.50000000e+01]\n",
            " [1.15545219e+02 1.48000000e+02 8.40000000e+01 1.70000000e+01\n",
            "  9.22600000e+03 1.00000000e+01]\n",
            " [2.06943313e+01 1.61000000e+02 3.39000000e+02 1.00000000e+00\n",
            "  8.00000000e+00 2.40000000e+01]\n",
            " [1.22700725e+02 8.70000000e+01 2.96000000e+02 7.60000000e+01\n",
            "  9.06500000e+03 2.70000000e+01]\n",
            " [1.07385613e+02 7.60000000e+01 2.34000000e+02 5.70000000e+01\n",
            "  8.05900000e+03 2.90000000e+01]\n",
            " [4.62469313e+01 1.63000000e+02 6.11000000e+02 7.00000000e+00\n",
            "  1.88800000e+03 6.00000000e+00]\n",
            " [1.05548688e+02 5.20000000e+01 3.05000000e+02 5.90000000e+01\n",
            "  8.31100000e+03 2.00000000e+01]\n",
            " [9.97662500e+01 1.56000000e+02 7.10000000e+01 2.10000000e+01\n",
            "  8.63800000e+03 1.00000000e+01]\n",
            " [2.30208125e+01 1.51000000e+02 2.86000000e+02 1.00000000e+00\n",
            "  1.94000000e+02 8.00000000e+00]\n",
            " [3.27126375e+01 2.22000000e+02 5.62000000e+02 2.00000000e+00\n",
            "  3.72000000e+02 6.00000000e+00]\n",
            " [7.98039625e+01 4.70000000e+01 1.64000000e+02 6.40000000e+01\n",
            "  6.47400000e+03 2.60000000e+01]\n",
            " [4.91683500e+01 1.53000000e+02 4.93000000e+02 1.60000000e+01\n",
            "  3.12000000e+03 1.90000000e+01]\n",
            " [1.30771375e+02 9.00000000e+01 2.27000000e+02 8.20000000e+01\n",
            "  1.03350000e+04 4.30000000e+01]\n",
            " [8.90125750e+01 8.70000000e+01 7.70000000e+01 1.70000000e+01\n",
            "  7.44900000e+03 2.20000000e+01]\n",
            " [5.23441313e+01 9.90000000e+01 4.32000000e+02 9.00000000e+00\n",
            "  3.65700000e+03 2.10000000e+01]\n",
            " [1.15545219e+02 1.48000000e+02 8.40000000e+01 2.30000000e+01\n",
            "  9.24700000e+03 1.30000000e+01]\n",
            " [3.84146125e+01 7.90000000e+01 2.93000000e+02 2.00000000e+00\n",
            "  1.90000000e+03 1.10000000e+01]\n",
            " [8.90125750e+01 8.70000000e+01 7.70000000e+01 1.90000000e+01\n",
            "  7.43800000e+03 2.20000000e+01]\n",
            " [1.23526750e+02 1.01000000e+02 1.07000000e+02 3.70000000e+01\n",
            "  1.00060000e+04 2.60000000e+01]\n",
            " [2.54514938e+01 9.30000000e+01 4.97000000e+02 1.00000000e+00\n",
            "  1.34000000e+02 8.00000000e+00]\n",
            " [6.15059688e+01 1.01000000e+02 3.04000000e+02 2.30000000e+01\n",
            "  4.57000000e+03 1.00000000e+01]\n",
            " [6.31853938e+01 4.90000000e+01 2.01000000e+02 6.40000000e+01\n",
            "  4.74100000e+03 3.80000000e+01]\n",
            " [5.76716125e+01 1.07000000e+02 4.97000000e+02 1.30000000e+01\n",
            "  3.46800000e+03 6.00000000e+00]\n",
            " [1.05732944e+02 9.30000000e+01 1.85000000e+02 4.90000000e+01\n",
            "  8.43600000e+03 2.80000000e+01]\n",
            " [4.56396750e+01 6.10000000e+01 2.61000000e+02 2.80000000e+01\n",
            "  3.27500000e+03 1.70000000e+01]\n",
            " [3.08182750e+01 9.90000000e+01 3.68000000e+02 2.00000000e+00\n",
            "  7.45000000e+02 6.00000000e+00]\n",
            " [1.21707625e+02 9.90000000e+01 2.73000000e+02 5.80000000e+01\n",
            "  8.38600000e+03 3.40000000e+01]]\n",
            "1440\n",
            "360\n",
            "1440\n",
            "360\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset1 = pd.read_csv('neudefect4.csv')\n",
        "print(dataset1)\n",
        "\n",
        "x = dataset1.iloc[:,:-1].values\n",
        "print(len(x[0]))\n",
        "\n",
        "y = list()\n",
        "\n",
        "\n",
        "print(x[0])\n",
        "print(x[499])\n",
        "\n",
        "for i in x:\n",
        "    x_new.append(i)\n",
        "\n",
        "random.shuffle(x)\n",
        "print(x[0])\n",
        "print(x[499])\n",
        "\n",
        "\n",
        "for i in range(0,600):\n",
        "    y.append(3)\n",
        "    y_new.append(3)\n",
        "\n",
        "\n",
        "X_train_new, X_test_new, y_train_new, y_test_new = train_test_split( x, y, test_size=0.2, random_state=4)\n",
        "print(X_test_new)\n",
        "\n",
        "for i in X_train_new :\n",
        "    X_train.append(i)\n",
        "\n",
        "for i in X_test_new :\n",
        "    X_test.append(i)\n",
        "\n",
        "for i in y_train_new :\n",
        "    y_train.append(i)\n",
        "\n",
        "for i in y_test_new :\n",
        "    y_test.append(i)\n",
        "\n",
        "print(len(X_train))\n",
        "print(len(X_test))\n",
        "print(len(y_train))\n",
        "print(len(y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dEDzeED2jzrk",
        "outputId": "0df0a482-3733-478d-9c6a-8c0f84e270fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        energy  dots  lines  contours  edges  corner   \n",
            "0     4.900825    45    218         1      0     145   \n",
            "1     4.900825    45    218         1      0      84   \n",
            "2     4.910156    14    115         1      0      38   \n",
            "3     4.910156    14    115         1      0      45   \n",
            "4    15.046094    86      0         1    784      50   \n",
            "..         ...   ...    ...       ...    ...     ... ..\n",
            "595   6.341663    49    140         2      0     105   \n",
            "596  16.225606   110      0         1    596       7   \n",
            "597  16.225606   110      0         1    596      10   \n",
            "598  15.959525   118      0         3    308       6   \n",
            "599  15.959525   118      0         2    307       6   \n",
            "\n",
            "[600 rows x 7 columns]\n",
            "6\n",
            "[  4.900825  45.       218.         1.         0.       145.      ]\n",
            "[14.232975 87.        0.        1.       66.       12.      ]\n",
            "[  4.900825  45.       218.         1.         0.       145.      ]\n",
            "[2.57401313e+01 1.18000000e+02 0.00000000e+00 1.00000000e+00\n",
            " 1.78100000e+03 5.00000000e+00]\n",
            "[[6.04887250e+01 1.17000000e+02 0.00000000e+00 1.00000000e+00\n",
            "  5.67200000e+03 1.00000000e+01]\n",
            " [3.30843000e+01 9.90000000e+01 0.00000000e+00 3.00000000e+00\n",
            "  2.22000000e+03 5.00000000e+00]\n",
            " [4.91015625e+00 1.40000000e+01 1.15000000e+02 1.00000000e+00\n",
            "  0.00000000e+00 3.80000000e+01]\n",
            " [3.24807313e+01 1.72000000e+02 0.00000000e+00 3.00000000e+00\n",
            "  3.72800000e+03 3.00000000e+00]\n",
            " [6.86332500e+00 2.90000000e+01 7.00000000e+00 1.00000000e+00\n",
            "  1.12000000e+02 7.00000000e+00]\n",
            " [3.69296563e+01 1.67000000e+02 0.00000000e+00 1.00000000e+00\n",
            "  3.50300000e+03 6.40000000e+01]\n",
            " [1.07682313e+01 8.00000000e+01 5.00000000e+00 1.00000000e+00\n",
            "  1.10000000e+02 1.41000000e+02]\n",
            " [8.43102500e+00 2.70000000e+01 0.00000000e+00 1.00000000e+00\n",
            "  0.00000000e+00 6.70000000e+01]\n",
            " [2.43172688e+01 9.00000000e+01 0.00000000e+00 1.00000000e+00\n",
            "  7.95000000e+02 6.60000000e+01]\n",
            " [4.91015625e+00 1.40000000e+01 1.15000000e+02 1.00000000e+00\n",
            "  0.00000000e+00 3.80000000e+01]\n",
            " [7.44656250e+00 3.30000000e+01 0.00000000e+00 1.00000000e+00\n",
            "  7.50000000e+01 9.10000000e+01]\n",
            " [1.84072500e+01 1.19000000e+02 0.00000000e+00 1.00000000e+00\n",
            "  1.14000000e+02 1.91000000e+02]\n",
            " [4.30878188e+01 1.55000000e+02 0.00000000e+00 1.00000000e+00\n",
            "  4.34200000e+03 4.80000000e+01]\n",
            " [4.91015625e+00 1.40000000e+01 1.15000000e+02 1.00000000e+00\n",
            "  0.00000000e+00 3.80000000e+01]\n",
            " [1.84072500e+01 1.19000000e+02 0.00000000e+00 1.00000000e+00\n",
            "  1.14000000e+02 1.91000000e+02]\n",
            " [2.11488250e+01 9.80000000e+01 0.00000000e+00 1.00000000e+00\n",
            "  3.84000000e+02 4.90000000e+01]\n",
            " [1.65389063e+01 1.04000000e+02 1.00000000e+00 1.00000000e+00\n",
            "  5.98000000e+02 1.76000000e+02]\n",
            " [8.10714375e+00 5.50000000e+01 6.30000000e+01 1.00000000e+00\n",
            "  1.30000000e+01 2.00000000e+00]\n",
            " [2.92566188e+01 2.38000000e+02 0.00000000e+00 1.00000000e+00\n",
            "  1.10400000e+03 1.48000000e+02]\n",
            " [1.49579813e+01 7.80000000e+01 0.00000000e+00 1.00000000e+00\n",
            "  6.77000000e+02 5.00000000e+00]\n",
            " [2.18569375e+01 1.10000000e+02 0.00000000e+00 1.00000000e+00\n",
            "  7.86000000e+02 1.10000000e+01]\n",
            " [1.75781813e+01 1.82000000e+02 0.00000000e+00 1.00000000e+00\n",
            "  7.81000000e+02 5.00000000e+00]\n",
            " [3.47946375e+01 2.43000000e+02 0.00000000e+00 1.00000000e+00\n",
            "  1.96600000e+03 1.78000000e+02]\n",
            " [4.71193125e+00 3.80000000e+01 7.90000000e+01 1.00000000e+00\n",
            "  0.00000000e+00 1.43000000e+02]\n",
            " [2.11488250e+01 9.80000000e+01 0.00000000e+00 1.00000000e+00\n",
            "  3.84000000e+02 7.90000000e+01]\n",
            " [1.25260813e+01 2.10000000e+01 0.00000000e+00 1.00000000e+00\n",
            "  2.45000000e+02 1.90000000e+01]\n",
            " [1.18998750e+01 3.60000000e+01 0.00000000e+00 1.00000000e+00\n",
            "  1.00000000e+01 3.30000000e+01]\n",
            " [5.49644875e+01 2.44000000e+02 0.00000000e+00 1.00000000e+00\n",
            "  5.40100000e+03 8.30000000e+01]\n",
            " [3.52742313e+01 2.80000000e+01 7.00000000e+00 4.00000000e+00\n",
            "  4.49300000e+03 2.20000000e+01]\n",
            " [6.81294375e+00 3.70000000e+01 0.00000000e+00 1.00000000e+00\n",
            "  0.00000000e+00 8.30000000e+01]\n",
            " [4.29760938e+01 2.33000000e+02 0.00000000e+00 1.00000000e+00\n",
            "  3.31500000e+03 1.95000000e+02]\n",
            " [1.31835938e+01 5.50000000e+01 0.00000000e+00 1.00000000e+00\n",
            "  6.50000000e+01 1.64000000e+02]\n",
            " [2.53780000e+00 3.00000000e+01 1.52000000e+02 1.00000000e+00\n",
            "  0.00000000e+00 2.25000000e+02]\n",
            " [2.53780000e+00 3.00000000e+01 1.52000000e+02 1.00000000e+00\n",
            "  0.00000000e+00 2.10000000e+02]\n",
            " [7.44656250e+00 3.30000000e+01 0.00000000e+00 1.00000000e+00\n",
            "  7.50000000e+01 8.80000000e+01]\n",
            " [4.54381875e+00 2.70000000e+01 1.05000000e+02 1.00000000e+00\n",
            "  1.70000000e+01 1.80000000e+01]\n",
            " [3.79547625e+01 9.80000000e+01 0.00000000e+00 1.00000000e+00\n",
            "  4.60700000e+03 9.00000000e+00]\n",
            " [1.63857063e+01 4.60000000e+01 1.17000000e+02 1.00000000e+00\n",
            "  1.42900000e+03 2.00000000e+00]\n",
            " [1.56923875e+01 1.09000000e+02 0.00000000e+00 2.00000000e+00\n",
            "  8.70000000e+02 5.00000000e+00]\n",
            " [4.54021188e+01 3.70000000e+01 0.00000000e+00 6.00000000e+00\n",
            "  4.57600000e+03 1.10000000e+01]\n",
            " [4.90082500e+00 4.50000000e+01 2.18000000e+02 1.00000000e+00\n",
            "  0.00000000e+00 1.45000000e+02]\n",
            " [5.69921563e+01 1.19000000e+02 2.30000000e+01 8.00000000e+00\n",
            "  8.85900000e+03 1.70000000e+01]\n",
            " [1.12116250e+01 5.20000000e+01 0.00000000e+00 1.00000000e+00\n",
            "  1.01000000e+02 7.00000000e+00]\n",
            " [9.02126875e+00 6.40000000e+01 0.00000000e+00 1.00000000e+00\n",
            "  0.00000000e+00 4.40000000e+01]\n",
            " [1.93805875e+01 7.70000000e+01 0.00000000e+00 1.00000000e+00\n",
            "  8.19000000e+02 1.74000000e+02]\n",
            " [7.44656250e+00 3.30000000e+01 0.00000000e+00 1.00000000e+00\n",
            "  7.50000000e+01 9.10000000e+01]\n",
            " [1.75781813e+01 1.82000000e+02 0.00000000e+00 1.00000000e+00\n",
            "  7.82000000e+02 6.00000000e+00]\n",
            " [6.43362500e+00 5.40000000e+01 1.30000000e+01 1.00000000e+00\n",
            "  0.00000000e+00 5.40000000e+01]\n",
            " [6.31137500e+00 3.10000000e+01 3.70000000e+01 1.00000000e+00\n",
            "  1.00000000e+01 1.77000000e+02]\n",
            " [1.17217000e+01 6.10000000e+01 1.18000000e+02 1.00000000e+00\n",
            "  5.10000000e+01 7.00000000e+00]\n",
            " [4.93446062e+01 8.30000000e+01 0.00000000e+00 5.00000000e+00\n",
            "  5.98600000e+03 2.30000000e+01]\n",
            " [1.84072500e+01 1.19000000e+02 0.00000000e+00 1.00000000e+00\n",
            "  1.14000000e+02 1.91000000e+02]\n",
            " [4.09297125e+01 2.10000000e+02 0.00000000e+00 1.00000000e+00\n",
            "  4.34500000e+03 1.20000000e+01]\n",
            " [5.66496813e+01 1.22000000e+02 0.00000000e+00 3.00000000e+00\n",
            "  8.44500000e+03 7.00000000e+00]\n",
            " [9.45091875e+00 4.70000000e+01 0.00000000e+00 1.00000000e+00\n",
            "  3.38000000e+02 1.32000000e+02]\n",
            " [3.57201438e+01 1.19000000e+02 0.00000000e+00 1.00000000e+00\n",
            "  3.89900000e+03 1.80000000e+01]\n",
            " [4.91015625e+00 1.40000000e+01 1.15000000e+02 1.00000000e+00\n",
            "  0.00000000e+00 4.50000000e+01]\n",
            " [1.00724625e+01 8.60000000e+01 1.00000000e+01 1.00000000e+00\n",
            "  1.41000000e+02 1.60000000e+02]\n",
            " [6.81294375e+00 3.70000000e+01 0.00000000e+00 1.00000000e+00\n",
            "  0.00000000e+00 8.30000000e+01]\n",
            " [3.36547125e+01 1.05000000e+02 0.00000000e+00 8.00000000e+00\n",
            "  3.22100000e+03 4.00000000e+00]\n",
            " [2.18569375e+01 1.10000000e+02 0.00000000e+00 1.00000000e+00\n",
            "  7.85000000e+02 1.70000000e+01]\n",
            " [5.41931250e+00 2.40000000e+01 0.00000000e+00 1.00000000e+00\n",
            "  2.15000000e+02 4.00000000e+00]\n",
            " [1.80103625e+01 3.00000000e+01 0.00000000e+00 4.00000000e+00\n",
            "  7.90000000e+02 1.50000000e+01]\n",
            " [9.86223750e+00 8.60000000e+01 0.00000000e+00 1.00000000e+00\n",
            "  4.67000000e+02 3.00000000e+00]\n",
            " [2.03548812e+01 9.70000000e+01 0.00000000e+00 1.00000000e+00\n",
            "  1.45900000e+03 2.00000000e+00]\n",
            " [6.28483125e+00 4.80000000e+01 1.48000000e+02 1.00000000e+00\n",
            "  0.00000000e+00 1.60000000e+02]\n",
            " [7.44656250e+00 3.30000000e+01 0.00000000e+00 1.00000000e+00\n",
            "  7.50000000e+01 9.10000000e+01]\n",
            " [1.65579375e+01 2.60000000e+01 0.00000000e+00 1.00000000e+00\n",
            "  8.35000000e+02 2.90000000e+01]\n",
            " [1.09455000e+01 3.80000000e+01 0.00000000e+00 1.00000000e+00\n",
            "  0.00000000e+00 1.03000000e+02]\n",
            " [6.86655000e+00 2.20000000e+01 0.00000000e+00 1.00000000e+00\n",
            "  1.04000000e+02 3.00000000e+00]\n",
            " [3.57201438e+01 1.19000000e+02 0.00000000e+00 1.00000000e+00\n",
            "  3.90200000e+03 7.00000000e+00]\n",
            " [5.40113938e+01 2.30000000e+02 0.00000000e+00 4.00000000e+00\n",
            "  7.10300000e+03 1.00000000e+01]\n",
            " [6.42735750e+01 1.09000000e+02 0.00000000e+00 8.00000000e+00\n",
            "  9.02900000e+03 1.50000000e+01]\n",
            " [4.91015625e+00 1.40000000e+01 1.15000000e+02 1.00000000e+00\n",
            "  0.00000000e+00 4.50000000e+01]\n",
            " [2.21592500e+00 2.30000000e+01 1.07000000e+02 1.00000000e+00\n",
            "  0.00000000e+00 6.10000000e+01]\n",
            " [4.30878188e+01 1.55000000e+02 0.00000000e+00 1.00000000e+00\n",
            "  4.35400000e+03 2.90000000e+01]\n",
            " [4.54021188e+01 3.70000000e+01 0.00000000e+00 5.00000000e+00\n",
            "  4.56800000e+03 1.20000000e+01]\n",
            " [4.57901813e+01 2.37000000e+02 0.00000000e+00 1.00000000e+00\n",
            "  3.59000000e+03 1.56000000e+02]\n",
            " [1.84072500e+01 1.19000000e+02 0.00000000e+00 1.00000000e+00\n",
            "  1.21000000e+02 1.39000000e+02]\n",
            " [2.32773750e+01 6.40000000e+01 1.10000000e+01 1.00000000e+00\n",
            "  1.80400000e+03 7.00000000e+00]\n",
            " [1.99235625e+00 2.30000000e+01 1.24000000e+02 1.00000000e+00\n",
            "  0.00000000e+00 9.20000000e+01]\n",
            " [2.00995188e+01 4.30000000e+01 0.00000000e+00 1.00000000e+00\n",
            "  7.89000000e+02 3.20000000e+01]\n",
            " [1.12116250e+01 5.20000000e+01 0.00000000e+00 1.00000000e+00\n",
            "  1.01000000e+02 1.00000000e+01]\n",
            " [1.47921875e+00 2.90000000e+01 9.50000000e+01 1.00000000e+00\n",
            "  0.00000000e+00 1.05000000e+02]\n",
            " [4.09297125e+01 2.10000000e+02 0.00000000e+00 1.00000000e+00\n",
            "  4.34500000e+03 1.20000000e+01]\n",
            " [6.13561813e+01 1.34000000e+02 1.50000000e+01 3.00000000e+00\n",
            "  9.56200000e+03 8.00000000e+00]\n",
            " [6.34820250e+01 1.25000000e+02 0.00000000e+00 7.00000000e+00\n",
            "  9.66700000e+03 1.90000000e+01]\n",
            " [6.28483125e+00 4.80000000e+01 1.48000000e+02 1.00000000e+00\n",
            "  0.00000000e+00 1.56000000e+02]\n",
            " [2.53780000e+00 3.00000000e+01 1.52000000e+02 1.00000000e+00\n",
            "  0.00000000e+00 2.25000000e+02]\n",
            " [1.77141625e+01 5.80000000e+01 0.00000000e+00 1.00000000e+00\n",
            "  9.76000000e+02 7.00000000e+00]\n",
            " [8.27537500e+00 5.10000000e+01 1.47000000e+02 1.00000000e+00\n",
            "  0.00000000e+00 1.07000000e+02]\n",
            " [2.18569375e+01 1.10000000e+02 0.00000000e+00 1.00000000e+00\n",
            "  7.86000000e+02 1.10000000e+01]\n",
            " [1.84072500e+01 1.19000000e+02 0.00000000e+00 1.00000000e+00\n",
            "  1.21000000e+02 1.39000000e+02]\n",
            " [5.40113938e+01 2.30000000e+02 0.00000000e+00 3.00000000e+00\n",
            "  7.12200000e+03 1.00000000e+01]\n",
            " [5.29541875e+00 2.40000000e+01 1.03000000e+02 1.00000000e+00\n",
            "  0.00000000e+00 3.60000000e+01]\n",
            " [4.71193125e+00 3.80000000e+01 7.90000000e+01 1.00000000e+00\n",
            "  0.00000000e+00 1.43000000e+02]\n",
            " [6.28483125e+00 4.80000000e+01 1.48000000e+02 1.00000000e+00\n",
            "  0.00000000e+00 1.56000000e+02]\n",
            " [2.32773750e+01 6.40000000e+01 1.10000000e+01 1.00000000e+00\n",
            "  1.80400000e+03 7.00000000e+00]\n",
            " [4.23777500e+00 4.70000000e+01 1.74000000e+02 2.00000000e+00\n",
            "  3.30000000e+01 1.70000000e+02]\n",
            " [1.63856563e+01 5.80000000e+01 0.00000000e+00 1.00000000e+00\n",
            "  2.89000000e+02 2.00000000e+00]\n",
            " [1.07682313e+01 8.00000000e+01 5.00000000e+00 1.00000000e+00\n",
            "  1.04000000e+02 1.87000000e+02]\n",
            " [1.32402250e+01 1.11000000e+02 0.00000000e+00 1.00000000e+00\n",
            "  4.75000000e+02 1.80000000e+01]\n",
            " [1.31835938e+01 5.50000000e+01 0.00000000e+00 1.00000000e+00\n",
            "  6.50000000e+01 1.26000000e+02]\n",
            " [1.09455000e+01 3.80000000e+01 0.00000000e+00 1.00000000e+00\n",
            "  0.00000000e+00 1.03000000e+02]\n",
            " [2.32773750e+01 6.40000000e+01 1.10000000e+01 1.00000000e+00\n",
            "  1.80400000e+03 5.00000000e+00]\n",
            " [3.39950625e+01 1.65000000e+02 0.00000000e+00 3.00000000e+00\n",
            "  3.12000000e+03 2.00000000e+01]\n",
            " [1.18998750e+01 3.60000000e+01 0.00000000e+00 1.00000000e+00\n",
            "  1.00000000e+01 3.30000000e+01]\n",
            " [1.32402250e+01 1.11000000e+02 0.00000000e+00 1.00000000e+00\n",
            "  4.75000000e+02 1.80000000e+01]\n",
            " [3.21106875e+00 3.00000000e+01 1.12000000e+02 1.00000000e+00\n",
            "  0.00000000e+00 8.00000000e+01]\n",
            " [1.55894188e+01 7.10000000e+01 0.00000000e+00 1.00000000e+00\n",
            "  2.64000000e+02 1.34000000e+02]\n",
            " [1.13582438e+01 3.30000000e+01 0.00000000e+00 1.00000000e+00\n",
            "  2.88000000e+02 1.60000000e+01]\n",
            " [1.98461688e+01 4.90000000e+01 0.00000000e+00 3.00000000e+00\n",
            "  1.58400000e+03 3.00000000e+00]\n",
            " [6.60139375e+00 2.50000000e+01 0.00000000e+00 1.00000000e+00\n",
            "  0.00000000e+00 8.10000000e+01]\n",
            " [3.17541125e+01 2.40000000e+02 0.00000000e+00 1.00000000e+00\n",
            "  8.29000000e+02 1.14000000e+02]\n",
            " [2.33332000e+01 9.10000000e+01 0.00000000e+00 1.00000000e+00\n",
            "  1.51100000e+03 5.00000000e+00]\n",
            " [6.04887250e+01 1.17000000e+02 0.00000000e+00 1.00000000e+00\n",
            "  5.67500000e+03 1.10000000e+01]\n",
            " [1.73117938e+01 1.20000000e+02 0.00000000e+00 8.00000000e+00\n",
            "  5.03000000e+02 1.40000000e+01]\n",
            " [1.65272500e+01 3.10000000e+01 3.10000000e+01 1.00000000e+00\n",
            "  7.09000000e+02 2.10000000e+01]\n",
            " [4.44078375e+01 1.96000000e+02 0.00000000e+00 3.00000000e+00\n",
            "  3.85200000e+03 1.50000000e+01]\n",
            " [6.46578250e+01 1.80000000e+02 0.00000000e+00 4.00000000e+00\n",
            "  7.59600000e+03 2.00000000e+01]]\n",
            "1920\n",
            "480\n",
            "1920\n",
            "480\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset1 = pd.read_csv('neudefect5.csv')\n",
        "print(dataset1)\n",
        "\n",
        "x = dataset1.iloc[:,:-1].values\n",
        "print(len(x[0]))\n",
        "\n",
        "y = list()\n",
        "\n",
        "\n",
        "print(x[0])\n",
        "print(x[499])\n",
        "\n",
        "\n",
        "random.shuffle(x)\n",
        "print(x[0])\n",
        "print(x[499])\n",
        "\n",
        "for i in x:\n",
        "    x_new.append(i)\n",
        "\n",
        "for i in range(0,600):\n",
        "    y.append(4)\n",
        "    y_new.append(4)\n",
        "\n",
        "\n",
        "X_train_new, X_test_new, y_train_new, y_test_new = train_test_split( x, y, test_size=0.2, random_state=4)\n",
        "print(X_test_new)\n",
        "\n",
        "for i in X_train_new :\n",
        "    X_train.append(i)\n",
        "\n",
        "for i in X_test_new :\n",
        "    X_test.append(i)\n",
        "\n",
        "for i in y_train_new :\n",
        "    y_train.append(i)\n",
        "\n",
        "for i in y_test_new :\n",
        "    y_test.append(i)\n",
        "\n",
        "print(len(X_train))\n",
        "print(len(X_test))\n",
        "print(len(y_train))\n",
        "print(len(y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gvDwVG3xjznH",
        "outputId": "433f97b4-7892-49c5-b381-43599697f564"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        energy  dots  lines  contours  edges  corner   \n",
            "0    27.866075   231      0         1    144     123   \n",
            "1    27.866075   231      0         1    138     160   \n",
            "2    24.338119   218     32         1    211     183   \n",
            "3    24.338119   218     32         1    213      52   \n",
            "4    18.673944   324     63         9      0       8   \n",
            "..         ...   ...    ...       ...    ...     ... ..\n",
            "595  19.063156   247     94         6     40       4   \n",
            "596  33.260206   156     25         2    586      10   \n",
            "597  33.260206   156     25         2    576      13   \n",
            "598  30.911975   216     21         2    476       5   \n",
            "599  30.911975   216     21         2    463       5   \n",
            "\n",
            "[600 rows x 7 columns]\n",
            "6\n",
            "[ 27.866075 231.         0.         1.       144.       123.      ]\n",
            "[ 25.7831375 152.         12.          1.        597.          8.       ]\n",
            "[ 27.866075 231.         0.         1.       144.       123.      ]\n",
            "[ 25.3854 207.      23.       3.     167.       6.    ]\n",
            "[[3.13297125e+01 3.38000000e+02 5.60000000e+01 8.00000000e+00\n",
            "  7.39000000e+02 1.35000000e+02]\n",
            " [2.06898188e+01 2.61000000e+02 1.10800000e+03 1.00000000e+00\n",
            "  2.50000000e+01 2.00000000e+02]\n",
            " [2.76901250e+01 2.92000000e+02 7.80000000e+01 5.00000000e+00\n",
            "  5.93000000e+02 4.00000000e+00]\n",
            " [3.71478250e+01 3.16000000e+02 1.50000000e+01 2.00000000e+00\n",
            "  7.38000000e+02 3.00000000e+00]\n",
            " [2.62413938e+01 2.14000000e+02 5.60000000e+01 1.10000000e+01\n",
            "  2.61000000e+02 5.90000000e+01]\n",
            " [3.13244750e+01 2.40000000e+02 1.10000000e+01 2.00000000e+00\n",
            "  3.04000000e+02 1.20000000e+01]\n",
            " [5.38485313e+01 3.07000000e+02 1.00000000e+00 1.00000000e+00\n",
            "  1.61000000e+03 2.20000000e+01]\n",
            " [2.61607750e+01 2.50000000e+02 4.30000000e+01 1.00000000e+00\n",
            "  7.60000000e+01 1.97000000e+02]\n",
            " [4.62315063e+01 2.14000000e+02 0.00000000e+00 1.00000000e+00\n",
            "  1.17000000e+03 1.10000000e+01]\n",
            " [2.33659125e+01 2.97000000e+02 4.30000000e+01 1.00000000e+00\n",
            "  1.34000000e+02 3.00000000e+00]\n",
            " [1.45897625e+01 3.47000000e+02 9.04000000e+02 1.00000000e+00\n",
            "  0.00000000e+00 1.18000000e+02]\n",
            " [2.61607750e+01 2.50000000e+02 4.30000000e+01 1.00000000e+00\n",
            "  7.60000000e+01 2.03000000e+02]\n",
            " [2.06749875e+01 2.05000000e+02 7.90000000e+01 1.00000000e+00\n",
            "  9.30000000e+01 3.00000000e+00]\n",
            " [5.30278938e+01 1.89000000e+02 4.00000000e+00 2.00000000e+00\n",
            "  1.92600000e+03 1.80000000e+01]\n",
            " [3.06344125e+01 2.70000000e+02 3.30000000e+01 2.00000000e+00\n",
            "  4.80000000e+02 6.00000000e+00]\n",
            " [3.18798375e+01 2.39000000e+02 2.80000000e+01 1.00000000e+00\n",
            "  4.74000000e+02 4.00000000e+00]\n",
            " [2.43381188e+01 2.18000000e+02 3.20000000e+01 1.00000000e+00\n",
            "  2.13000000e+02 5.20000000e+01]\n",
            " [4.37358688e+01 3.17000000e+02 4.10000000e+01 3.00000000e+00\n",
            "  1.77900000e+03 2.20000000e+01]\n",
            " [3.99336625e+01 2.70000000e+02 3.10000000e+01 3.00000000e+00\n",
            "  1.49200000e+03 8.00000000e+00]\n",
            " [2.31287438e+01 1.42000000e+02 2.49000000e+02 1.00000000e+00\n",
            "  9.10000000e+01 3.00000000e+00]\n",
            " [4.38645750e+01 2.57000000e+02 2.50000000e+01 3.00000000e+00\n",
            "  1.22700000e+03 3.00000000e+00]\n",
            " [4.06221625e+01 4.08000000e+02 1.20000000e+01 2.00000000e+00\n",
            "  9.68000000e+02 2.00000000e+00]\n",
            " [5.10691563e+01 2.39000000e+02 0.00000000e+00 1.00000000e+00\n",
            "  1.79200000e+03 2.10000000e+01]\n",
            " [2.62413938e+01 2.14000000e+02 5.60000000e+01 1.10000000e+01\n",
            "  2.61000000e+02 5.90000000e+01]\n",
            " [1.98635375e+01 2.63000000e+02 1.19200000e+03 5.00000000e+00\n",
            "  4.40000000e+01 1.42000000e+02]\n",
            " [2.30987688e+01 2.69000000e+02 1.03700000e+03 8.00000000e+00\n",
            "  2.04000000e+02 1.77000000e+02]\n",
            " [4.99726375e+01 1.51000000e+02 1.30000000e+01 4.00000000e+00\n",
            "  2.20800000e+03 8.00000000e+00]\n",
            " [2.25820188e+01 2.42000000e+02 6.70000000e+01 5.00000000e+00\n",
            "  9.70000000e+01 1.73000000e+02]\n",
            " [3.11904563e+01 2.83000000e+02 4.30000000e+01 1.00000000e+00\n",
            "  2.70000000e+02 1.14000000e+02]\n",
            " [3.80520125e+01 1.99000000e+02 4.00000000e+01 1.00000000e+00\n",
            "  1.10700000e+03 4.00000000e+01]\n",
            " [3.79685688e+01 2.41000000e+02 2.90000000e+01 3.00000000e+00\n",
            "  8.43000000e+02 6.00000000e+00]\n",
            " [2.74244438e+01 3.17000000e+02 2.00000000e+00 4.00000000e+00\n",
            "  1.55000000e+02 2.00000000e+00]\n",
            " [2.15219000e+01 2.84000000e+02 9.32000000e+02 9.00000000e+00\n",
            "  1.48000000e+02 1.51000000e+02]\n",
            " [3.71478250e+01 3.16000000e+02 1.50000000e+01 2.00000000e+00\n",
            "  7.36000000e+02 3.00000000e+00]\n",
            " [3.20083875e+01 2.42000000e+02 6.00000000e+00 1.00000000e+00\n",
            "  3.71000000e+02 9.00000000e+00]\n",
            " [3.97081125e+01 2.53000000e+02 4.80000000e+01 4.00000000e+00\n",
            "  1.25700000e+03 1.10000000e+01]\n",
            " [3.94301938e+01 4.53000000e+02 7.00000000e+00 1.00000000e+00\n",
            "  6.09000000e+02 2.20000000e+01]\n",
            " [3.79685688e+01 2.41000000e+02 2.90000000e+01 3.00000000e+00\n",
            "  8.43000000e+02 6.00000000e+00]\n",
            " [2.97144313e+01 3.35000000e+02 4.50000000e+01 3.00000000e+00\n",
            "  4.22000000e+02 2.00000000e+00]\n",
            " [2.78900438e+01 3.06000000e+02 1.00600000e+03 1.00000000e+00\n",
            "  5.68000000e+02 1.92000000e+02]\n",
            " [1.86739438e+01 3.24000000e+02 6.30000000e+01 7.00000000e+00\n",
            "  0.00000000e+00 2.00000000e+00]\n",
            " [4.58158313e+01 2.41000000e+02 0.00000000e+00 1.00000000e+00\n",
            "  1.03500000e+03 1.20000000e+01]\n",
            " [2.76901250e+01 2.92000000e+02 7.80000000e+01 5.00000000e+00\n",
            "  5.93000000e+02 4.00000000e+00]\n",
            " [3.47301688e+01 3.48000000e+02 1.00000000e+01 2.00000000e+00\n",
            "  4.52000000e+02 1.60000000e+01]\n",
            " [2.92689750e+01 2.69000000e+02 4.52000000e+02 5.00000000e+00\n",
            "  4.54000000e+02 1.62000000e+02]\n",
            " [3.40593938e+01 2.27000000e+02 6.00000000e+01 1.00000000e+01\n",
            "  9.97000000e+02 1.20000000e+01]\n",
            " [3.42285188e+01 2.79000000e+02 9.00000000e+00 1.00000000e+00\n",
            "  4.36000000e+02 9.60000000e+01]\n",
            " [2.61607750e+01 2.50000000e+02 4.30000000e+01 1.00000000e+00\n",
            "  7.60000000e+01 2.03000000e+02]\n",
            " [2.53854000e+01 2.07000000e+02 2.30000000e+01 4.00000000e+00\n",
            "  1.67000000e+02 7.00000000e+00]\n",
            " [5.11366250e+01 2.10000000e+02 1.00000000e+01 1.00000000e+00\n",
            "  1.40100000e+03 7.00000000e+00]\n",
            " [2.34000188e+01 1.57000000e+02 7.78000000e+02 1.00000000e+00\n",
            "  1.23000000e+02 1.82000000e+02]\n",
            " [4.05093688e+01 2.79000000e+02 1.00000000e+01 1.00000000e+00\n",
            "  8.67000000e+02 2.00000000e+00]\n",
            " [4.29167500e+01 2.79000000e+02 1.00000000e+01 3.00000000e+00\n",
            "  8.79000000e+02 2.00000000e+00]\n",
            " [3.61436125e+01 2.42000000e+02 6.20000000e+01 5.00000000e+00\n",
            "  1.04200000e+03 6.00000000e+00]\n",
            " [4.05093688e+01 2.79000000e+02 1.00000000e+01 1.00000000e+00\n",
            "  8.67000000e+02 2.00000000e+00]\n",
            " [2.06749875e+01 2.05000000e+02 7.90000000e+01 1.00000000e+00\n",
            "  9.30000000e+01 4.00000000e+00]\n",
            " [1.99663438e+01 2.30000000e+02 4.50000000e+01 1.00000000e+00\n",
            "  4.90000000e+01 2.00000000e+00]\n",
            " [3.00277375e+01 4.20000000e+02 3.30000000e+01 1.00000000e+00\n",
            "  4.16000000e+02 1.52000000e+02]\n",
            " [3.14082938e+01 3.42000000e+02 2.70000000e+01 1.00000000e+00\n",
            "  6.23000000e+02 1.46000000e+02]\n",
            " [3.49822375e+01 2.76000000e+02 7.50000000e+01 1.00000000e+00\n",
            "  9.86000000e+02 2.00000000e+00]\n",
            " [2.34149813e+01 2.67000000e+02 6.40000000e+01 2.00000000e+00\n",
            "  9.90000000e+01 5.30000000e+01]\n",
            " [2.82980063e+01 1.77000000e+02 8.00000000e+00 1.00000000e+00\n",
            "  4.16000000e+02 2.00000000e+01]\n",
            " [2.01652625e+01 2.87000000e+02 1.15700000e+03 3.00000000e+00\n",
            "  6.00000000e+01 1.43000000e+02]\n",
            " [1.55614750e+01 3.43000000e+02 1.12400000e+03 2.00000000e+00\n",
            "  0.00000000e+00 1.41000000e+02]\n",
            " [4.37358688e+01 3.17000000e+02 4.10000000e+01 3.00000000e+00\n",
            "  1.77900000e+03 2.20000000e+01]\n",
            " [3.05253313e+01 3.53000000e+02 8.76000000e+02 2.00000000e+00\n",
            "  8.70000000e+02 1.00000000e+01]\n",
            " [4.29167500e+01 2.79000000e+02 1.00000000e+01 8.00000000e+00\n",
            "  8.64000000e+02 2.00000000e+00]\n",
            " [4.25694313e+01 2.86000000e+02 2.30000000e+01 2.00000000e+00\n",
            "  9.18000000e+02 5.00000000e+00]\n",
            " [2.33659125e+01 2.97000000e+02 4.30000000e+01 2.00000000e+00\n",
            "  1.35000000e+02 4.00000000e+00]\n",
            " [3.61436125e+01 2.42000000e+02 6.20000000e+01 2.00000000e+00\n",
            "  1.04500000e+03 1.10000000e+01]\n",
            " [2.74357563e+01 3.06000000e+02 7.60000000e+01 6.00000000e+00\n",
            "  4.82000000e+02 1.50000000e+01]\n",
            " [3.77018875e+01 2.25000000e+02 6.00000000e+00 1.00000000e+00\n",
            "  5.66000000e+02 6.00000000e+00]\n",
            " [3.79685688e+01 2.41000000e+02 2.90000000e+01 2.00000000e+00\n",
            "  8.44000000e+02 7.00000000e+00]\n",
            " [2.78660750e+01 2.31000000e+02 0.00000000e+00 1.00000000e+00\n",
            "  1.38000000e+02 1.60000000e+02]\n",
            " [3.47301688e+01 3.48000000e+02 1.00000000e+01 2.00000000e+00\n",
            "  4.53000000e+02 8.00000000e+00]\n",
            " [4.29167500e+01 2.79000000e+02 1.00000000e+01 8.00000000e+00\n",
            "  8.64000000e+02 2.00000000e+00]\n",
            " [1.97252063e+01 2.93000000e+02 1.12800000e+03 1.00000000e+00\n",
            "  4.30000000e+01 1.28000000e+02]\n",
            " [3.13244750e+01 2.40000000e+02 1.10000000e+01 2.00000000e+00\n",
            "  3.04000000e+02 1.20000000e+01]\n",
            " [4.25694313e+01 2.86000000e+02 2.30000000e+01 2.00000000e+00\n",
            "  9.19000000e+02 3.00000000e+00]\n",
            " [4.44430563e+01 3.35000000e+02 1.30000000e+01 3.00000000e+00\n",
            "  1.14200000e+03 3.00000000e+00]\n",
            " [3.14082938e+01 3.42000000e+02 2.70000000e+01 1.00000000e+00\n",
            "  6.21000000e+02 1.00000000e+01]\n",
            " [3.13297125e+01 3.38000000e+02 5.60000000e+01 8.00000000e+00\n",
            "  7.39000000e+02 1.35000000e+02]\n",
            " [2.62413938e+01 2.14000000e+02 5.60000000e+01 1.10000000e+01\n",
            "  2.61000000e+02 5.90000000e+01]\n",
            " [2.34000188e+01 1.57000000e+02 7.78000000e+02 1.00000000e+00\n",
            "  1.23000000e+02 1.87000000e+02]\n",
            " [3.47301688e+01 3.48000000e+02 1.00000000e+01 2.00000000e+00\n",
            "  4.53000000e+02 8.00000000e+00]\n",
            " [1.84495125e+01 3.61000000e+02 1.18600000e+03 2.00000000e+00\n",
            "  7.30000000e+01 1.63000000e+02]\n",
            " [3.80520125e+01 1.99000000e+02 4.00000000e+01 1.00000000e+00\n",
            "  1.10700000e+03 4.00000000e+01]\n",
            " [2.16900000e+01 2.58000000e+02 6.50000000e+01 1.00000000e+00\n",
            "  9.80000000e+01 4.00000000e+00]\n",
            " [2.58336188e+01 1.58000000e+02 6.00000000e+00 5.00000000e+00\n",
            "  1.84000000e+02 1.00000000e+01]\n",
            " [4.37358688e+01 3.17000000e+02 4.10000000e+01 3.00000000e+00\n",
            "  1.77900000e+03 2.20000000e+01]\n",
            " [3.14082938e+01 3.42000000e+02 2.70000000e+01 1.00000000e+00\n",
            "  6.21000000e+02 1.00000000e+01]\n",
            " [4.52969875e+01 2.53000000e+02 2.60000000e+01 1.00000000e+00\n",
            "  1.34900000e+03 5.00000000e+00]\n",
            " [4.02873438e+01 2.94000000e+02 3.60000000e+01 1.00000000e+00\n",
            "  9.87000000e+02 4.00000000e+00]\n",
            " [4.29167500e+01 2.79000000e+02 1.00000000e+01 8.00000000e+00\n",
            "  8.64000000e+02 2.00000000e+00]\n",
            " [3.66132438e+01 2.66000000e+02 5.00000000e+00 1.00000000e+00\n",
            "  8.14000000e+02 7.00000000e+00]\n",
            " [2.82710938e+01 2.96000000e+02 8.10000000e+01 2.00000000e+00\n",
            "  5.60000000e+02 4.00000000e+00]\n",
            " [3.97081125e+01 2.53000000e+02 4.80000000e+01 7.00000000e+00\n",
            "  1.25800000e+03 1.90000000e+01]\n",
            " [4.20296938e+01 2.56000000e+02 3.20000000e+01 7.00000000e+00\n",
            "  1.17200000e+03 1.10000000e+01]\n",
            " [3.18798375e+01 2.39000000e+02 2.80000000e+01 1.00000000e+00\n",
            "  4.74000000e+02 4.00000000e+00]\n",
            " [3.99336625e+01 2.70000000e+02 3.10000000e+01 2.00000000e+00\n",
            "  1.48700000e+03 9.00000000e+00]\n",
            " [3.78418125e+01 2.85000000e+02 2.20000000e+01 6.00000000e+00\n",
            "  7.13000000e+02 8.00000000e+00]\n",
            " [5.36366500e+01 2.09000000e+02 3.00000000e+00 3.00000000e+00\n",
            "  1.64100000e+03 1.50000000e+01]\n",
            " [3.77018875e+01 2.25000000e+02 6.00000000e+00 1.00000000e+00\n",
            "  5.68000000e+02 5.00000000e+00]\n",
            " [4.99726375e+01 1.51000000e+02 1.30000000e+01 7.00000000e+00\n",
            "  2.20700000e+03 2.00000000e+00]\n",
            " [3.79685688e+01 2.41000000e+02 2.90000000e+01 3.00000000e+00\n",
            "  8.43000000e+02 6.00000000e+00]\n",
            " [2.74244438e+01 3.17000000e+02 2.00000000e+00 4.00000000e+00\n",
            "  1.55000000e+02 2.00000000e+00]\n",
            " [2.78660750e+01 2.31000000e+02 0.00000000e+00 1.00000000e+00\n",
            "  1.38000000e+02 1.60000000e+02]\n",
            " [3.96506438e+01 2.66000000e+02 1.20000000e+01 4.00000000e+00\n",
            "  6.19000000e+02 2.00000000e+00]\n",
            " [1.99663438e+01 2.30000000e+02 4.50000000e+01 1.00000000e+00\n",
            "  4.90000000e+01 2.00000000e+00]\n",
            " [3.87402750e+01 2.51000000e+02 2.20000000e+01 2.00000000e+00\n",
            "  1.17000000e+03 2.00000000e+00]\n",
            " [2.69804438e+01 2.01000000e+02 2.00000000e+00 4.00000000e+00\n",
            "  3.33000000e+02 1.03000000e+02]\n",
            " [2.43381188e+01 2.18000000e+02 3.20000000e+01 1.00000000e+00\n",
            "  2.13000000e+02 5.20000000e+01]\n",
            " [2.50386438e+01 2.57000000e+02 2.40000000e+01 1.00000000e+00\n",
            "  1.39000000e+02 5.00000000e+00]\n",
            " [2.70483938e+01 2.28000000e+02 5.30000000e+01 2.00000000e+00\n",
            "  3.39000000e+02 4.00000000e+00]\n",
            " [3.35907750e+01 2.53000000e+02 7.10000000e+01 4.00000000e+00\n",
            "  9.83000000e+02 1.20000000e+01]\n",
            " [2.65801188e+01 3.52000000e+02 9.78000000e+02 1.00000000e+00\n",
            "  6.60000000e+02 1.60000000e+01]\n",
            " [4.06221625e+01 4.08000000e+02 1.20000000e+01 3.00000000e+00\n",
            "  9.71000000e+02 8.00000000e+00]\n",
            " [2.81976188e+01 3.24000000e+02 6.28000000e+02 5.00000000e+00\n",
            "  6.77000000e+02 1.80000000e+02]\n",
            " [3.18798375e+01 2.39000000e+02 2.80000000e+01 1.00000000e+00\n",
            "  4.74000000e+02 4.20000000e+01]\n",
            " [3.33352625e+01 2.37000000e+02 2.00000000e+00 1.00000000e+00\n",
            "  5.91000000e+02 1.60000000e+01]]\n",
            "2400\n",
            "600\n",
            "2400\n",
            "600\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset1 = pd.read_csv('neudefect6.csv')\n",
        "print(dataset1)\n",
        "\n",
        "x = dataset1.iloc[:,:-1].values\n",
        "print(len(x[0]))\n",
        "\n",
        "y = list()\n",
        "\n",
        "\n",
        "print(x[0])\n",
        "print(x[499])\n",
        "\n",
        "\n",
        "random.shuffle(x)\n",
        "print(x[0])\n",
        "print(x[499])\n",
        "\n",
        "for i in x:\n",
        "    x_new.append(i)\n",
        "\n",
        "for i in range(0,600):\n",
        "    y.append(5)\n",
        "    y_new.append(5)\n",
        "\n",
        "\n",
        "X_train_new, X_test_new, y_train_new, y_test_new = train_test_split( x, y, test_size=0.2, random_state=4)\n",
        "print(X_test_new)\n",
        "\n",
        "for i in X_train_new :\n",
        "    X_train.append(i)\n",
        "\n",
        "for i in X_test_new :\n",
        "    X_test.append(i)\n",
        "\n",
        "for i in y_train_new :\n",
        "    y_train.append(i)\n",
        "\n",
        "for i in y_test_new :\n",
        "    y_test.append(i)\n",
        "\n",
        "print(len(X_train))\n",
        "print(len(X_test))\n",
        "print(len(y_train))\n",
        "print(len(y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dcyo-9y9jzlA",
        "outputId": "ad2b2bf6-f601-4008-d94d-704e1f97d98e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        energy  dots  lines  contours  edges  corner   \n",
            "0     3.930488   120     17         1    154       3   \n",
            "1     3.930488   120     17         1    154       3   \n",
            "2    24.651506    42     32         5    848       9   \n",
            "3    24.651506    42     32         5    848       9   \n",
            "4    17.056650    14      7        11    717      16   \n",
            "..         ...   ...    ...       ...    ...     ... ..\n",
            "595  10.991888    62      2         2    536       3   \n",
            "596   5.499306    79    416         2     98      17   \n",
            "597   5.499306    79    416         2     98      17   \n",
            "598  13.290188     5    116        10    546       9   \n",
            "599  13.290188     5    116        10    546       9   \n",
            "\n",
            "[600 rows x 7 columns]\n",
            "6\n",
            "[  3.9304875 120.         17.          1.        154.          3.       ]\n",
            "[  13.1159875   20.           0.           4.        1246.\n",
            "    6.       ]\n",
            "[  3.9304875 120.         17.          1.        154.          3.       ]\n",
            "[  5.3968125  11.         10.          1.        325.          6.       ]\n",
            "[[2.32727313e+01 3.00000000e+00 4.21000000e+02 1.00000000e+00\n",
            "  1.70900000e+03 6.00000000e+00]\n",
            " [3.99722500e+00 9.20000000e+01 2.00000000e+02 1.00000000e+00\n",
            "  1.53000000e+02 4.00000000e+00]\n",
            " [2.06646938e+01 8.00000000e+00 4.85000000e+02 1.00000000e+00\n",
            "  8.48000000e+02 3.00000000e+00]\n",
            " [1.93873313e+01 6.00000000e+00 5.63000000e+02 6.00000000e+00\n",
            "  1.31300000e+03 4.00000000e+00]\n",
            " [1.28109625e+01 2.30000000e+01 3.46000000e+02 6.00000000e+00\n",
            "  8.11000000e+02 5.00000000e+00]\n",
            " [7.65099375e+00 1.42000000e+02 0.00000000e+00 3.00000000e+00\n",
            "  1.89000000e+02 1.11000000e+02]\n",
            " [9.44234375e+00 1.00000000e+01 1.44000000e+02 4.00000000e+00\n",
            "  7.64000000e+02 5.00000000e+00]\n",
            " [1.70566500e+01 1.40000000e+01 7.00000000e+00 1.10000000e+01\n",
            "  7.17000000e+02 1.60000000e+01]\n",
            " [2.31781688e+01 7.00000000e+00 5.83000000e+02 8.00000000e+00\n",
            "  1.33300000e+03 3.00000000e+00]\n",
            " [1.73914000e+01 1.00000000e+00 2.73000000e+02 9.00000000e+00\n",
            "  8.70000000e+02 1.80000000e+01]\n",
            " [1.93632500e+00 3.40000000e+01 9.00000000e+00 1.00000000e+00\n",
            "  1.80000000e+01 2.00000000e+00]\n",
            " [2.80787813e+01 6.00000000e+00 0.00000000e+00 3.00000000e+00\n",
            "  8.94000000e+02 9.00000000e+00]\n",
            " [1.75013938e+01 3.00000000e+00 1.00000000e+00 5.00000000e+00\n",
            "  9.48000000e+02 2.70000000e+01]\n",
            " [3.93048750e+00 1.20000000e+02 1.70000000e+01 1.00000000e+00\n",
            "  1.54000000e+02 3.00000000e+00]\n",
            " [6.11891250e+00 2.70000000e+01 1.02000000e+02 1.00000000e+00\n",
            "  3.76000000e+02 2.00000000e+00]\n",
            " [1.49583813e+01 4.00000000e+00 8.00000000e+01 6.00000000e+00\n",
            "  1.11300000e+03 9.00000000e+00]\n",
            " [8.99995625e+00 0.00000000e+00 6.90000000e+01 1.00000000e+00\n",
            "  3.10000000e+02 5.00000000e+00]\n",
            " [1.17084063e+01 6.00000000e+00 0.00000000e+00 4.00000000e+00\n",
            "  8.51000000e+02 2.80000000e+01]\n",
            " [3.72057750e+01 1.60000000e+01 4.46000000e+02 4.00000000e+00\n",
            "  2.06300000e+03 9.00000000e+00]\n",
            " [3.59238125e+01 8.00000000e+00 3.67000000e+02 2.40000000e+01\n",
            "  2.08600000e+03 6.00000000e+00]\n",
            " [2.80787813e+01 6.00000000e+00 0.00000000e+00 3.00000000e+00\n",
            "  8.94000000e+02 9.00000000e+00]\n",
            " [2.43233875e+01 6.00000000e+00 6.38000000e+02 2.00000000e+00\n",
            "  7.64000000e+02 4.00000000e+00]\n",
            " [5.76326875e+00 7.20000000e+01 3.39000000e+02 1.00000000e+00\n",
            "  3.88000000e+02 3.00000000e+00]\n",
            " [6.62452500e+00 1.80000000e+01 2.44000000e+02 3.00000000e+00\n",
            "  4.00000000e+02 4.00000000e+00]\n",
            " [2.84867438e+01 1.00000000e+00 3.11000000e+02 1.90000000e+01\n",
            "  1.25900000e+03 1.80000000e+01]\n",
            " [6.10881250e+00 2.20000000e+01 2.60000000e+01 8.00000000e+00\n",
            "  5.34000000e+02 8.00000000e+00]\n",
            " [3.90243125e+00 5.70000000e+01 5.50000000e+01 4.00000000e+00\n",
            "  1.65000000e+02 2.00000000e+00]\n",
            " [7.44812500e+00 8.00000000e+00 2.30000000e+01 2.00000000e+00\n",
            "  4.19000000e+02 2.00000000e+00]\n",
            " [3.39269688e+01 5.00000000e+00 3.94000000e+02 1.80000000e+01\n",
            "  1.67000000e+03 1.50000000e+01]\n",
            " [2.34224625e+01 2.00000000e+00 1.31000000e+02 3.00000000e+00\n",
            "  1.14100000e+03 3.20000000e+01]\n",
            " [1.49583813e+01 4.00000000e+00 8.00000000e+01 6.00000000e+00\n",
            "  1.11300000e+03 9.00000000e+00]\n",
            " [1.57069938e+01 0.00000000e+00 1.82000000e+02 2.00000000e+00\n",
            "  7.45000000e+02 2.10000000e+01]\n",
            " [6.53986250e+00 7.70000000e+01 2.16000000e+02 1.00000000e+00\n",
            "  1.53000000e+02 1.25000000e+02]\n",
            " [1.72134438e+01 1.00000000e+00 2.00000000e+00 5.00000000e+00\n",
            "  1.12200000e+03 1.60000000e+01]\n",
            " [2.46515063e+01 4.20000000e+01 3.20000000e+01 5.00000000e+00\n",
            "  8.48000000e+02 9.00000000e+00]\n",
            " [4.54986250e+00 6.80000000e+01 3.10000000e+01 3.00000000e+00\n",
            "  2.77000000e+02 5.00000000e+00]\n",
            " [1.19659938e+01 1.00000000e+00 3.40000000e+01 1.50000000e+01\n",
            "  7.68000000e+02 2.30000000e+01]\n",
            " [1.69108188e+01 1.10000000e+01 4.00000000e+00 8.00000000e+00\n",
            "  7.39000000e+02 1.40000000e+01]\n",
            " [2.43586125e+01 1.00000000e+00 0.00000000e+00 4.00000000e+00\n",
            "  1.19600000e+03 4.70000000e+01]\n",
            " [1.18298625e+01 2.00000000e+00 1.04000000e+02 6.00000000e+00\n",
            "  8.67000000e+02 1.40000000e+01]\n",
            " [1.34974250e+01 2.00000000e+00 2.33000000e+02 7.00000000e+00\n",
            "  7.48000000e+02 1.80000000e+01]\n",
            " [4.91875000e+00 1.19000000e+02 3.80000000e+01 1.00000000e+00\n",
            "  3.47000000e+02 8.30000000e+01]\n",
            " [7.63301250e+00 4.00000000e+00 9.10000000e+01 2.00000000e+00\n",
            "  5.12000000e+02 1.40000000e+01]\n",
            " [3.39269688e+01 5.00000000e+00 3.94000000e+02 1.80000000e+01\n",
            "  1.67000000e+03 1.50000000e+01]\n",
            " [1.91712563e+01 3.70000000e+01 4.24000000e+02 6.00000000e+00\n",
            "  6.50000000e+02 3.00000000e+00]\n",
            " [1.46942750e+01 0.00000000e+00 2.50000000e+02 1.00000000e+00\n",
            "  8.03000000e+02 5.00000000e+00]\n",
            " [6.62452500e+00 1.80000000e+01 2.44000000e+02 3.00000000e+00\n",
            "  4.00000000e+02 4.00000000e+00]\n",
            " [1.34974250e+01 2.00000000e+00 2.33000000e+02 7.00000000e+00\n",
            "  7.48000000e+02 1.80000000e+01]\n",
            " [2.30851688e+01 4.00000000e+00 1.29000000e+02 5.00000000e+00\n",
            "  9.41000000e+02 1.30000000e+01]\n",
            " [8.31657500e+00 1.10000000e+01 5.80000000e+01 3.00000000e+00\n",
            "  5.66000000e+02 4.00000000e+00]\n",
            " [6.51071250e+00 0.00000000e+00 1.10000000e+01 1.00000000e+00\n",
            "  4.18000000e+02 7.00000000e+00]\n",
            " [2.15920375e+01 1.00000000e+00 5.40000000e+01 6.00000000e+00\n",
            "  1.10800000e+03 3.10000000e+01]\n",
            " [1.39089375e+00 2.40000000e+01 4.00000000e+00 1.00000000e+00\n",
            "  0.00000000e+00 2.80000000e+01]\n",
            " [3.31391250e+00 1.70000000e+01 7.00000000e+00 1.00000000e+01\n",
            "  2.16000000e+02 6.00000000e+00]\n",
            " [2.80787813e+01 6.00000000e+00 0.00000000e+00 3.00000000e+00\n",
            "  8.94000000e+02 9.00000000e+00]\n",
            " [1.28109625e+01 2.30000000e+01 3.46000000e+02 6.00000000e+00\n",
            "  8.11000000e+02 5.00000000e+00]\n",
            " [1.70566500e+01 1.40000000e+01 7.00000000e+00 1.10000000e+01\n",
            "  7.17000000e+02 1.60000000e+01]\n",
            " [1.25564438e+01 8.50000000e+01 0.00000000e+00 1.00000000e+00\n",
            "  4.59000000e+02 1.00000000e+01]\n",
            " [1.69975125e+01 3.00000000e+00 1.60000000e+02 8.00000000e+00\n",
            "  9.88000000e+02 7.00000000e+00]\n",
            " [2.15817438e+01 1.00000000e+00 1.40000000e+01 2.00000000e+00\n",
            "  1.00900000e+03 2.40000000e+01]\n",
            " [2.80787813e+01 6.00000000e+00 0.00000000e+00 3.00000000e+00\n",
            "  8.94000000e+02 9.00000000e+00]\n",
            " [7.44812500e+00 8.00000000e+00 2.30000000e+01 2.00000000e+00\n",
            "  4.19000000e+02 2.00000000e+00]\n",
            " [6.31717500e+00 0.00000000e+00 1.00000000e+01 1.00000000e+00\n",
            "  3.36000000e+02 8.00000000e+00]\n",
            " [3.15709375e+01 2.40000000e+01 2.71000000e+02 2.00000000e+00\n",
            "  1.83500000e+03 8.00000000e+00]\n",
            " [1.14644313e+01 1.50000000e+01 5.05000000e+02 3.00000000e+00\n",
            "  6.55000000e+02 2.00000000e+00]\n",
            " [3.39269688e+01 5.00000000e+00 3.94000000e+02 1.80000000e+01\n",
            "  1.67000000e+03 1.50000000e+01]\n",
            " [2.38876500e+01 4.00000000e+00 2.00000000e+00 5.00000000e+00\n",
            "  1.00800000e+03 3.10000000e+01]\n",
            " [1.71278625e+01 1.00000000e+00 1.67000000e+02 6.00000000e+00\n",
            "  9.02000000e+02 1.60000000e+01]\n",
            " [6.54056875e+00 6.10000000e+01 3.09000000e+02 1.00000000e+00\n",
            "  4.46000000e+02 2.00000000e+00]\n",
            " [7.05382500e+00 6.30000000e+01 3.36000000e+02 1.00000000e+00\n",
            "  5.69000000e+02 1.00000000e+01]\n",
            " [4.98565625e+00 4.20000000e+01 1.36000000e+02 1.00000000e+00\n",
            "  3.52000000e+02 1.61000000e+02]\n",
            " [6.48600625e+00 9.90000000e+01 3.91000000e+02 3.00000000e+00\n",
            "  3.45000000e+02 1.45000000e+02]\n",
            " [1.78334813e+01 0.00000000e+00 5.20000000e+01 2.00000000e+00\n",
            "  9.86000000e+02 3.10000000e+01]\n",
            " [3.93048750e+00 1.20000000e+02 1.70000000e+01 1.00000000e+00\n",
            "  1.54000000e+02 3.00000000e+00]\n",
            " [3.35431813e+01 2.40000000e+01 3.21000000e+02 2.00000000e+01\n",
            "  1.90200000e+03 3.00000000e+00]\n",
            " [1.68878125e+01 1.00000000e+00 2.01000000e+02 6.00000000e+00\n",
            "  8.00000000e+02 1.10000000e+01]\n",
            " [6.88406875e+00 5.00000000e+00 1.50000000e+01 3.00000000e+00\n",
            "  4.39000000e+02 2.00000000e+00]\n",
            " [1.28109625e+01 2.30000000e+01 3.46000000e+02 6.00000000e+00\n",
            "  8.11000000e+02 5.00000000e+00]\n",
            " [2.68558125e+00 2.00000000e+01 6.00000000e+00 1.00000000e+00\n",
            "  1.25000000e+02 2.00000000e+00]\n",
            " [9.35021250e+00 3.00000000e+00 9.20000000e+01 4.00000000e+00\n",
            "  6.11000000e+02 3.00000000e+00]\n",
            " [6.88406875e+00 5.00000000e+00 1.50000000e+01 3.00000000e+00\n",
            "  4.39000000e+02 2.00000000e+00]\n",
            " [1.09919000e+01 1.00000000e+00 1.13000000e+02 2.00000000e+00\n",
            "  3.83000000e+02 6.00000000e+00]\n",
            " [5.08460625e+00 1.00000000e+00 2.48000000e+02 1.00000000e+00\n",
            "  3.41000000e+02 3.00000000e+00]\n",
            " [2.27433750e+01 6.00000000e+00 0.00000000e+00 6.00000000e+00\n",
            "  1.14800000e+03 3.30000000e+01]\n",
            " [2.05480250e+01 6.00000000e+00 4.72000000e+02 2.30000000e+01\n",
            "  1.62400000e+03 6.00000000e+00]\n",
            " [1.39019250e+01 5.90000000e+01 2.62000000e+02 2.00000000e+00\n",
            "  5.85000000e+02 2.00000000e+00]\n",
            " [2.35176000e+01 0.00000000e+00 0.00000000e+00 5.00000000e+00\n",
            "  1.20600000e+03 3.70000000e+01]\n",
            " [1.57263500e+01 1.00000000e+00 1.09000000e+02 1.00000000e+00\n",
            "  8.15000000e+02 2.70000000e+01]\n",
            " [1.57069938e+01 0.00000000e+00 1.82000000e+02 2.00000000e+00\n",
            "  7.45000000e+02 2.10000000e+01]\n",
            " [6.54056875e+00 6.10000000e+01 3.09000000e+02 1.00000000e+00\n",
            "  4.46000000e+02 2.00000000e+00]\n",
            " [3.59238125e+01 8.00000000e+00 3.67000000e+02 2.40000000e+01\n",
            "  2.08600000e+03 6.00000000e+00]\n",
            " [2.42112563e+01 1.50000000e+01 6.22000000e+02 3.00000000e+00\n",
            "  1.17300000e+03 5.00000000e+00]\n",
            " [2.46515063e+01 4.20000000e+01 3.20000000e+01 5.00000000e+00\n",
            "  8.48000000e+02 9.00000000e+00]\n",
            " [8.40370625e+00 7.20000000e+01 0.00000000e+00 3.00000000e+00\n",
            "  5.29000000e+02 2.00000000e+00]\n",
            " [1.57263500e+01 1.00000000e+00 1.09000000e+02 1.00000000e+00\n",
            "  8.15000000e+02 2.70000000e+01]\n",
            " [2.34224625e+01 2.00000000e+00 1.31000000e+02 3.00000000e+00\n",
            "  1.14100000e+03 3.20000000e+01]\n",
            " [6.21448750e+00 5.00000000e+01 1.89000000e+02 4.00000000e+00\n",
            "  4.94000000e+02 2.30000000e+01]\n",
            " [3.37722563e+01 3.20000000e+01 1.23000000e+02 1.00000000e+00\n",
            "  1.70700000e+03 1.00000000e+01]\n",
            " [3.12610813e+01 4.00000000e+00 1.93000000e+02 1.00000000e+01\n",
            "  1.21600000e+03 1.30000000e+01]\n",
            " [3.95806875e+00 1.72000000e+02 8.60000000e+01 6.00000000e+00\n",
            "  1.80000000e+02 1.43000000e+02]\n",
            " [2.24050563e+01 1.00000000e+00 2.83000000e+02 2.00000000e+00\n",
            "  6.03000000e+02 4.00000000e+00]\n",
            " [1.81163125e+00 2.50000000e+01 1.72000000e+02 1.00000000e+00\n",
            "  0.00000000e+00 7.90000000e+01]\n",
            " [2.80787813e+01 6.00000000e+00 0.00000000e+00 3.00000000e+00\n",
            "  8.94000000e+02 9.00000000e+00]\n",
            " [1.75013938e+01 3.00000000e+00 1.00000000e+00 5.00000000e+00\n",
            "  9.48000000e+02 2.70000000e+01]\n",
            " [7.61456250e+00 2.10000000e+01 2.60000000e+02 4.00000000e+00\n",
            "  3.76000000e+02 2.00000000e+00]\n",
            " [1.25564438e+01 8.50000000e+01 0.00000000e+00 1.00000000e+00\n",
            "  4.59000000e+02 1.00000000e+01]\n",
            " [1.70566500e+01 1.40000000e+01 7.00000000e+00 1.10000000e+01\n",
            "  7.17000000e+02 1.60000000e+01]\n",
            " [2.38876500e+01 4.00000000e+00 2.00000000e+00 5.00000000e+00\n",
            "  1.00800000e+03 3.10000000e+01]\n",
            " [2.27433750e+01 6.00000000e+00 0.00000000e+00 6.00000000e+00\n",
            "  1.14800000e+03 3.30000000e+01]\n",
            " [2.27433750e+01 6.00000000e+00 0.00000000e+00 6.00000000e+00\n",
            "  1.14800000e+03 3.30000000e+01]\n",
            " [1.49892313e+01 4.10000000e+01 2.62000000e+02 1.00000000e+00\n",
            "  4.39000000e+02 3.00000000e+00]\n",
            " [2.46515063e+01 4.20000000e+01 3.20000000e+01 5.00000000e+00\n",
            "  8.48000000e+02 9.00000000e+00]\n",
            " [1.69975125e+01 3.00000000e+00 1.60000000e+02 8.00000000e+00\n",
            "  9.88000000e+02 7.00000000e+00]\n",
            " [2.92639125e+01 7.00000000e+00 0.00000000e+00 7.00000000e+00\n",
            "  1.13100000e+03 2.70000000e+01]\n",
            " [7.63301250e+00 4.00000000e+00 9.10000000e+01 2.00000000e+00\n",
            "  5.12000000e+02 1.40000000e+01]\n",
            " [4.66553125e+00 5.80000000e+01 0.00000000e+00 1.00000000e+00\n",
            "  2.99000000e+02 6.00000000e+00]\n",
            " [1.30034688e+01 3.40000000e+01 2.54000000e+02 5.00000000e+00\n",
            "  9.34000000e+02 1.90000000e+01]\n",
            " [2.92142500e+00 0.00000000e+00 3.00000000e+00 2.00000000e+00\n",
            "  2.79000000e+02 4.00000000e+00]\n",
            " [6.76505000e+00 5.60000000e+01 3.30000000e+01 1.00000000e+00\n",
            "  4.50000000e+02 3.00000000e+00]\n",
            " [1.78139688e+01 0.00000000e+00 2.00000000e+00 9.00000000e+00\n",
            "  1.12600000e+03 1.80000000e+01]]\n",
            "2880\n",
            "720\n",
            "2880\n",
            "720\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7KDFT7r-jzjQ",
        "outputId": "507c0b7e-56bc-4144-d7a5-bba5eeae5d5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "K899YhgSjzhB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(x_new))\n",
        "print(len(y_new))"
      ],
      "metadata": {
        "id": "O1udwtj2jzet",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17c9ec6a-6791-4c7c-9410-7f673342e865"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3600\n",
            "3600\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train=np.array(X_train)\n",
        "y_train=np.array(y_train)\n",
        "X_test=np.array(X_test)\n",
        "y_test=np.array(y_test)"
      ],
      "metadata": {
        "id": "NJNEwAmfETlD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print ('Train set:', X_train.shape,  y_train.shape)\n",
        "print ('Test set:', X_test.shape,  y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AvmzbrZXEXEY",
        "outputId": "ac5d34f8-8e74-4526-abbd-544c03dc122f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set: (2880, 6) (2880,)\n",
            "Test set: (720, 6) (720,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nsamples, nx = X_train.shape\n",
        "X_train = X_train.reshape((nsamples,nx))"
      ],
      "metadata": {
        "id": "nAzNYeEuEX5w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nT0QvIU3EvTm",
        "outputId": "29369d76-4ca7-4bb3-80e3-ef174218e001"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2880, 6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nsamples, nx = X_test.shape\n",
        "X_test = X_test.reshape((nsamples,nx))"
      ],
      "metadata": {
        "id": "2Ot-FXUpFCd5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bnuOKL1wFG0d",
        "outputId": "c65ff888-be69-47d6-d254-ee3eadbc853b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(720, 6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "E07e4aCBEsX_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_begin = time.time()\n",
        "clf = svm.SVC(kernel='linear')\n",
        "clf.fit(X_train, y_train) \n",
        "train_end = time.time()\n",
        "train_time = train_end - train_begin\n",
        "\n"
      ],
      "metadata": {
        "id": "KRmPNV2aM7bG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_begin = time.time()\n",
        "yhat = clf.predict(X_test)\n",
        "test_end = time.time()\n",
        "test_time = test_end - test_begin\n",
        "print(yhat)\n",
        "\n",
        "print(metrics.accuracy_score(y_test, yhat))\n",
        "print(confusion_matrix(y_test, yhat))\n",
        "print(classification_report(y_test, yhat))\n",
        "print(train_time)\n",
        "print(test_time)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BhsrrOlTHN3X",
        "outputId": "152af929-10b1-4a02-f6c0-ce8716c9fbb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 2 0 0 0 0 0 0 0 2 0 0 0\n",
            " 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 3 1 3 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 3 1 1 1 3 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3\n",
            " 1 3 1 1 3 5 3 4 1 3 2 3 5 3 3 3 3 3 1 3 3 3 3 1 3 3 3 3 3 3 3 3 1 3 3 3 3\n",
            " 3 3 3 3 3 1 1 3 3 3 3 3 3 3 1 3 3 3 3 5 3 3 3 3 1 3 1 3 3 3 3 3 3 3 3 1 3\n",
            " 3 3 3 1 3 5 3 1 1 3 3 3 3 3 3 3 1 3 3 3 3 3 3 3 3 3 1 1 1 3 5 1 3 3 3 3 4\n",
            " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
            " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
            " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
            " 4 4 4 4 4 4 4 4 1 5 5 5 3 5 5 5 5 3 5 5 5 5 5 5 3 5 5 5 3 5 3 5 5 5 5 3 3\n",
            " 5 5 5 3 3 5 5 5 5 5 5 5 5 5 5 3 5 5 5 5 5 3 5 5 5 5 5 5 5 5 5 5 5 4 5 5 3\n",
            " 5 5 5 5 5 5 5 3 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 3 5 5 5 2 5\n",
            " 5 5 5 5 5 5 2 3 5 5 5 5 5 3 3 5 5]\n",
            "0.9152777777777777\n",
            "[[114   0   6   0   0   0]\n",
            " [  0 116   0   4   0   0]\n",
            " [  2   0 118   0   0   0]\n",
            " [  0  21   1  92   1   5]\n",
            " [  0   0   0   0 120   0]\n",
            " [  0   1   2  17   1  99]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.95      0.97       120\n",
            "           1       0.84      0.97      0.90       120\n",
            "           2       0.93      0.98      0.96       120\n",
            "           3       0.81      0.77      0.79       120\n",
            "           4       0.98      1.00      0.99       120\n",
            "           5       0.95      0.82      0.88       120\n",
            "\n",
            "    accuracy                           0.92       720\n",
            "   macro avg       0.92      0.92      0.91       720\n",
            "weighted avg       0.92      0.92      0.91       720\n",
            "\n",
            "185.59272360801697\n",
            "0.01587963104248047\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_time)\n",
        "print(test_time/len(X_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7zsZjwX7Ksgh",
        "outputId": "69fee1c5-b61b-48dd-d694-2fd2ea9ac039"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "185.59272360801697\n",
            "2.2055043114556208e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clf = svm.SVC(kernel='rbf', gamma=\"scale\")\n",
        "clf.fit(X_train, y_train) \n",
        "yhat = clf.predict(X_test)\n",
        "print(yhat)\n",
        "\n",
        "print(metrics.accuracy_score(y_test, yhat))\n",
        "print(confusion_matrix(y_test, yhat))\n",
        "print(classification_report(y_test, yhat))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJq2DgC2nZ_R",
        "outputId": "956115cd-f102-4403-99d3-4dc99df14ae7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 0 0 0 0 0 2 0 0 2 0 0 2 0 2 2 2 0 0 2 0 0 0 0 2 0 0 2 0 0 0 2 0 0 0 2\n",
            " 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 2 2 0\n",
            " 0 2 0 0 0 4 0 0 2 2 0 2 2 0 0 0 2 0 0 0 2 0 0 0 0 0 0 0 0 2 2 2 0 0 0 4 0\n",
            " 0 0 0 0 0 2 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 5 2 2 2 5 2 2 2 5 2 2 2 2 2 5 0 2\n",
            " 2 2 1 2 2 0 2 4 2 5 2 2 5 2 0 0 2 2 2 2 2 2 0 2 2 2 2 2 2 5 2 2 2 0 5 0 2\n",
            " 2 2 2 2 2 0 2 2 2 2 2 2 4 2 2 2 2 0 2 2 2 5 2 2 0 2 2 2 2 2 2 2 0 5 2 2 2\n",
            " 5 2 5 2 0 5 2 1 2 1 2 2 2 2 2 2 0 2 0 2 2 2 2 2 2 2 2 1 3 1 1 1 1 5 3 5 1\n",
            " 1 5 1 5 1 1 1 1 5 5 5 3 4 5 4 5 1 3 1 1 1 1 5 1 2 1 2 3 1 3 5 5 1 3 2 3 3\n",
            " 3 3 2 3 1 1 1 1 5 1 2 5 5 1 5 3 5 1 4 4 3 3 5 2 5 5 1 1 5 1 3 1 5 1 1 5 2\n",
            " 4 1 1 1 3 3 5 3 2 5 1 5 3 1 5 1 1 5 5 1 1 5 1 4 1 1 5 1 3 1 1 1 1 1 1 1 4\n",
            " 4 4 4 4 4 4 4 1 1 4 1 4 1 1 4 4 1 4 4 4 1 4 4 4 4 4 4 4 4 4 4 4 1 4 4 4 4\n",
            " 4 4 1 4 4 4 4 1 4 4 4 4 4 4 4 4 1 1 1 4 4 4 1 4 3 4 4 4 4 4 4 4 1 4 4 1 4\n",
            " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 1 4 4 1 1 1 4 1 1\n",
            " 3 1 4 4 4 4 4 1 5 5 5 5 5 5 5 5 1 5 3 5 1 5 5 5 3 5 1 5 5 5 5 1 5 5 5 5 5\n",
            " 5 5 5 5 5 5 5 5 5 3 5 5 5 5 5 5 5 5 5 5 5 5 1 5 5 1 5 5 5 5 5 1 1 5 5 5 5\n",
            " 5 5 5 5 5 5 1 5 5 1 5 5 5 1 5 1 5 5 5 3 5 5 5 5 5 1 5 5 5 5 5 5 5 5 5 5 5\n",
            " 5 5 1 5 5 5 5 5 5 1 5 5 5 5 3 5 5]\n",
            "0.7138888888888889\n",
            "[[ 91   0  27   0   2   0]\n",
            " [  0 120   0   0   0   0]\n",
            " [ 14   3  88   0   2  13]\n",
            " [  0  54   8  21   6  31]\n",
            " [  0  24   0   2  94   0]\n",
            " [  0  15   0   5   0 100]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.76      0.81       120\n",
            "           1       0.56      1.00      0.71       120\n",
            "           2       0.72      0.73      0.72       120\n",
            "           3       0.75      0.17      0.28       120\n",
            "           4       0.90      0.78      0.84       120\n",
            "           5       0.69      0.83      0.76       120\n",
            "\n",
            "    accuracy                           0.71       720\n",
            "   macro avg       0.75      0.71      0.69       720\n",
            "weighted avg       0.75      0.71      0.69       720\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clf = svm.SVC(kernel='rbf', gamma=\"auto\")\n",
        "clf.fit(X_train, y_train) \n",
        "yhat = clf.predict(X_test)\n",
        "print(yhat)\n",
        "\n",
        "print(metrics.accuracy_score(y_test, yhat))\n",
        "print(confusion_matrix(y_test, yhat))\n",
        "print(classification_report(y_test, yhat))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bZZPyqQDneq7",
        "outputId": "c7990595-af80-45b5-b322-d1d6da825339"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 0 0 0 0 2 0 2 0 2 0 0 0 0 0 0 2 0 0 0 0 2 0 0 0 0 0 2 0 0 2 2 0 2 2 0\n",
            " 0 0 2 0 0 0 2 0 2 0 2 0 2 2 0 2 0 0 2 0 2 0 2 0 0 2 0 0 0 0 0 0 2 0 2 2 0\n",
            " 0 2 0 2 0 2 2 2 0 0 0 0 0 0 2 2 2 0 0 2 2 0 2 0 2 2 0 0 2 0 0 0 0 0 0 0 0\n",
            " 0 2 0 0 0 0 0 2 0 1 1 1 2 1 1 1 1 1 1 1 1 1 1 2 1 1 2 1 2 1 1 1 1 1 1 1 1\n",
            " 2 1 2 1 1 1 2 2 1 1 1 2 1 1 1 2 2 1 1 1 1 1 2 1 1 1 1 1 1 2 1 1 1 2 1 1 1\n",
            " 1 1 1 1 2 1 1 1 1 2 1 2 1 1 1 1 1 1 2 2 1 1 1 1 2 1 2 1 1 1 1 1 1 2 1 1 2\n",
            " 1 1 1 1 1 2 1 1 1 1 1 1 1 2 2 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 2 3 2 3 3 3 2 3 3\n",
            " 2 3 3 3 3 3 2 2 3 3 3 3 2 3 3 3 3 3 3 3 3 2 3 3 2 2 3 3 2 2 3 2 3 2 2 3 2\n",
            " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 3 3 2 3 3 3 3 3 3 2 3 3 3 3 2 3 3 3 3 3 3\n",
            " 2 3 3 3 2 2 2 2 2 2 3 3 3 3 2 3 3 2 3 3 3 3 3 3 2 3 3 3 3 3 3 3 3 3 3 2 2\n",
            " 2 2 4 4 4 4 2 2 4 2 4 4 4 4 4 4 4 4 4 2 4 4 4 2 4 2 4 4 4 4 4 2 4 2 4 4 4\n",
            " 4 4 4 2 4 4 4 2 4 4 2 2 2 4 4 4 4 4 4 4 4 4 4 4 2 4 2 2 2 2 4 2 2 4 4 4 4\n",
            " 4 4 4 4 4 4 4 4 4 4 2 4 4 4 4 4 4 4 4 2 2 2 2 4 2 4 4 2 4 2 4 4 4 4 2 4 4\n",
            " 2 4 2 4 2 2 4 2 2 5 5 5 5 5 5 5 2 5 2 5 5 5 5 5 5 5 5 2 5 5 2 5 5 5 5 5 5\n",
            " 5 5 5 5 5 5 5 5 5 5 2 5 5 5 5 5 5 5 5 5 2 5 5 5 2 5 5 5 2 5 5 5 5 5 2 5 5\n",
            " 5 5 2 5 5 2 5 5 5 5 2 5 5 5 5 2 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 2 5 2 5\n",
            " 5 5 5 5 5 5 5 2 5 2 5 5 5 5 2 2 5]\n",
            "0.7861111111111111\n",
            "[[ 80   0  40   0   0   0]\n",
            " [  0  94  26   0   0   0]\n",
            " [  0   0 120   0   0   0]\n",
            " [  0   0  31  89   0   0]\n",
            " [  0   0  37   0  83   0]\n",
            " [  0   0  20   0   0 100]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.67      0.80       120\n",
            "           1       1.00      0.78      0.88       120\n",
            "           2       0.44      1.00      0.61       120\n",
            "           3       1.00      0.74      0.85       120\n",
            "           4       1.00      0.69      0.82       120\n",
            "           5       1.00      0.83      0.91       120\n",
            "\n",
            "    accuracy                           0.79       720\n",
            "   macro avg       0.91      0.79      0.81       720\n",
            "weighted avg       0.91      0.79      0.81       720\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "poly_svc = svm.SVC(kernel='poly', degree=5).fit(X_train, y_train)\n",
        "yhat = poly_svc.predict(X_test)\n",
        "print(yhat)\n",
        "print(metrics.accuracy_score(y_test, yhat))\n",
        "print(confusion_matrix(y_test, yhat))\n",
        "print(classification_report(y_test, yhat))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qxQSN0DYngIp",
        "outputId": "7cc12bd0-9530-4278-d5cc-50eb6e4718d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 3 0 0 5 0 0 0 0 0 0 5 0 0 5 0 0 0 2 0 0 0 0 5 0 2 0 3 0 0 0 0 2 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 2 5 0 0 0 0 2 5 0 0 0 0 0 0 0\n",
            " 0 0 0 0 5 1 0 0 2 0 0 0 2 0 0 0 0 3 5 0 0 0 0 0 0 0 0 0 0 2 0 0 5 0 0 1 0\n",
            " 3 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 2 2 2 1 2 2 2 1 2 0 2 0 2 1 2 2\n",
            " 2 2 1 2 2 2 5 1 2 1 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 1 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 3 2 2 2 2 2 1 2 3 3 2 2 2 2 2 2 2 5 1 2 2 2\n",
            " 1 2 1 2 3 1 3 1 3 1 2 2 5 2 2 0 3 2 2 2 2 2 0 2 2 2 2 1 4 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 4 1 1 1 1 1 1 3 1 3 4 1 4 1 1 1 1 3 3 1\n",
            " 1 4 3 1 1 1 1 1 1 1 3 1 1 1 1 4 1 1 1 1 1 3 1 3 1 1 1 1 1 1 3 1 1 1 1 1 3\n",
            " 1 1 1 1 4 3 1 3 3 1 1 1 3 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "0.4444444444444444\n",
            "[[ 96   2   8   5   0   9]\n",
            " [  0 120   0   0   0   0]\n",
            " [  4  18  88   7   0   3]\n",
            " [  0  97   0  16   7   0]\n",
            " [  0 120   0   0   0   0]\n",
            " [  0 120   0   0   0   0]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.80      0.87       120\n",
            "           1       0.25      1.00      0.40       120\n",
            "           2       0.92      0.73      0.81       120\n",
            "           3       0.57      0.13      0.22       120\n",
            "           4       0.00      0.00      0.00       120\n",
            "           5       0.00      0.00      0.00       120\n",
            "\n",
            "    accuracy                           0.44       720\n",
            "   macro avg       0.45      0.44      0.38       720\n",
            "weighted avg       0.45      0.44      0.38       720\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(1,8) :\n",
        "    poly_svc = svm.SVC(kernel='poly', degree=i).fit(X_train, y_train)\n",
        "    yhat = poly_svc.predict(X_test)\n",
        "    print(yhat)\n",
        "    print('Degree = ',i, metrics.accuracy_score(y_test, yhat))\n",
        "    # print(confusion_matrix(y_test, yhat))\n",
        "    # print(classification_report(y_test, yhat))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zaPZAKyWnhfg",
        "outputId": "e35d7584-523c-4128-d1c8-526b0502c651"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 2 0 0 2 0 0 0 0 0 2 2 0 0 0 2 2 0 2 0 0 0 0 2 0 2 0 2 0 0 0 0 2 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 2 2 0 0 2 0 2 2 0 0 0 0 2 0 0\n",
            " 0 2 0 0 2 4 0 0 2 0 0 0 2 0 0 0 2 2 2 0 0 0 0 0 0 0 0 0 0 2 0 0 2 0 0 4 0\n",
            " 2 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 5 2 2 2 5 2 2 2 5 2 2 2 0 2 5 0 2\n",
            " 2 2 1 2 2 0 3 4 2 1 2 2 5 2 0 0 2 2 2 2 2 2 0 2 2 2 2 2 2 5 2 2 2 0 5 0 2\n",
            " 2 2 2 2 2 0 2 2 2 2 2 2 4 2 2 2 2 0 0 2 2 1 2 2 2 2 2 2 0 2 2 2 0 5 2 2 2\n",
            " 1 2 5 2 2 5 2 1 2 1 2 2 3 2 2 2 2 2 0 2 2 2 2 2 2 2 2 1 3 1 1 1 1 5 5 3 1\n",
            " 1 5 1 5 1 1 1 1 5 5 5 2 5 5 4 5 1 3 1 1 1 1 5 1 2 1 2 3 1 3 5 5 1 3 2 3 5\n",
            " 5 3 2 5 1 1 1 1 5 1 2 5 5 1 5 3 5 1 5 4 5 3 3 2 5 5 1 1 5 1 3 1 3 1 1 5 2\n",
            " 4 1 1 1 3 3 5 3 2 3 1 5 3 1 5 1 1 5 5 1 1 5 1 4 1 1 5 1 2 1 1 1 1 1 1 1 4\n",
            " 1 4 4 4 4 1 4 1 1 4 1 3 1 1 1 4 1 4 4 4 1 4 4 4 4 4 3 4 4 4 4 4 1 4 4 4 4\n",
            " 4 4 1 1 4 4 4 1 4 4 4 4 1 4 4 4 1 1 1 4 1 4 1 4 4 1 4 4 4 4 4 4 1 4 4 1 1\n",
            " 4 4 4 4 4 1 1 4 4 4 4 4 4 4 4 4 4 3 3 1 4 4 4 4 3 4 1 4 1 3 4 1 1 1 4 1 1\n",
            " 4 1 4 4 3 3 1 1 5 5 5 5 5 5 5 5 1 5 1 5 1 5 1 5 5 5 1 5 5 1 5 1 5 5 5 5 5\n",
            " 5 5 5 5 5 5 5 5 5 5 5 5 5 1 5 5 5 5 5 5 5 5 1 5 5 1 1 5 5 5 5 1 1 5 5 5 5\n",
            " 5 5 5 5 5 5 1 5 1 1 5 5 5 1 5 1 5 5 5 5 1 5 5 5 5 1 5 5 1 5 1 5 5 5 5 5 5\n",
            " 5 5 1 5 5 5 5 5 5 1 5 5 5 5 1 5 5]\n",
            "Degree =  1 0.6722222222222223\n",
            "[2 2 0 0 2 0 0 0 0 0 2 3 0 2 3 0 2 0 2 0 0 0 0 3 0 2 0 2 0 0 0 0 2 0 0 0 0\n",
            " 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 2 2 0 0 2 0 2 2 0 0 0 0 0 0 0\n",
            " 0 0 0 0 3 1 0 0 2 0 0 2 2 0 0 0 2 2 3 0 0 0 0 0 0 0 0 0 0 2 0 0 2 0 0 1 0\n",
            " 2 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 2 2 2 5 2 2 2 1 2 2 2 2 2 1 2 2\n",
            " 2 2 1 2 2 2 3 1 2 1 2 2 4 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 4 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 3 5 2 2 2\n",
            " 1 2 4 2 2 1 2 1 2 1 2 2 3 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 3 1 1 1 1 1 1 4 1\n",
            " 1 1 1 4 1 1 1 1 4 4 1 3 4 1 1 5 1 3 1 1 1 1 1 1 3 1 2 3 1 3 1 1 1 5 3 3 1\n",
            " 1 3 2 1 1 1 1 1 1 1 2 1 1 1 1 3 1 1 1 1 1 3 5 3 1 1 1 1 5 1 3 1 5 1 1 1 2\n",
            " 1 1 1 1 3 3 1 3 2 5 1 5 3 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 4 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 4 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 4 1 1 1 1 1 4 5 1 1 1 1 1 1 1 1 1 1 4 4 1 1 1 1 1 1\n",
            " 1 1 1 1 4 4 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 5 1 1 1\n",
            " 1 1 1 1 1 5 1 1 1 1 1 1 1 1 1 4 1 5 1 5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 5 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 5 1 1 1 1 1 1 1 5 1 1 1]\n",
            "Degree =  2 0.4722222222222222\n",
            "[2 3 0 0 3 0 0 0 0 0 2 3 0 0 5 0 0 0 2 0 0 0 0 5 0 2 0 2 0 0 0 0 2 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 2 3 0 0 2 0 2 3 0 0 0 0 0 0 0\n",
            " 0 0 0 0 3 1 0 0 2 0 0 2 2 0 0 0 2 3 5 0 0 0 0 0 0 0 0 0 0 2 0 0 3 0 0 1 0\n",
            " 3 0 0 0 0 0 0 2 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 2 2 2 1 2 2 2 1 2 0 2 2 2 1 2 2\n",
            " 2 2 1 2 2 2 5 1 2 1 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 1 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 1 2 3 2 2 2 2 2 2 2 2 5 5 2 2 2\n",
            " 1 2 1 2 2 1 2 1 2 1 2 2 5 2 2 0 2 2 2 2 2 2 2 2 2 2 2 1 3 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 3 1 1 1 5 1 3 1 1 1 1 1 1 3 1 3 3 1 5 1 1 1 4 3 3 1\n",
            " 1 3 3 1 1 1 1 1 1 1 2 1 1 1 1 3 1 1 1 1 1 3 1 3 1 1 1 1 5 1 3 1 1 1 1 1 2\n",
            " 1 1 1 1 3 3 1 3 2 1 1 5 3 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "Degree =  3 0.4513888888888889\n",
            "[0 3 0 0 5 0 0 0 0 0 0 5 0 0 5 0 0 0 2 0 0 0 0 5 0 2 0 3 0 0 0 0 2 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 2 5 0 0 0 0 2 3 0 0 0 0 0 0 0\n",
            " 0 0 0 0 5 1 0 0 2 0 0 0 2 0 0 0 0 3 5 0 0 0 0 0 0 0 0 0 0 2 0 0 5 0 0 1 0\n",
            " 3 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 2 2 2 1 2 2 2 1 2 0 2 0 2 1 2 2\n",
            " 2 2 1 2 2 2 5 1 2 1 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 1 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 1 2 3 2 2 2 2 2 2 2 2 5 5 2 2 2\n",
            " 1 2 1 2 2 1 3 1 2 1 2 2 5 2 2 0 2 2 2 2 2 2 0 2 2 2 2 1 4 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 4 1 1 1 1 1 1 3 1 3 4 1 4 1 1 1 1 3 3 1\n",
            " 1 5 3 1 1 1 1 1 1 1 3 1 1 1 1 4 1 1 1 1 1 3 1 3 1 1 1 1 1 1 3 1 1 1 1 1 3\n",
            " 1 1 1 1 5 3 1 3 3 1 1 1 3 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "Degree =  4 0.4513888888888889\n",
            "[0 3 0 0 5 0 0 0 0 0 0 5 0 0 5 0 0 0 2 0 0 0 0 5 0 2 0 3 0 0 0 0 2 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 2 5 0 0 0 0 2 5 0 0 0 0 0 0 0\n",
            " 0 0 0 0 5 1 0 0 2 0 0 0 2 0 0 0 0 3 5 0 0 0 0 0 0 0 0 0 0 2 0 0 5 0 0 1 0\n",
            " 3 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 2 2 2 1 2 2 2 1 2 0 2 0 2 1 2 2\n",
            " 2 2 1 2 2 2 5 1 2 1 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 1 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 3 2 2 2 2 2 1 2 3 3 2 2 2 2 2 2 2 5 1 2 2 2\n",
            " 1 2 1 2 3 1 3 1 3 1 2 2 5 2 2 0 3 2 2 2 2 2 0 2 2 2 2 1 4 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 4 1 1 1 1 1 1 3 1 3 4 1 4 1 1 1 1 3 3 1\n",
            " 1 4 3 1 1 1 1 1 1 1 3 1 1 1 1 4 1 1 1 1 1 3 1 3 1 1 1 1 1 1 3 1 1 1 1 1 3\n",
            " 1 1 1 1 4 3 1 3 3 1 1 1 3 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "Degree =  5 0.4444444444444444\n",
            "[0 5 0 0 5 0 0 0 0 0 2 5 0 0 5 0 0 0 2 0 0 0 0 5 0 2 0 5 0 0 0 0 2 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 5 0 0 2 5 0 0 2 0 2 5 0 0 0 0 0 0 0\n",
            " 0 0 0 0 5 1 0 0 2 0 0 0 2 0 0 0 2 5 5 0 0 0 0 0 0 0 0 0 0 2 0 0 5 0 0 1 0\n",
            " 5 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 2 2 2 1 2 2 2 1 2 0 2 0 2 1 2 2\n",
            " 2 2 1 2 2 2 5 1 2 1 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 1 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 3 2 2 2 2 2 1 2 3 3 2 2 2 2 2 2 2 5 1 2 2 2\n",
            " 1 2 1 2 3 1 3 1 3 1 2 2 5 2 2 0 3 2 2 2 2 2 2 2 2 2 2 1 4 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 4 1 1 1 1 1 1 3 1 3 4 1 4 1 1 1 1 3 4 1\n",
            " 1 4 3 1 1 1 1 1 1 1 3 1 1 1 1 4 1 1 1 1 1 3 1 3 1 1 1 1 1 1 3 1 1 1 1 1 3\n",
            " 1 1 1 1 4 3 1 3 3 1 1 1 3 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "Degree =  6 0.44027777777777777\n",
            "[0 4 0 0 5 0 0 0 0 0 2 5 0 0 5 0 0 0 2 0 0 0 0 5 0 2 0 4 0 0 0 0 2 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0 2 5 0 0 2 0 2 4 0 0 0 0 0 0 0\n",
            " 0 0 0 0 5 1 0 0 2 0 0 0 2 0 0 0 2 4 5 0 0 0 0 0 0 0 0 0 0 2 0 0 5 0 0 1 0\n",
            " 4 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 2 2 2 1 2 2 2 1 2 0 2 0 2 1 2 2\n",
            " 2 2 1 2 2 2 5 1 2 1 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 1 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 3 2 2 2 2 2 1 2 3 3 2 2 2 2 2 2 2 5 1 2 2 2\n",
            " 1 2 1 2 3 1 3 1 3 1 2 2 5 2 2 0 3 2 2 2 2 2 2 2 2 2 2 1 4 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 4 1 1 1 1 1 1 3 1 3 4 1 1 1 1 1 1 3 4 1\n",
            " 1 4 3 1 1 1 1 1 1 1 2 1 1 1 1 4 1 1 1 1 1 4 1 3 1 1 1 1 1 1 3 1 1 1 1 1 2\n",
            " 1 1 1 1 4 3 1 3 2 1 1 1 3 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "Degree =  7 0.43472222222222223\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "poly_svc = svm.SVC(kernel='poly', degree=1).fit(X_train, y_train)\n",
        "yhat = poly_svc.predict(X_test)\n",
        "print(yhat)\n",
        "print(metrics.accuracy_score(y_test, yhat))\n",
        "print(confusion_matrix(y_test, yhat))\n",
        "print(classification_report(y_test, yhat))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mTA_PGQeninc",
        "outputId": "410aed10-ebd6-4e1c-9828-6cad41e0f96f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 2 0 0 2 0 0 0 0 0 2 2 0 0 0 2 2 0 2 0 0 0 0 2 0 2 0 2 0 0 0 0 2 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 2 2 0 0 2 0 2 2 0 0 0 0 2 0 0\n",
            " 0 2 0 0 2 4 0 0 2 0 0 0 2 0 0 0 2 2 2 0 0 0 0 0 0 0 0 0 0 2 0 0 2 0 0 4 0\n",
            " 2 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 5 2 2 2 5 2 2 2 5 2 2 2 0 2 5 0 2\n",
            " 2 2 1 2 2 0 3 4 2 1 2 2 5 2 0 0 2 2 2 2 2 2 0 2 2 2 2 2 2 5 2 2 2 0 5 0 2\n",
            " 2 2 2 2 2 0 2 2 2 2 2 2 4 2 2 2 2 0 0 2 2 1 2 2 2 2 2 2 0 2 2 2 0 5 2 2 2\n",
            " 1 2 5 2 2 5 2 1 2 1 2 2 3 2 2 2 2 2 0 2 2 2 2 2 2 2 2 1 3 1 1 1 1 5 5 3 1\n",
            " 1 5 1 5 1 1 1 1 5 5 5 2 5 5 4 5 1 3 1 1 1 1 5 1 2 1 2 3 1 3 5 5 1 3 2 3 5\n",
            " 5 3 2 5 1 1 1 1 5 1 2 5 5 1 5 3 5 1 5 4 5 3 3 2 5 5 1 1 5 1 3 1 3 1 1 5 2\n",
            " 4 1 1 1 3 3 5 3 2 3 1 5 3 1 5 1 1 5 5 1 1 5 1 4 1 1 5 1 2 1 1 1 1 1 1 1 4\n",
            " 1 4 4 4 4 1 4 1 1 4 1 3 1 1 1 4 1 4 4 4 1 4 4 4 4 4 3 4 4 4 4 4 1 4 4 4 4\n",
            " 4 4 1 1 4 4 4 1 4 4 4 4 1 4 4 4 1 1 1 4 1 4 1 4 4 1 4 4 4 4 4 4 1 4 4 1 1\n",
            " 4 4 4 4 4 1 1 4 4 4 4 4 4 4 4 4 4 3 3 1 4 4 4 4 3 4 1 4 1 3 4 1 1 1 4 1 1\n",
            " 4 1 4 4 3 3 1 1 5 5 5 5 5 5 5 5 1 5 1 5 1 5 1 5 5 5 1 5 5 1 5 1 5 5 5 5 5\n",
            " 5 5 5 5 5 5 5 5 5 5 5 5 5 1 5 5 5 5 5 5 5 5 1 5 5 1 1 5 5 5 5 1 1 5 5 5 5\n",
            " 5 5 5 5 5 5 1 5 1 1 5 5 5 1 5 1 5 5 5 5 1 5 5 5 5 1 5 5 1 5 1 5 5 5 5 5 5\n",
            " 5 5 1 5 5 5 5 5 5 1 5 5 5 5 1 5 5]\n",
            "0.6722222222222223\n",
            "[[ 90   0  28   0   2   0]\n",
            " [  0 120   0   0   0   0]\n",
            " [ 14   6  86   2   2  10]\n",
            " [  0  54  10  18   4  34]\n",
            " [  0  37   0   8  75   0]\n",
            " [  0  25   0   0   0  95]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.75      0.80       120\n",
            "           1       0.50      1.00      0.66       120\n",
            "           2       0.69      0.72      0.70       120\n",
            "           3       0.64      0.15      0.24       120\n",
            "           4       0.90      0.62      0.74       120\n",
            "           5       0.68      0.79      0.73       120\n",
            "\n",
            "    accuracy                           0.67       720\n",
            "   macro avg       0.71      0.67      0.65       720\n",
            "weighted avg       0.71      0.67      0.65       720\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "05iyJw_poRb_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# k Fold cross validation\n",
        "# k fold cross validation\n",
        "from sklearn.model_selection import KFold,RepeatedKFold \n",
        "kf = RepeatedKFold(n_splits=5, n_repeats=10, random_state=2652124) \n",
        "\n",
        "for train_index, test_index in kf.split(x_new):\n",
        "      #print(\"Train:\", train_index, \"Validation:\",test_index)\n",
        "      #X_train_new, X_test_new = x_new[train_index], x_new[test_index] \n",
        "      X_train_new, X_test_new = np.array(x_new)[train_index.astype(int)], np.array(x_new)[test_index.astype(int)]\n",
        "      #y_train_new, y_test_new = y_new[train_index], y_new[test_index]\n",
        "      y_train_new, y_test_new = np.array(y_new)[train_index.astype(int)], np.array(y_new)[test_index.astype(int)]\n",
        "      \n",
        "      \n",
        "      clf = svm.SVC(kernel='linear')\n",
        "      clf.fit(X_train, y_train) \n",
        "      yhat = clf.predict(X_test)\n",
        "      print(metrics.accuracy_score(y_test, yhat))\n",
        "      print(confusion_matrix(y_test, yhat))\n",
        "      print(classification_report(y_test, yhat))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RfYGFcZVgyOn",
        "outputId": "a3d45e32-c5cc-4728-e3bf-cb36f8be2233"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9291666666666667\n",
            "[[119   0   1   0   0   0]\n",
            " [  0 114   0   5   0   1]\n",
            " [  8   0 112   0   0   0]\n",
            " [  0  18   0 101   0   1]\n",
            " [  0   0   2   0 118   0]\n",
            " [  0   6   0   9   0 105]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.99      0.96       120\n",
            "           1       0.83      0.95      0.88       120\n",
            "           2       0.97      0.93      0.95       120\n",
            "           3       0.88      0.84      0.86       120\n",
            "           4       1.00      0.98      0.99       120\n",
            "           5       0.98      0.88      0.93       120\n",
            "\n",
            "    accuracy                           0.93       720\n",
            "   macro avg       0.93      0.93      0.93       720\n",
            "weighted avg       0.93      0.93      0.93       720\n",
            "\n",
            "0.9291666666666667\n",
            "[[119   0   1   0   0   0]\n",
            " [  0 114   0   5   0   1]\n",
            " [  8   0 112   0   0   0]\n",
            " [  0  18   0 101   0   1]\n",
            " [  0   0   2   0 118   0]\n",
            " [  0   6   0   9   0 105]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.99      0.96       120\n",
            "           1       0.83      0.95      0.88       120\n",
            "           2       0.97      0.93      0.95       120\n",
            "           3       0.88      0.84      0.86       120\n",
            "           4       1.00      0.98      0.99       120\n",
            "           5       0.98      0.88      0.93       120\n",
            "\n",
            "    accuracy                           0.93       720\n",
            "   macro avg       0.93      0.93      0.93       720\n",
            "weighted avg       0.93      0.93      0.93       720\n",
            "\n",
            "0.9291666666666667\n",
            "[[119   0   1   0   0   0]\n",
            " [  0 114   0   5   0   1]\n",
            " [  8   0 112   0   0   0]\n",
            " [  0  18   0 101   0   1]\n",
            " [  0   0   2   0 118   0]\n",
            " [  0   6   0   9   0 105]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.99      0.96       120\n",
            "           1       0.83      0.95      0.88       120\n",
            "           2       0.97      0.93      0.95       120\n",
            "           3       0.88      0.84      0.86       120\n",
            "           4       1.00      0.98      0.99       120\n",
            "           5       0.98      0.88      0.93       120\n",
            "\n",
            "    accuracy                           0.93       720\n",
            "   macro avg       0.93      0.93      0.93       720\n",
            "weighted avg       0.93      0.93      0.93       720\n",
            "\n",
            "0.9291666666666667\n",
            "[[119   0   1   0   0   0]\n",
            " [  0 114   0   5   0   1]\n",
            " [  8   0 112   0   0   0]\n",
            " [  0  18   0 101   0   1]\n",
            " [  0   0   2   0 118   0]\n",
            " [  0   6   0   9   0 105]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.99      0.96       120\n",
            "           1       0.83      0.95      0.88       120\n",
            "           2       0.97      0.93      0.95       120\n",
            "           3       0.88      0.84      0.86       120\n",
            "           4       1.00      0.98      0.99       120\n",
            "           5       0.98      0.88      0.93       120\n",
            "\n",
            "    accuracy                           0.93       720\n",
            "   macro avg       0.93      0.93      0.93       720\n",
            "weighted avg       0.93      0.93      0.93       720\n",
            "\n",
            "0.9291666666666667\n",
            "[[119   0   1   0   0   0]\n",
            " [  0 114   0   5   0   1]\n",
            " [  8   0 112   0   0   0]\n",
            " [  0  18   0 101   0   1]\n",
            " [  0   0   2   0 118   0]\n",
            " [  0   6   0   9   0 105]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.99      0.96       120\n",
            "           1       0.83      0.95      0.88       120\n",
            "           2       0.97      0.93      0.95       120\n",
            "           3       0.88      0.84      0.86       120\n",
            "           4       1.00      0.98      0.99       120\n",
            "           5       0.98      0.88      0.93       120\n",
            "\n",
            "    accuracy                           0.93       720\n",
            "   macro avg       0.93      0.93      0.93       720\n",
            "weighted avg       0.93      0.93      0.93       720\n",
            "\n",
            "0.9291666666666667\n",
            "[[119   0   1   0   0   0]\n",
            " [  0 114   0   5   0   1]\n",
            " [  8   0 112   0   0   0]\n",
            " [  0  18   0 101   0   1]\n",
            " [  0   0   2   0 118   0]\n",
            " [  0   6   0   9   0 105]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.99      0.96       120\n",
            "           1       0.83      0.95      0.88       120\n",
            "           2       0.97      0.93      0.95       120\n",
            "           3       0.88      0.84      0.86       120\n",
            "           4       1.00      0.98      0.99       120\n",
            "           5       0.98      0.88      0.93       120\n",
            "\n",
            "    accuracy                           0.93       720\n",
            "   macro avg       0.93      0.93      0.93       720\n",
            "weighted avg       0.93      0.93      0.93       720\n",
            "\n",
            "0.9291666666666667\n",
            "[[119   0   1   0   0   0]\n",
            " [  0 114   0   5   0   1]\n",
            " [  8   0 112   0   0   0]\n",
            " [  0  18   0 101   0   1]\n",
            " [  0   0   2   0 118   0]\n",
            " [  0   6   0   9   0 105]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.99      0.96       120\n",
            "           1       0.83      0.95      0.88       120\n",
            "           2       0.97      0.93      0.95       120\n",
            "           3       0.88      0.84      0.86       120\n",
            "           4       1.00      0.98      0.99       120\n",
            "           5       0.98      0.88      0.93       120\n",
            "\n",
            "    accuracy                           0.93       720\n",
            "   macro avg       0.93      0.93      0.93       720\n",
            "weighted avg       0.93      0.93      0.93       720\n",
            "\n",
            "0.9291666666666667\n",
            "[[119   0   1   0   0   0]\n",
            " [  0 114   0   5   0   1]\n",
            " [  8   0 112   0   0   0]\n",
            " [  0  18   0 101   0   1]\n",
            " [  0   0   2   0 118   0]\n",
            " [  0   6   0   9   0 105]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.99      0.96       120\n",
            "           1       0.83      0.95      0.88       120\n",
            "           2       0.97      0.93      0.95       120\n",
            "           3       0.88      0.84      0.86       120\n",
            "           4       1.00      0.98      0.99       120\n",
            "           5       0.98      0.88      0.93       120\n",
            "\n",
            "    accuracy                           0.93       720\n",
            "   macro avg       0.93      0.93      0.93       720\n",
            "weighted avg       0.93      0.93      0.93       720\n",
            "\n",
            "0.9291666666666667\n",
            "[[119   0   1   0   0   0]\n",
            " [  0 114   0   5   0   1]\n",
            " [  8   0 112   0   0   0]\n",
            " [  0  18   0 101   0   1]\n",
            " [  0   0   2   0 118   0]\n",
            " [  0   6   0   9   0 105]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.99      0.96       120\n",
            "           1       0.83      0.95      0.88       120\n",
            "           2       0.97      0.93      0.95       120\n",
            "           3       0.88      0.84      0.86       120\n",
            "           4       1.00      0.98      0.99       120\n",
            "           5       0.98      0.88      0.93       120\n",
            "\n",
            "    accuracy                           0.93       720\n",
            "   macro avg       0.93      0.93      0.93       720\n",
            "weighted avg       0.93      0.93      0.93       720\n",
            "\n",
            "0.9291666666666667\n",
            "[[119   0   1   0   0   0]\n",
            " [  0 114   0   5   0   1]\n",
            " [  8   0 112   0   0   0]\n",
            " [  0  18   0 101   0   1]\n",
            " [  0   0   2   0 118   0]\n",
            " [  0   6   0   9   0 105]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.99      0.96       120\n",
            "           1       0.83      0.95      0.88       120\n",
            "           2       0.97      0.93      0.95       120\n",
            "           3       0.88      0.84      0.86       120\n",
            "           4       1.00      0.98      0.99       120\n",
            "           5       0.98      0.88      0.93       120\n",
            "\n",
            "    accuracy                           0.93       720\n",
            "   macro avg       0.93      0.93      0.93       720\n",
            "weighted avg       0.93      0.93      0.93       720\n",
            "\n",
            "0.9291666666666667\n",
            "[[119   0   1   0   0   0]\n",
            " [  0 114   0   5   0   1]\n",
            " [  8   0 112   0   0   0]\n",
            " [  0  18   0 101   0   1]\n",
            " [  0   0   2   0 118   0]\n",
            " [  0   6   0   9   0 105]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.99      0.96       120\n",
            "           1       0.83      0.95      0.88       120\n",
            "           2       0.97      0.93      0.95       120\n",
            "           3       0.88      0.84      0.86       120\n",
            "           4       1.00      0.98      0.99       120\n",
            "           5       0.98      0.88      0.93       120\n",
            "\n",
            "    accuracy                           0.93       720\n",
            "   macro avg       0.93      0.93      0.93       720\n",
            "weighted avg       0.93      0.93      0.93       720\n",
            "\n",
            "0.9291666666666667\n",
            "[[119   0   1   0   0   0]\n",
            " [  0 114   0   5   0   1]\n",
            " [  8   0 112   0   0   0]\n",
            " [  0  18   0 101   0   1]\n",
            " [  0   0   2   0 118   0]\n",
            " [  0   6   0   9   0 105]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.99      0.96       120\n",
            "           1       0.83      0.95      0.88       120\n",
            "           2       0.97      0.93      0.95       120\n",
            "           3       0.88      0.84      0.86       120\n",
            "           4       1.00      0.98      0.99       120\n",
            "           5       0.98      0.88      0.93       120\n",
            "\n",
            "    accuracy                           0.93       720\n",
            "   macro avg       0.93      0.93      0.93       720\n",
            "weighted avg       0.93      0.93      0.93       720\n",
            "\n",
            "0.9291666666666667\n",
            "[[119   0   1   0   0   0]\n",
            " [  0 114   0   5   0   1]\n",
            " [  8   0 112   0   0   0]\n",
            " [  0  18   0 101   0   1]\n",
            " [  0   0   2   0 118   0]\n",
            " [  0   6   0   9   0 105]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.99      0.96       120\n",
            "           1       0.83      0.95      0.88       120\n",
            "           2       0.97      0.93      0.95       120\n",
            "           3       0.88      0.84      0.86       120\n",
            "           4       1.00      0.98      0.99       120\n",
            "           5       0.98      0.88      0.93       120\n",
            "\n",
            "    accuracy                           0.93       720\n",
            "   macro avg       0.93      0.93      0.93       720\n",
            "weighted avg       0.93      0.93      0.93       720\n",
            "\n",
            "0.9291666666666667\n",
            "[[119   0   1   0   0   0]\n",
            " [  0 114   0   5   0   1]\n",
            " [  8   0 112   0   0   0]\n",
            " [  0  18   0 101   0   1]\n",
            " [  0   0   2   0 118   0]\n",
            " [  0   6   0   9   0 105]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.99      0.96       120\n",
            "           1       0.83      0.95      0.88       120\n",
            "           2       0.97      0.93      0.95       120\n",
            "           3       0.88      0.84      0.86       120\n",
            "           4       1.00      0.98      0.99       120\n",
            "           5       0.98      0.88      0.93       120\n",
            "\n",
            "    accuracy                           0.93       720\n",
            "   macro avg       0.93      0.93      0.93       720\n",
            "weighted avg       0.93      0.93      0.93       720\n",
            "\n",
            "0.9291666666666667\n",
            "[[119   0   1   0   0   0]\n",
            " [  0 114   0   5   0   1]\n",
            " [  8   0 112   0   0   0]\n",
            " [  0  18   0 101   0   1]\n",
            " [  0   0   2   0 118   0]\n",
            " [  0   6   0   9   0 105]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.99      0.96       120\n",
            "           1       0.83      0.95      0.88       120\n",
            "           2       0.97      0.93      0.95       120\n",
            "           3       0.88      0.84      0.86       120\n",
            "           4       1.00      0.98      0.99       120\n",
            "           5       0.98      0.88      0.93       120\n",
            "\n",
            "    accuracy                           0.93       720\n",
            "   macro avg       0.93      0.93      0.93       720\n",
            "weighted avg       0.93      0.93      0.93       720\n",
            "\n",
            "0.9291666666666667\n",
            "[[119   0   1   0   0   0]\n",
            " [  0 114   0   5   0   1]\n",
            " [  8   0 112   0   0   0]\n",
            " [  0  18   0 101   0   1]\n",
            " [  0   0   2   0 118   0]\n",
            " [  0   6   0   9   0 105]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.99      0.96       120\n",
            "           1       0.83      0.95      0.88       120\n",
            "           2       0.97      0.93      0.95       120\n",
            "           3       0.88      0.84      0.86       120\n",
            "           4       1.00      0.98      0.99       120\n",
            "           5       0.98      0.88      0.93       120\n",
            "\n",
            "    accuracy                           0.93       720\n",
            "   macro avg       0.93      0.93      0.93       720\n",
            "weighted avg       0.93      0.93      0.93       720\n",
            "\n",
            "0.9291666666666667\n",
            "[[119   0   1   0   0   0]\n",
            " [  0 114   0   5   0   1]\n",
            " [  8   0 112   0   0   0]\n",
            " [  0  18   0 101   0   1]\n",
            " [  0   0   2   0 118   0]\n",
            " [  0   6   0   9   0 105]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.99      0.96       120\n",
            "           1       0.83      0.95      0.88       120\n",
            "           2       0.97      0.93      0.95       120\n",
            "           3       0.88      0.84      0.86       120\n",
            "           4       1.00      0.98      0.99       120\n",
            "           5       0.98      0.88      0.93       120\n",
            "\n",
            "    accuracy                           0.93       720\n",
            "   macro avg       0.93      0.93      0.93       720\n",
            "weighted avg       0.93      0.93      0.93       720\n",
            "\n",
            "0.9291666666666667\n",
            "[[119   0   1   0   0   0]\n",
            " [  0 114   0   5   0   1]\n",
            " [  8   0 112   0   0   0]\n",
            " [  0  18   0 101   0   1]\n",
            " [  0   0   2   0 118   0]\n",
            " [  0   6   0   9   0 105]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.99      0.96       120\n",
            "           1       0.83      0.95      0.88       120\n",
            "           2       0.97      0.93      0.95       120\n",
            "           3       0.88      0.84      0.86       120\n",
            "           4       1.00      0.98      0.99       120\n",
            "           5       0.98      0.88      0.93       120\n",
            "\n",
            "    accuracy                           0.93       720\n",
            "   macro avg       0.93      0.93      0.93       720\n",
            "weighted avg       0.93      0.93      0.93       720\n",
            "\n",
            "0.9291666666666667\n",
            "[[119   0   1   0   0   0]\n",
            " [  0 114   0   5   0   1]\n",
            " [  8   0 112   0   0   0]\n",
            " [  0  18   0 101   0   1]\n",
            " [  0   0   2   0 118   0]\n",
            " [  0   6   0   9   0 105]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.99      0.96       120\n",
            "           1       0.83      0.95      0.88       120\n",
            "           2       0.97      0.93      0.95       120\n",
            "           3       0.88      0.84      0.86       120\n",
            "           4       1.00      0.98      0.99       120\n",
            "           5       0.98      0.88      0.93       120\n",
            "\n",
            "    accuracy                           0.93       720\n",
            "   macro avg       0.93      0.93      0.93       720\n",
            "weighted avg       0.93      0.93      0.93       720\n",
            "\n",
            "0.9291666666666667\n",
            "[[119   0   1   0   0   0]\n",
            " [  0 114   0   5   0   1]\n",
            " [  8   0 112   0   0   0]\n",
            " [  0  18   0 101   0   1]\n",
            " [  0   0   2   0 118   0]\n",
            " [  0   6   0   9   0 105]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.99      0.96       120\n",
            "           1       0.83      0.95      0.88       120\n",
            "           2       0.97      0.93      0.95       120\n",
            "           3       0.88      0.84      0.86       120\n",
            "           4       1.00      0.98      0.99       120\n",
            "           5       0.98      0.88      0.93       120\n",
            "\n",
            "    accuracy                           0.93       720\n",
            "   macro avg       0.93      0.93      0.93       720\n",
            "weighted avg       0.93      0.93      0.93       720\n",
            "\n",
            "0.9291666666666667\n",
            "[[119   0   1   0   0   0]\n",
            " [  0 114   0   5   0   1]\n",
            " [  8   0 112   0   0   0]\n",
            " [  0  18   0 101   0   1]\n",
            " [  0   0   2   0 118   0]\n",
            " [  0   6   0   9   0 105]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.99      0.96       120\n",
            "           1       0.83      0.95      0.88       120\n",
            "           2       0.97      0.93      0.95       120\n",
            "           3       0.88      0.84      0.86       120\n",
            "           4       1.00      0.98      0.99       120\n",
            "           5       0.98      0.88      0.93       120\n",
            "\n",
            "    accuracy                           0.93       720\n",
            "   macro avg       0.93      0.93      0.93       720\n",
            "weighted avg       0.93      0.93      0.93       720\n",
            "\n",
            "0.9291666666666667\n",
            "[[119   0   1   0   0   0]\n",
            " [  0 114   0   5   0   1]\n",
            " [  8   0 112   0   0   0]\n",
            " [  0  18   0 101   0   1]\n",
            " [  0   0   2   0 118   0]\n",
            " [  0   6   0   9   0 105]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.99      0.96       120\n",
            "           1       0.83      0.95      0.88       120\n",
            "           2       0.97      0.93      0.95       120\n",
            "           3       0.88      0.84      0.86       120\n",
            "           4       1.00      0.98      0.99       120\n",
            "           5       0.98      0.88      0.93       120\n",
            "\n",
            "    accuracy                           0.93       720\n",
            "   macro avg       0.93      0.93      0.93       720\n",
            "weighted avg       0.93      0.93      0.93       720\n",
            "\n",
            "0.9291666666666667\n",
            "[[119   0   1   0   0   0]\n",
            " [  0 114   0   5   0   1]\n",
            " [  8   0 112   0   0   0]\n",
            " [  0  18   0 101   0   1]\n",
            " [  0   0   2   0 118   0]\n",
            " [  0   6   0   9   0 105]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.99      0.96       120\n",
            "           1       0.83      0.95      0.88       120\n",
            "           2       0.97      0.93      0.95       120\n",
            "           3       0.88      0.84      0.86       120\n",
            "           4       1.00      0.98      0.99       120\n",
            "           5       0.98      0.88      0.93       120\n",
            "\n",
            "    accuracy                           0.93       720\n",
            "   macro avg       0.93      0.93      0.93       720\n",
            "weighted avg       0.93      0.93      0.93       720\n",
            "\n",
            "0.9291666666666667\n",
            "[[119   0   1   0   0   0]\n",
            " [  0 114   0   5   0   1]\n",
            " [  8   0 112   0   0   0]\n",
            " [  0  18   0 101   0   1]\n",
            " [  0   0   2   0 118   0]\n",
            " [  0   6   0   9   0 105]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.99      0.96       120\n",
            "           1       0.83      0.95      0.88       120\n",
            "           2       0.97      0.93      0.95       120\n",
            "           3       0.88      0.84      0.86       120\n",
            "           4       1.00      0.98      0.99       120\n",
            "           5       0.98      0.88      0.93       120\n",
            "\n",
            "    accuracy                           0.93       720\n",
            "   macro avg       0.93      0.93      0.93       720\n",
            "weighted avg       0.93      0.93      0.93       720\n",
            "\n",
            "0.9291666666666667\n",
            "[[119   0   1   0   0   0]\n",
            " [  0 114   0   5   0   1]\n",
            " [  8   0 112   0   0   0]\n",
            " [  0  18   0 101   0   1]\n",
            " [  0   0   2   0 118   0]\n",
            " [  0   6   0   9   0 105]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.99      0.96       120\n",
            "           1       0.83      0.95      0.88       120\n",
            "           2       0.97      0.93      0.95       120\n",
            "           3       0.88      0.84      0.86       120\n",
            "           4       1.00      0.98      0.99       120\n",
            "           5       0.98      0.88      0.93       120\n",
            "\n",
            "    accuracy                           0.93       720\n",
            "   macro avg       0.93      0.93      0.93       720\n",
            "weighted avg       0.93      0.93      0.93       720\n",
            "\n",
            "0.9291666666666667\n",
            "[[119   0   1   0   0   0]\n",
            " [  0 114   0   5   0   1]\n",
            " [  8   0 112   0   0   0]\n",
            " [  0  18   0 101   0   1]\n",
            " [  0   0   2   0 118   0]\n",
            " [  0   6   0   9   0 105]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.99      0.96       120\n",
            "           1       0.83      0.95      0.88       120\n",
            "           2       0.97      0.93      0.95       120\n",
            "           3       0.88      0.84      0.86       120\n",
            "           4       1.00      0.98      0.99       120\n",
            "           5       0.98      0.88      0.93       120\n",
            "\n",
            "    accuracy                           0.93       720\n",
            "   macro avg       0.93      0.93      0.93       720\n",
            "weighted avg       0.93      0.93      0.93       720\n",
            "\n",
            "0.9291666666666667\n",
            "[[119   0   1   0   0   0]\n",
            " [  0 114   0   5   0   1]\n",
            " [  8   0 112   0   0   0]\n",
            " [  0  18   0 101   0   1]\n",
            " [  0   0   2   0 118   0]\n",
            " [  0   6   0   9   0 105]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.99      0.96       120\n",
            "           1       0.83      0.95      0.88       120\n",
            "           2       0.97      0.93      0.95       120\n",
            "           3       0.88      0.84      0.86       120\n",
            "           4       1.00      0.98      0.99       120\n",
            "           5       0.98      0.88      0.93       120\n",
            "\n",
            "    accuracy                           0.93       720\n",
            "   macro avg       0.93      0.93      0.93       720\n",
            "weighted avg       0.93      0.93      0.93       720\n",
            "\n",
            "0.9291666666666667\n",
            "[[119   0   1   0   0   0]\n",
            " [  0 114   0   5   0   1]\n",
            " [  8   0 112   0   0   0]\n",
            " [  0  18   0 101   0   1]\n",
            " [  0   0   2   0 118   0]\n",
            " [  0   6   0   9   0 105]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.99      0.96       120\n",
            "           1       0.83      0.95      0.88       120\n",
            "           2       0.97      0.93      0.95       120\n",
            "           3       0.88      0.84      0.86       120\n",
            "           4       1.00      0.98      0.99       120\n",
            "           5       0.98      0.88      0.93       120\n",
            "\n",
            "    accuracy                           0.93       720\n",
            "   macro avg       0.93      0.93      0.93       720\n",
            "weighted avg       0.93      0.93      0.93       720\n",
            "\n",
            "0.9291666666666667\n",
            "[[119   0   1   0   0   0]\n",
            " [  0 114   0   5   0   1]\n",
            " [  8   0 112   0   0   0]\n",
            " [  0  18   0 101   0   1]\n",
            " [  0   0   2   0 118   0]\n",
            " [  0   6   0   9   0 105]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.99      0.96       120\n",
            "           1       0.83      0.95      0.88       120\n",
            "           2       0.97      0.93      0.95       120\n",
            "           3       0.88      0.84      0.86       120\n",
            "           4       1.00      0.98      0.99       120\n",
            "           5       0.98      0.88      0.93       120\n",
            "\n",
            "    accuracy                           0.93       720\n",
            "   macro avg       0.93      0.93      0.93       720\n",
            "weighted avg       0.93      0.93      0.93       720\n",
            "\n",
            "0.9291666666666667\n",
            "[[119   0   1   0   0   0]\n",
            " [  0 114   0   5   0   1]\n",
            " [  8   0 112   0   0   0]\n",
            " [  0  18   0 101   0   1]\n",
            " [  0   0   2   0 118   0]\n",
            " [  0   6   0   9   0 105]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.99      0.96       120\n",
            "           1       0.83      0.95      0.88       120\n",
            "           2       0.97      0.93      0.95       120\n",
            "           3       0.88      0.84      0.86       120\n",
            "           4       1.00      0.98      0.99       120\n",
            "           5       0.98      0.88      0.93       120\n",
            "\n",
            "    accuracy                           0.93       720\n",
            "   macro avg       0.93      0.93      0.93       720\n",
            "weighted avg       0.93      0.93      0.93       720\n",
            "\n",
            "0.9291666666666667\n",
            "[[119   0   1   0   0   0]\n",
            " [  0 114   0   5   0   1]\n",
            " [  8   0 112   0   0   0]\n",
            " [  0  18   0 101   0   1]\n",
            " [  0   0   2   0 118   0]\n",
            " [  0   6   0   9   0 105]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.99      0.96       120\n",
            "           1       0.83      0.95      0.88       120\n",
            "           2       0.97      0.93      0.95       120\n",
            "           3       0.88      0.84      0.86       120\n",
            "           4       1.00      0.98      0.99       120\n",
            "           5       0.98      0.88      0.93       120\n",
            "\n",
            "    accuracy                           0.93       720\n",
            "   macro avg       0.93      0.93      0.93       720\n",
            "weighted avg       0.93      0.93      0.93       720\n",
            "\n",
            "0.9291666666666667\n",
            "[[119   0   1   0   0   0]\n",
            " [  0 114   0   5   0   1]\n",
            " [  8   0 112   0   0   0]\n",
            " [  0  18   0 101   0   1]\n",
            " [  0   0   2   0 118   0]\n",
            " [  0   6   0   9   0 105]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.99      0.96       120\n",
            "           1       0.83      0.95      0.88       120\n",
            "           2       0.97      0.93      0.95       120\n",
            "           3       0.88      0.84      0.86       120\n",
            "           4       1.00      0.98      0.99       120\n",
            "           5       0.98      0.88      0.93       120\n",
            "\n",
            "    accuracy                           0.93       720\n",
            "   macro avg       0.93      0.93      0.93       720\n",
            "weighted avg       0.93      0.93      0.93       720\n",
            "\n",
            "0.9291666666666667\n",
            "[[119   0   1   0   0   0]\n",
            " [  0 114   0   5   0   1]\n",
            " [  8   0 112   0   0   0]\n",
            " [  0  18   0 101   0   1]\n",
            " [  0   0   2   0 118   0]\n",
            " [  0   6   0   9   0 105]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.99      0.96       120\n",
            "           1       0.83      0.95      0.88       120\n",
            "           2       0.97      0.93      0.95       120\n",
            "           3       0.88      0.84      0.86       120\n",
            "           4       1.00      0.98      0.99       120\n",
            "           5       0.98      0.88      0.93       120\n",
            "\n",
            "    accuracy                           0.93       720\n",
            "   macro avg       0.93      0.93      0.93       720\n",
            "weighted avg       0.93      0.93      0.93       720\n",
            "\n",
            "0.9291666666666667\n",
            "[[119   0   1   0   0   0]\n",
            " [  0 114   0   5   0   1]\n",
            " [  8   0 112   0   0   0]\n",
            " [  0  18   0 101   0   1]\n",
            " [  0   0   2   0 118   0]\n",
            " [  0   6   0   9   0 105]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.99      0.96       120\n",
            "           1       0.83      0.95      0.88       120\n",
            "           2       0.97      0.93      0.95       120\n",
            "           3       0.88      0.84      0.86       120\n",
            "           4       1.00      0.98      0.99       120\n",
            "           5       0.98      0.88      0.93       120\n",
            "\n",
            "    accuracy                           0.93       720\n",
            "   macro avg       0.93      0.93      0.93       720\n",
            "weighted avg       0.93      0.93      0.93       720\n",
            "\n",
            "0.9291666666666667\n",
            "[[119   0   1   0   0   0]\n",
            " [  0 114   0   5   0   1]\n",
            " [  8   0 112   0   0   0]\n",
            " [  0  18   0 101   0   1]\n",
            " [  0   0   2   0 118   0]\n",
            " [  0   6   0   9   0 105]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.99      0.96       120\n",
            "           1       0.83      0.95      0.88       120\n",
            "           2       0.97      0.93      0.95       120\n",
            "           3       0.88      0.84      0.86       120\n",
            "           4       1.00      0.98      0.99       120\n",
            "           5       0.98      0.88      0.93       120\n",
            "\n",
            "    accuracy                           0.93       720\n",
            "   macro avg       0.93      0.93      0.93       720\n",
            "weighted avg       0.93      0.93      0.93       720\n",
            "\n",
            "0.9291666666666667\n",
            "[[119   0   1   0   0   0]\n",
            " [  0 114   0   5   0   1]\n",
            " [  8   0 112   0   0   0]\n",
            " [  0  18   0 101   0   1]\n",
            " [  0   0   2   0 118   0]\n",
            " [  0   6   0   9   0 105]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.99      0.96       120\n",
            "           1       0.83      0.95      0.88       120\n",
            "           2       0.97      0.93      0.95       120\n",
            "           3       0.88      0.84      0.86       120\n",
            "           4       1.00      0.98      0.99       120\n",
            "           5       0.98      0.88      0.93       120\n",
            "\n",
            "    accuracy                           0.93       720\n",
            "   macro avg       0.93      0.93      0.93       720\n",
            "weighted avg       0.93      0.93      0.93       720\n",
            "\n",
            "0.9291666666666667\n",
            "[[119   0   1   0   0   0]\n",
            " [  0 114   0   5   0   1]\n",
            " [  8   0 112   0   0   0]\n",
            " [  0  18   0 101   0   1]\n",
            " [  0   0   2   0 118   0]\n",
            " [  0   6   0   9   0 105]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.99      0.96       120\n",
            "           1       0.83      0.95      0.88       120\n",
            "           2       0.97      0.93      0.95       120\n",
            "           3       0.88      0.84      0.86       120\n",
            "           4       1.00      0.98      0.99       120\n",
            "           5       0.98      0.88      0.93       120\n",
            "\n",
            "    accuracy                           0.93       720\n",
            "   macro avg       0.93      0.93      0.93       720\n",
            "weighted avg       0.93      0.93      0.93       720\n",
            "\n",
            "0.9291666666666667\n",
            "[[119   0   1   0   0   0]\n",
            " [  0 114   0   5   0   1]\n",
            " [  8   0 112   0   0   0]\n",
            " [  0  18   0 101   0   1]\n",
            " [  0   0   2   0 118   0]\n",
            " [  0   6   0   9   0 105]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.99      0.96       120\n",
            "           1       0.83      0.95      0.88       120\n",
            "           2       0.97      0.93      0.95       120\n",
            "           3       0.88      0.84      0.86       120\n",
            "           4       1.00      0.98      0.99       120\n",
            "           5       0.98      0.88      0.93       120\n",
            "\n",
            "    accuracy                           0.93       720\n",
            "   macro avg       0.93      0.93      0.93       720\n",
            "weighted avg       0.93      0.93      0.93       720\n",
            "\n",
            "0.9291666666666667\n",
            "[[119   0   1   0   0   0]\n",
            " [  0 114   0   5   0   1]\n",
            " [  8   0 112   0   0   0]\n",
            " [  0  18   0 101   0   1]\n",
            " [  0   0   2   0 118   0]\n",
            " [  0   6   0   9   0 105]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.99      0.96       120\n",
            "           1       0.83      0.95      0.88       120\n",
            "           2       0.97      0.93      0.95       120\n",
            "           3       0.88      0.84      0.86       120\n",
            "           4       1.00      0.98      0.99       120\n",
            "           5       0.98      0.88      0.93       120\n",
            "\n",
            "    accuracy                           0.93       720\n",
            "   macro avg       0.93      0.93      0.93       720\n",
            "weighted avg       0.93      0.93      0.93       720\n",
            "\n",
            "0.9291666666666667\n",
            "[[119   0   1   0   0   0]\n",
            " [  0 114   0   5   0   1]\n",
            " [  8   0 112   0   0   0]\n",
            " [  0  18   0 101   0   1]\n",
            " [  0   0   2   0 118   0]\n",
            " [  0   6   0   9   0 105]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.99      0.96       120\n",
            "           1       0.83      0.95      0.88       120\n",
            "           2       0.97      0.93      0.95       120\n",
            "           3       0.88      0.84      0.86       120\n",
            "           4       1.00      0.98      0.99       120\n",
            "           5       0.98      0.88      0.93       120\n",
            "\n",
            "    accuracy                           0.93       720\n",
            "   macro avg       0.93      0.93      0.93       720\n",
            "weighted avg       0.93      0.93      0.93       720\n",
            "\n",
            "0.9291666666666667\n",
            "[[119   0   1   0   0   0]\n",
            " [  0 114   0   5   0   1]\n",
            " [  8   0 112   0   0   0]\n",
            " [  0  18   0 101   0   1]\n",
            " [  0   0   2   0 118   0]\n",
            " [  0   6   0   9   0 105]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.99      0.96       120\n",
            "           1       0.83      0.95      0.88       120\n",
            "           2       0.97      0.93      0.95       120\n",
            "           3       0.88      0.84      0.86       120\n",
            "           4       1.00      0.98      0.99       120\n",
            "           5       0.98      0.88      0.93       120\n",
            "\n",
            "    accuracy                           0.93       720\n",
            "   macro avg       0.93      0.93      0.93       720\n",
            "weighted avg       0.93      0.93      0.93       720\n",
            "\n",
            "0.9291666666666667\n",
            "[[119   0   1   0   0   0]\n",
            " [  0 114   0   5   0   1]\n",
            " [  8   0 112   0   0   0]\n",
            " [  0  18   0 101   0   1]\n",
            " [  0   0   2   0 118   0]\n",
            " [  0   6   0   9   0 105]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.99      0.96       120\n",
            "           1       0.83      0.95      0.88       120\n",
            "           2       0.97      0.93      0.95       120\n",
            "           3       0.88      0.84      0.86       120\n",
            "           4       1.00      0.98      0.99       120\n",
            "           5       0.98      0.88      0.93       120\n",
            "\n",
            "    accuracy                           0.93       720\n",
            "   macro avg       0.93      0.93      0.93       720\n",
            "weighted avg       0.93      0.93      0.93       720\n",
            "\n",
            "0.9291666666666667\n",
            "[[119   0   1   0   0   0]\n",
            " [  0 114   0   5   0   1]\n",
            " [  8   0 112   0   0   0]\n",
            " [  0  18   0 101   0   1]\n",
            " [  0   0   2   0 118   0]\n",
            " [  0   6   0   9   0 105]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.99      0.96       120\n",
            "           1       0.83      0.95      0.88       120\n",
            "           2       0.97      0.93      0.95       120\n",
            "           3       0.88      0.84      0.86       120\n",
            "           4       1.00      0.98      0.99       120\n",
            "           5       0.98      0.88      0.93       120\n",
            "\n",
            "    accuracy                           0.93       720\n",
            "   macro avg       0.93      0.93      0.93       720\n",
            "weighted avg       0.93      0.93      0.93       720\n",
            "\n",
            "0.9291666666666667\n",
            "[[119   0   1   0   0   0]\n",
            " [  0 114   0   5   0   1]\n",
            " [  8   0 112   0   0   0]\n",
            " [  0  18   0 101   0   1]\n",
            " [  0   0   2   0 118   0]\n",
            " [  0   6   0   9   0 105]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.99      0.96       120\n",
            "           1       0.83      0.95      0.88       120\n",
            "           2       0.97      0.93      0.95       120\n",
            "           3       0.88      0.84      0.86       120\n",
            "           4       1.00      0.98      0.99       120\n",
            "           5       0.98      0.88      0.93       120\n",
            "\n",
            "    accuracy                           0.93       720\n",
            "   macro avg       0.93      0.93      0.93       720\n",
            "weighted avg       0.93      0.93      0.93       720\n",
            "\n",
            "0.9291666666666667\n",
            "[[119   0   1   0   0   0]\n",
            " [  0 114   0   5   0   1]\n",
            " [  8   0 112   0   0   0]\n",
            " [  0  18   0 101   0   1]\n",
            " [  0   0   2   0 118   0]\n",
            " [  0   6   0   9   0 105]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.99      0.96       120\n",
            "           1       0.83      0.95      0.88       120\n",
            "           2       0.97      0.93      0.95       120\n",
            "           3       0.88      0.84      0.86       120\n",
            "           4       1.00      0.98      0.99       120\n",
            "           5       0.98      0.88      0.93       120\n",
            "\n",
            "    accuracy                           0.93       720\n",
            "   macro avg       0.93      0.93      0.93       720\n",
            "weighted avg       0.93      0.93      0.93       720\n",
            "\n",
            "0.9291666666666667\n",
            "[[119   0   1   0   0   0]\n",
            " [  0 114   0   5   0   1]\n",
            " [  8   0 112   0   0   0]\n",
            " [  0  18   0 101   0   1]\n",
            " [  0   0   2   0 118   0]\n",
            " [  0   6   0   9   0 105]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.99      0.96       120\n",
            "           1       0.83      0.95      0.88       120\n",
            "           2       0.97      0.93      0.95       120\n",
            "           3       0.88      0.84      0.86       120\n",
            "           4       1.00      0.98      0.99       120\n",
            "           5       0.98      0.88      0.93       120\n",
            "\n",
            "    accuracy                           0.93       720\n",
            "   macro avg       0.93      0.93      0.93       720\n",
            "weighted avg       0.93      0.93      0.93       720\n",
            "\n",
            "0.9291666666666667\n",
            "[[119   0   1   0   0   0]\n",
            " [  0 114   0   5   0   1]\n",
            " [  8   0 112   0   0   0]\n",
            " [  0  18   0 101   0   1]\n",
            " [  0   0   2   0 118   0]\n",
            " [  0   6   0   9   0 105]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.99      0.96       120\n",
            "           1       0.83      0.95      0.88       120\n",
            "           2       0.97      0.93      0.95       120\n",
            "           3       0.88      0.84      0.86       120\n",
            "           4       1.00      0.98      0.99       120\n",
            "           5       0.98      0.88      0.93       120\n",
            "\n",
            "    accuracy                           0.93       720\n",
            "   macro avg       0.93      0.93      0.93       720\n",
            "weighted avg       0.93      0.93      0.93       720\n",
            "\n",
            "0.9291666666666667\n",
            "[[119   0   1   0   0   0]\n",
            " [  0 114   0   5   0   1]\n",
            " [  8   0 112   0   0   0]\n",
            " [  0  18   0 101   0   1]\n",
            " [  0   0   2   0 118   0]\n",
            " [  0   6   0   9   0 105]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.99      0.96       120\n",
            "           1       0.83      0.95      0.88       120\n",
            "           2       0.97      0.93      0.95       120\n",
            "           3       0.88      0.84      0.86       120\n",
            "           4       1.00      0.98      0.99       120\n",
            "           5       0.98      0.88      0.93       120\n",
            "\n",
            "    accuracy                           0.93       720\n",
            "   macro avg       0.93      0.93      0.93       720\n",
            "weighted avg       0.93      0.93      0.93       720\n",
            "\n",
            "0.9291666666666667\n",
            "[[119   0   1   0   0   0]\n",
            " [  0 114   0   5   0   1]\n",
            " [  8   0 112   0   0   0]\n",
            " [  0  18   0 101   0   1]\n",
            " [  0   0   2   0 118   0]\n",
            " [  0   6   0   9   0 105]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.99      0.96       120\n",
            "           1       0.83      0.95      0.88       120\n",
            "           2       0.97      0.93      0.95       120\n",
            "           3       0.88      0.84      0.86       120\n",
            "           4       1.00      0.98      0.99       120\n",
            "           5       0.98      0.88      0.93       120\n",
            "\n",
            "    accuracy                           0.93       720\n",
            "   macro avg       0.93      0.93      0.93       720\n",
            "weighted avg       0.93      0.93      0.93       720\n",
            "\n",
            "0.9291666666666667\n",
            "[[119   0   1   0   0   0]\n",
            " [  0 114   0   5   0   1]\n",
            " [  8   0 112   0   0   0]\n",
            " [  0  18   0 101   0   1]\n",
            " [  0   0   2   0 118   0]\n",
            " [  0   6   0   9   0 105]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.99      0.96       120\n",
            "           1       0.83      0.95      0.88       120\n",
            "           2       0.97      0.93      0.95       120\n",
            "           3       0.88      0.84      0.86       120\n",
            "           4       1.00      0.98      0.99       120\n",
            "           5       0.98      0.88      0.93       120\n",
            "\n",
            "    accuracy                           0.93       720\n",
            "   macro avg       0.93      0.93      0.93       720\n",
            "weighted avg       0.93      0.93      0.93       720\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# twin SVM"
      ],
      "metadata": {
        "id": "74goF3NuhL6d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# example SVM without kernel\n",
        "\n",
        "clf = TwinSVMClassifier()\n",
        "#clf = sklearn.multiclass.OneVsOneClassifier(clf) or sklearn.multiclass.OneVsRestClassifier(clf) depending on your needs\n",
        "# Train the classifier\n",
        "clf = clf.fit(X_train, y_train)\n",
        "\n",
        "# Output prediction\n",
        "yhat = clf.predict(X_test)\n",
        "print(metrics.accuracy_score(y_test, yhat))\n",
        "print(confusion_matrix(y_test, yhat))\n",
        "print(classification_report(y_test, yhat))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dz-mfLVSTk86",
        "outputId": "303e8564-db87-46ff-ffb5-4747531b40c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.3333333333333333\n",
            "[[120   0   0   0   0   0]\n",
            " [  0 120   0   0   0   0]\n",
            " [117   3   0   0   0   0]\n",
            " [ 35  85   0   0   0   0]\n",
            " [ 44  76   0   0   0   0]\n",
            " [ 26  94   0   0   0   0]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.35      1.00      0.52       120\n",
            "           1       0.32      1.00      0.48       120\n",
            "           2       0.00      0.00      0.00       120\n",
            "           3       0.00      0.00      0.00       120\n",
            "           4       0.00      0.00      0.00       120\n",
            "           5       0.00      0.00      0.00       120\n",
            "\n",
            "    accuracy                           0.33       720\n",
            "   macro avg       0.11      0.33      0.17       720\n",
            "weighted avg       0.11      0.33      0.17       720\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import multiclass"
      ],
      "metadata": {
        "id": "K2D83J7tU6YC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# clf = TwinSVMClassifier()\n",
        "clf = multiclass.OneVsOneClassifier(clf) \n",
        "# Train the classifier\n",
        "clf = clf.fit(X_train, y_train)\n",
        "\n",
        "# Output prediction\n",
        "yhat = clf.predict(X_test)\n",
        "print(metrics.accuracy_score(y_test, yhat))\n",
        "print(confusion_matrix(y_test, yhat))\n",
        "print(classification_report(y_test, yhat))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MnN70smAUE_I",
        "outputId": "80b207da-fef0-44db-8c93-9872ae752590"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8680555555555556\n",
            "[[120   0   0   0   0   0]\n",
            " [  0 120   0   0   0   0]\n",
            " [ 10   0 102   0   4   4]\n",
            " [  0  35   0  82   3   0]\n",
            " [  0   0   0   0 120   0]\n",
            " [  0  19   0  20   0  81]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      1.00      0.96       120\n",
            "           1       0.69      1.00      0.82       120\n",
            "           2       1.00      0.85      0.92       120\n",
            "           3       0.80      0.68      0.74       120\n",
            "           4       0.94      1.00      0.97       120\n",
            "           5       0.95      0.68      0.79       120\n",
            "\n",
            "    accuracy                           0.87       720\n",
            "   macro avg       0.89      0.87      0.87       720\n",
            "weighted avg       0.89      0.87      0.87       720\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# clf = TwinSVMClassifier()\n",
        "clf = multiclass.OneVsRestClassifier(clf)\n",
        "# Train the classifier\n",
        "clf = clf.fit(X_train, y_train)\n",
        "\n",
        "# Output prediction\n",
        "yhat = clf.predict(X_test)\n",
        "print(metrics.accuracy_score(y_test, yhat))\n",
        "print(confusion_matrix(y_test, yhat))\n",
        "print(classification_report(y_test, yhat))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pohsQA6XU4O4",
        "outputId": "01f581c7-0631-485a-bf5c-8c5fdc6cd99b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8027777777777778\n",
            "[[119   0   0   0   1   0]\n",
            " [  0 119   0   0   0   1]\n",
            " [ 17   0  91   0   6   6]\n",
            " [  1  51   0  25   8  35]\n",
            " [  0   0   0   0 120   0]\n",
            " [  0  16   0   0   0 104]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.99      0.93       120\n",
            "           1       0.64      0.99      0.78       120\n",
            "           2       1.00      0.76      0.86       120\n",
            "           3       1.00      0.21      0.34       120\n",
            "           4       0.89      1.00      0.94       120\n",
            "           5       0.71      0.87      0.78       120\n",
            "\n",
            "    accuracy                           0.80       720\n",
            "   macro avg       0.85      0.80      0.77       720\n",
            "weighted avg       0.85      0.80      0.77       720\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# example SVM RBF kernel params with fuzzy membership function\n",
        "\n",
        "clf = TwinSVMClassifier(0.1,0.1,1,1,3,2,1)\n",
        "#clf = sklearn.multiclass.OneVsOneClassifier(clf) or sklearn.multiclass.OneVsRestClassifier(clf) depending on your needs\n",
        "# Train the classifier\n",
        "clf = clf.fit(X_train, y_train)\n",
        "\n",
        "# Output prediction\n",
        "yhat = clf.predict(X_test)\n",
        "print(metrics.accuracy_score(y_test, yhat))\n",
        "print(confusion_matrix(y_test, yhat))\n",
        "print(classification_report(y_test, yhat))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O-MUab2EVJGo",
        "outputId": "bb0f4930-edb0-4e79-c8f6-fd9cd225eb02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.28888888888888886\n",
            "[[120   0   0   0   0   0]\n",
            " [ 32  88   0   0   0   0]\n",
            " [120   0   0   0   0   0]\n",
            " [119   1   0   0   0   0]\n",
            " [120   0   0   0   0   0]\n",
            " [120   0   0   0   0   0]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.19      1.00      0.32       120\n",
            "           1       0.99      0.73      0.84       120\n",
            "           2       0.00      0.00      0.00       120\n",
            "           3       0.00      0.00      0.00       120\n",
            "           4       0.00      0.00      0.00       120\n",
            "           5       0.00      0.00      0.00       120\n",
            "\n",
            "    accuracy                           0.29       720\n",
            "   macro avg       0.20      0.29      0.19       720\n",
            "weighted avg       0.20      0.29      0.19       720\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# example SVM linear kernel params with fuzzy membership function\n",
        "\n",
        "clf = TwinSVMClassifier(0.1,0.1,1,1,1,2,1)\n",
        "#clf = sklearn.multiclass.OneVsOneClassifier(clf) or sklearn.multiclass.OneVsRestClassifier(clf) depending on your needs\n",
        "# Train the classifier\n",
        "clf = clf.fit(X_train, y_train)\n",
        "\n",
        "# Output prediction\n",
        "yhat = clf.predict(X_test)\n",
        "print(metrics.accuracy_score(y_test, yhat))\n",
        "print(confusion_matrix(y_test, yhat))\n",
        "print(classification_report(y_test, yhat))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 432
        },
        "id": "H-Y518mgaW6q",
        "outputId": "0e83c61e-7b1e-41b6-8c33-1079fa197f7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "LinAlgError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-0788e326d665>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#clf = sklearn.multiclass.OneVsOneClassifier(clf) or sklearn.multiclass.OneVsRestClassifier(clf) depending on your needs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Train the classifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Output prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/TVSVM.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, Y)\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0;31m#####################Calculation of Function Parameters(Equation of planes)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0mw1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTwinPlane1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTwin_plane_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mR\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mC1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEpsilon1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregulz1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0;34m[\u001b[0m\u001b[0mw2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTwinPlane2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTwin_plane_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mR\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mC2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEpsilon2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregulz2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplane1_coeff_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplane1_offset_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/TwinPlane2.py\u001b[0m in \u001b[0;36mTwin_plane_2\u001b[0;34m(L, N, C2, Epsi2, regulz2)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;31m# for regularization we add identity matrix with wt. before inversion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mNtN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNtN\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mregulz2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNtN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mNtNLt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNtN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mLtNtNLt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mNtNLt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mLtNtNLt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mLtNtNLt\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLtNtNLt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36msolve\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36msolve\u001b[0;34m(a, b)\u001b[0m\n\u001b[1;32m    391\u001b[0m     \u001b[0msignature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'DD->D'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misComplexType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'dd->d'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m     \u001b[0mextobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_linalg_error_extobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_raise_linalgerror_singular\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m     \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgufunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36m_raise_linalgerror_singular\u001b[0;34m(err, flag)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_raise_linalgerror_singular\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLinAlgError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Singular matrix\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_raise_linalgerror_nonposdef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mLinAlgError\u001b[0m: Singular matrix"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# example SVM polynomial kernel params with fuzzy membership function\n",
        "\n",
        "clf = TwinSVMClassifier(0.1,0.1,1,1,2,2,1)\n",
        "#clf = sklearn.multiclass.OneVsOneClassifier(clf) or sklearn.multiclass.OneVsRestClassifier(clf) depending on your needs\n",
        "# Train the classifier\n",
        "clf = clf.fit(X_train, y_train)\n",
        "\n",
        "# Output prediction\n",
        "yhat = clf.predict(X_test)\n",
        "print(metrics.accuracy_score(y_test, yhat))\n",
        "print(confusion_matrix(y_test, yhat))\n",
        "print(classification_report(y_test, yhat))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 432
        },
        "id": "DVihfW67aeRZ",
        "outputId": "49b5eaf4-e913-4eaf-fc75-9e4123671dd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "LinAlgError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-2c2125a3e584>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#clf = sklearn.multiclass.OneVsOneClassifier(clf) or sklearn.multiclass.OneVsRestClassifier(clf) depending on your needs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Train the classifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Output prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/TVSVM.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, Y)\u001b[0m\n\u001b[1;32m    108\u001b[0m             \u001b[0mR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mR\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0me2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0;31m#####################Calculation of Function Parameters(Equation of planes)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m         \u001b[0;34m[\u001b[0m\u001b[0mw1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTwinPlane1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTwin_plane_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mR\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mC1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEpsilon1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregulz1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0mw2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTwinPlane2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTwin_plane_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mR\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mC2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEpsilon2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregulz2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplane1_coeff_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/TwinPlane1.py\u001b[0m in \u001b[0;36mTwin_plane_1\u001b[0;34m(R, S, C1, Epsi1, regulz1)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;31m# for regularization we add identity matrix with wt. before inversion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mStS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStS\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mregulz1\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mStS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mStSRt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mStS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mRtStSRt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mR\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mStSRt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mRtStSRt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mRtStSRt\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRtStSRt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36msolve\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36msolve\u001b[0;34m(a, b)\u001b[0m\n\u001b[1;32m    391\u001b[0m     \u001b[0msignature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'DD->D'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misComplexType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'dd->d'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m     \u001b[0mextobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_linalg_error_extobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_raise_linalgerror_singular\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m     \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgufunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36m_raise_linalgerror_singular\u001b[0;34m(err, flag)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_raise_linalgerror_singular\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLinAlgError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Singular matrix\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_raise_linalgerror_nonposdef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mLinAlgError\u001b[0m: Singular matrix"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clf = TwinSVMClassifier(0.1,0.1,1,1,3,2,0)\n",
        "#clf = sklearn.multiclass.OneVsOneClassifier(clf) or sklearn.multiclass.OneVsRestClassifier(clf) depending on your needs\n",
        "# Train the classifier\n",
        "clf = clf.fit(X_train, y_train)\n",
        "\n",
        "# Output prediction\n",
        "yhat = clf.predict(X_test)\n",
        "print(metrics.accuracy_score(y_test, yhat))\n",
        "print(confusion_matrix(y_test, yhat))\n",
        "print(classification_report(y_test, yhat))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 432
        },
        "id": "Lq4bFB4EYZpM",
        "outputId": "19caa7db-2c2e-4cd8-d6c1-0e06869f750d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "LinAlgError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-a554ef0d076e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#clf = sklearn.multiclass.OneVsOneClassifier(clf) or sklearn.multiclass.OneVsRestClassifier(clf) depending on your needs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Train the classifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Output prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/TVSVM.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, Y)\u001b[0m\n\u001b[1;32m    108\u001b[0m             \u001b[0mR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mR\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0me2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0;31m#####################Calculation of Function Parameters(Equation of planes)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m         \u001b[0;34m[\u001b[0m\u001b[0mw1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTwinPlane1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTwin_plane_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mR\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mC1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEpsilon1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregulz1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0mw2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTwinPlane2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTwin_plane_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mR\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mC2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEpsilon2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregulz2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplane1_coeff_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/TwinPlane1.py\u001b[0m in \u001b[0;36mTwin_plane_1\u001b[0;34m(R, S, C1, Epsi1, regulz1)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;31m# for regularization we add identity matrix with wt. before inversion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mStS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStS\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mregulz1\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mStS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mStSRt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mStS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mRtStSRt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mR\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mStSRt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mRtStSRt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mRtStSRt\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRtStSRt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36msolve\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36msolve\u001b[0;34m(a, b)\u001b[0m\n\u001b[1;32m    391\u001b[0m     \u001b[0msignature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'DD->D'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misComplexType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'dd->d'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m     \u001b[0mextobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_linalg_error_extobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_raise_linalgerror_singular\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m     \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgufunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36m_raise_linalgerror_singular\u001b[0;34m(err, flag)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_raise_linalgerror_singular\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLinAlgError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Singular matrix\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_raise_linalgerror_nonposdef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mLinAlgError\u001b[0m: Singular matrix"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# example SVM without kernel\n",
        "\n",
        "clf = TwinSVMClassifier(0.1,0.1,1,1,0,1,0)\n",
        "#clf = sklearn.multiclass.OneVsOneClassifier(clf) or sklearn.multiclass.OneVsRestClassifier(clf) depending on your needs\n",
        "# Train the classifier\n",
        "clf = clf.fit(X_train, y_train)\n",
        "\n",
        "# Output prediction\n",
        "yhat = clf.predict(X_test)\n",
        "print(metrics.accuracy_score(y_test, yhat))\n",
        "print(confusion_matrix(y_test, yhat))\n",
        "print(classification_report(y_test, yhat))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7fgDusOqYifL",
        "outputId": "1bd9e040-0cc4-44f8-8538-3426ab7244c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.3333333333333333\n",
            "[[120   0   0   0   0   0]\n",
            " [  0 120   0   0   0   0]\n",
            " [117   3   0   0   0   0]\n",
            " [ 35  85   0   0   0   0]\n",
            " [ 39  81   0   0   0   0]\n",
            " [ 26  94   0   0   0   0]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.36      1.00      0.53       120\n",
            "           1       0.31      1.00      0.48       120\n",
            "           2       0.00      0.00      0.00       120\n",
            "           3       0.00      0.00      0.00       120\n",
            "           4       0.00      0.00      0.00       120\n",
            "           5       0.00      0.00      0.00       120\n",
            "\n",
            "    accuracy                           0.33       720\n",
            "   macro avg       0.11      0.33      0.17       720\n",
            "weighted avg       0.11      0.33      0.17       720\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "K9cm2lKwY6yQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "sTpyOKGFc5ez"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "fkyF2ESdc5bY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Cu1yhiw6c5ZA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from libtsvm.preprocess import DataReader"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "PZr3wiNuc5Wd",
        "outputId": "2bc0f6e0-6ac4-46bf-9b69-9c54bcb7dc6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-120f0f836396>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlibtsvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataReader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'libtsvm'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install libtwinsvm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ea07ETNoc6h9",
        "outputId": "bc7c6bc3-003a-4efd-d521-621044df8ce2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting libtwinsvm\n",
            "  Downloading LIBTwinSVM-0.3.0-cp37-cp37m-manylinux1_x86_64.whl (2.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3 MB 18.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from libtwinsvm) (1.21.6)\n",
            "Collecting xlsxwriter\n",
            "  Downloading XlsxWriter-3.0.3-py3-none-any.whl (149 kB)\n",
            "\u001b[K     |████████████████████████████████| 149 kB 21.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from libtwinsvm) (1.3.5)\n",
            "Collecting pyQt5\n",
            "  Downloading PyQt5-5.15.6-cp36-abi3-manylinux1_x86_64.whl (8.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.3 MB 34.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from libtwinsvm) (1.1.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from libtwinsvm) (3.2.2)\n",
            "Collecting numpydoc==0.7.0\n",
            "  Downloading numpydoc-0.7.0.tar.gz (19 kB)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from libtwinsvm) (0.29.28)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (from libtwinsvm) (0.0)\n",
            "Requirement already satisfied: sphinx>=1.2.3 in /usr/local/lib/python3.7/dist-packages (from numpydoc==0.7.0->libtwinsvm) (1.8.6)\n",
            "Requirement already satisfied: Jinja2>=2.3 in /usr/local/lib/python3.7/dist-packages (from numpydoc==0.7.0->libtwinsvm) (2.11.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=2.3->numpydoc==0.7.0->libtwinsvm) (2.0.1)\n",
            "Requirement already satisfied: docutils<0.18,>=0.11 in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.2.3->numpydoc==0.7.0->libtwinsvm) (0.17.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.2.3->numpydoc==0.7.0->libtwinsvm) (57.4.0)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.2.3->numpydoc==0.7.0->libtwinsvm) (2.23.0)\n",
            "Requirement already satisfied: sphinxcontrib-websupport in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.2.3->numpydoc==0.7.0->libtwinsvm) (1.2.4)\n",
            "Requirement already satisfied: babel!=2.0,>=1.3 in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.2.3->numpydoc==0.7.0->libtwinsvm) (2.9.1)\n",
            "Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.2.3->numpydoc==0.7.0->libtwinsvm) (0.7.12)\n",
            "Requirement already satisfied: Pygments>=2.0 in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.2.3->numpydoc==0.7.0->libtwinsvm) (2.6.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.2.3->numpydoc==0.7.0->libtwinsvm) (21.3)\n",
            "Requirement already satisfied: imagesize in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.2.3->numpydoc==0.7.0->libtwinsvm) (1.3.0)\n",
            "Requirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.2.3->numpydoc==0.7.0->libtwinsvm) (2.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.2.3->numpydoc==0.7.0->libtwinsvm) (1.15.0)\n",
            "Requirement already satisfied: pytz>=2015.7 in /usr/local/lib/python3.7/dist-packages (from babel!=2.0,>=1.3->sphinx>=1.2.3->numpydoc==0.7.0->libtwinsvm) (2022.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.0.0->sphinx>=1.2.3->numpydoc==0.7.0->libtwinsvm) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.0.0->sphinx>=1.2.3->numpydoc==0.7.0->libtwinsvm) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.0.0->sphinx>=1.2.3->numpydoc==0.7.0->libtwinsvm) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.0.0->sphinx>=1.2.3->numpydoc==0.7.0->libtwinsvm) (1.24.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->libtwinsvm) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->libtwinsvm) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->libtwinsvm) (3.0.8)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->libtwinsvm) (1.4.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->libtwinsvm) (4.2.0)\n",
            "Collecting PyQt5-Qt5>=5.15.2\n",
            "  Downloading PyQt5_Qt5-5.15.2-py3-none-manylinux2014_x86_64.whl (59.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 59.9 MB 95 kB/s \n",
            "\u001b[?25hCollecting PyQt5-sip<13,>=12.8\n",
            "  Downloading PyQt5_sip-12.10.1-cp37-cp37m-manylinux1_x86_64.whl (338 kB)\n",
            "\u001b[K     |████████████████████████████████| 338 kB 63.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn->libtwinsvm) (1.0.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn->libtwinsvm) (1.4.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn->libtwinsvm) (3.1.0)\n",
            "Requirement already satisfied: sphinxcontrib-serializinghtml in /usr/local/lib/python3.7/dist-packages (from sphinxcontrib-websupport->sphinx>=1.2.3->numpydoc==0.7.0->libtwinsvm) (1.1.5)\n",
            "Building wheels for collected packages: numpydoc\n",
            "  Building wheel for numpydoc (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for numpydoc: filename=numpydoc-0.7.0-py3-none-any.whl size=20996 sha256=6d8a6479ee95c92942595c399f7dba5931029215903b348926090e6cb608b2fe\n",
            "  Stored in directory: /root/.cache/pip/wheels/12/b6/0d/31010d207388dff9c2ad1baa9e3e7e03ca3d112ad46074bf32\n",
            "Successfully built numpydoc\n",
            "Installing collected packages: PyQt5-sip, PyQt5-Qt5, xlsxwriter, pyQt5, numpydoc, libtwinsvm\n",
            "Successfully installed PyQt5-Qt5-5.15.2 PyQt5-sip-12.10.1 libtwinsvm-0.3.0 numpydoc-0.7.0 pyQt5-5.15.6 xlsxwriter-3.0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from libtsvm.preprocess import DataReader\n",
        "from libtsvm.estimators import LSTSVM\n",
        "from libtsvm.mc_scheme import OneVsOneClassifier\n",
        "from libtsvm.model_selection import Validator\n",
        "from libtsvm.estimators import TSVM"
      ],
      "metadata": {
        "id": "CUwBvHyydHxG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Choose a TSVM-based estimator\n",
        "kernel = 'RBF'\n",
        "lstsvm_clf = LSTSVM(kernel=kernel)\n",
        "\n",
        "# Step 3: Select a multi-class approach\n",
        "ovo_lstsvm = OneVsOneClassifier(lstsvm_clf)\n"
      ],
      "metadata": {
        "id": "Cr2hVCL5dMWc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(x_new))\n",
        "print(len(y_new))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o08-LfOhd2nK",
        "outputId": "a7eab027-8569-4cdb-bb93-fde8e51d0f37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3600\n",
            "3600\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Evaluate the multi-class estimator using train/test split\n",
        "eval_method = 't_t_split' # Train/Test split\n",
        "test_set_size = 20 # 20% of samples\n",
        "\n",
        "val = Validator(x_new, y_new, (eval_method, test_set_size), ovo_lstsvm)\n",
        "eval_func = val.choose_validator()"
      ],
      "metadata": {
        "id": "dTjP50vVdj_v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyper-parameters of the classifier\n",
        "h_params =  {'C1': 2**-2, 'C2': 2**-2, 'gamma': 2**-7}\n",
        "\n",
        "acc, std, full_report = eval_func(h_params)\n",
        "\n",
        "print(\"Accuracy: %.2f\" % acc)\n",
        "print(full_report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QSZT7LQGeKXU",
        "outputId": "1ad77f23-193d-434a-fdb1-169227b47b26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/libtsvm/estimators.py:572: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(-2 * u) * np.exp(2 * u * np.dot(x, y))\n",
            "/usr/local/lib/python3.7/dist-packages/libtsvm/estimators.py:405: RuntimeWarning: overflow encountered in multiply\n",
            "  inv_p_1 = np.linalg.inv((mat_G_G_t + (1 / self.C1) * mat_H_H_t) \\\n",
            "/usr/local/lib/python3.7/dist-packages/libtsvm/estimators.py:413: RuntimeWarning: overflow encountered in multiply\n",
            "  inv_p_2 = np.linalg.inv((mat_H_H_t + (1 / self.C2) * mat_G_G_t) \\\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 15.00\n",
            "{'accuracy': 15.0, 'acc_std': 0.0, 'micro_recall': 15.0, 'm_rec_std': 0.0, 'micro_precision': 15.0, 'm_prec_std': 0.0, 'mirco_f1': 15.0, 'm_f1_std': 0.0, 'C1': 0.25, 'C2': 0.25, 'gamma': 0.0078125}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/libtsvm/estimators.py:572: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(-2 * u) * np.exp(2 * u * np.dot(x, y))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Choose a TSVM-based estimator\n",
        "kernel = 'linear'\n",
        "tsvm_clf = TSVM(kernel=kernel)\n",
        "\n",
        "# Step 3: Evaluate the estimator using cross validation\n",
        "eval_method = 'CV' # Cross validation\n",
        "folds = 5\n",
        "\n",
        "val = Validator(x_new, y_new, (eval_method, folds), tsvm_clf)\n",
        "eval_func = val.choose_validator()\n",
        "\n",
        "# Hyper-parameters of the classifier\n",
        "h_params =  {'C1': 2**-2, 'C2': 2**1}\n",
        "\n",
        "acc, std, full_report = eval_func(h_params)\n",
        "\n",
        "print(\"Accuracy: %.2f\" % acc)\n",
        "print(full_report)"
      ],
      "metadata": {
        "id": "qMQGw6bxeMz3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "GtoSWSYbeweT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}